{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "from itertools import product\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "def standardization(data):\n",
    "    mu = np.mean(data, axis=0)\n",
    "    sigma = np.std(data, axis=0)\n",
    "    return (data - mu) / sigma\n",
    "def Cor_Loss_func(X,Y):\n",
    "    the_coef=torch.corrcoef(torch.cat([X.reshape([1,-1]),Y.reshape([1,-1])]))[0,1]\n",
    "    return -the_coef\n",
    "def Cor_Loss(X,Y):\n",
    "    cor=[]\n",
    "    for i in range(X.shape[0]):\n",
    "        cor.append(Cor_Loss_func(X[i,:],Y[i,:]).detach().numpy())\n",
    "    return torch.tensor(np.mean(cor),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Linear(ntoken,d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src=src.reshape(-1,433,1)\n",
    "        src = self.encoder(src.cuda()) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_csv=pd.read_csv(\"industry_ret_data_1500.csv\")\n",
    "dataset = data_csv.values\n",
    "dataset=np.delete(dataset,0,axis=1)\n",
    "dataset = dataset.astype('float32')\n",
    "dataset=standardization(dataset)\n",
    "vari=[]\n",
    "# for i in range(433):\n",
    "#     svar=np.var(np.array(dataset)[1000:1200,i])\n",
    "#     print(i,svar)\n",
    "#     vari.append(svar)\n",
    "# print(np.mean(vari))\n",
    "train_data = torch.from_numpy(np.array(dataset[:1000]))\n",
    "val_data = torch.from_numpy(np.array(dataset[1000:1200]))\n",
    "test_data = torch.from_numpy(np.array(dataset[1200:]))\n",
    "epochs = 5\n",
    "ntokens=1\n",
    "bptt =24\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape [full_seq_len, batch_size]\n",
    "        i: int\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
    "        target has shape [seq_len * batch_size]\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "    num_batches = len(train_data) // bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        #print(data,torch.reshape(targets.cpu(), data.size()))\n",
    "        batch_size = data.size(0)\n",
    "        if batch_size != bptt:  # only on last batch\n",
    "            src_mask = src_mask[:batch_size, :batch_size]\n",
    "        loss_function = torch.nn.MSELoss()  # 正确\n",
    "        output = model(data, src_mask)\n",
    "        output = torch.mean(output, 2)\n",
    "\n",
    "        loss = loss_function(torch.reshape(output.cuda(), targets.size()), targets.cuda())\n",
    "        cor=Cor_Loss(output.cpu(), torch.reshape(targets.cpu(), output.size()))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f} | 'f'cor {cor:.5f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) :\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    total_var=0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            batch_size = data.size(0)\n",
    "            if batch_size != bptt:\n",
    "                src_mask = src_mask[:batch_size, :batch_size]\n",
    "            output = model(data, src_mask)\n",
    "            output_flat = output.view(ntokens, -1)[0]\n",
    "\n",
    "            loss_function = torch.nn.MSELoss()  # 正确\n",
    "            output1 = torch.mean(output, 2)\n",
    "            v_cor=Cor_Loss(output.cpu(), torch.reshape(targets.cpu(),output.size()))\n",
    "            total_loss += batch_size * loss_function(output_flat.cuda(), targets.cuda()).item()\n",
    "            total_var+=batch_size*np.var(np.array(targets))\n",
    "            #print(targets,output_flat)\n",
    "\n",
    "   # print(\"var:\",total_var/(len(eval_data)-1))\n",
    "    return total_loss / (len(eval_data) - 1),v_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8, 8, 2, 2, 0.2, 0.1), (8, 8, 2, 2, 0.2, 0.01), (8, 8, 2, 2, 0.2, 0.005), (8, 8, 2, 2, 0.2, 0.001), (8, 8, 2, 2, 0.5, 0.1), (8, 8, 2, 2, 0.5, 0.01), (8, 8, 2, 2, 0.5, 0.005), (8, 8, 2, 2, 0.5, 0.001), (8, 8, 2, 4, 0.2, 0.1), (8, 8, 2, 4, 0.2, 0.01), (8, 8, 2, 4, 0.2, 0.005), (8, 8, 2, 4, 0.2, 0.001), (8, 8, 2, 4, 0.5, 0.1), (8, 8, 2, 4, 0.5, 0.01), (8, 8, 2, 4, 0.5, 0.005), (8, 8, 2, 4, 0.5, 0.001), (8, 8, 2, 8, 0.2, 0.1), (8, 8, 2, 8, 0.2, 0.01), (8, 8, 2, 8, 0.2, 0.005), (8, 8, 2, 8, 0.2, 0.001), (8, 8, 2, 8, 0.5, 0.1), (8, 8, 2, 8, 0.5, 0.01), (8, 8, 2, 8, 0.5, 0.005), (8, 8, 2, 8, 0.5, 0.001), (8, 8, 4, 2, 0.2, 0.1), (8, 8, 4, 2, 0.2, 0.01), (8, 8, 4, 2, 0.2, 0.005), (8, 8, 4, 2, 0.2, 0.001), (8, 8, 4, 2, 0.5, 0.1), (8, 8, 4, 2, 0.5, 0.01), (8, 8, 4, 2, 0.5, 0.005), (8, 8, 4, 2, 0.5, 0.001), (8, 8, 4, 4, 0.2, 0.1), (8, 8, 4, 4, 0.2, 0.01), (8, 8, 4, 4, 0.2, 0.005), (8, 8, 4, 4, 0.2, 0.001), (8, 8, 4, 4, 0.5, 0.1), (8, 8, 4, 4, 0.5, 0.01), (8, 8, 4, 4, 0.5, 0.005), (8, 8, 4, 4, 0.5, 0.001), (8, 8, 4, 8, 0.2, 0.1), (8, 8, 4, 8, 0.2, 0.01), (8, 8, 4, 8, 0.2, 0.005), (8, 8, 4, 8, 0.2, 0.001), (8, 8, 4, 8, 0.5, 0.1), (8, 8, 4, 8, 0.5, 0.01), (8, 8, 4, 8, 0.5, 0.005), (8, 8, 4, 8, 0.5, 0.001), (8, 8, 6, 2, 0.2, 0.1), (8, 8, 6, 2, 0.2, 0.01), (8, 8, 6, 2, 0.2, 0.005), (8, 8, 6, 2, 0.2, 0.001), (8, 8, 6, 2, 0.5, 0.1), (8, 8, 6, 2, 0.5, 0.01), (8, 8, 6, 2, 0.5, 0.005), (8, 8, 6, 2, 0.5, 0.001), (8, 8, 6, 4, 0.2, 0.1), (8, 8, 6, 4, 0.2, 0.01), (8, 8, 6, 4, 0.2, 0.005), (8, 8, 6, 4, 0.2, 0.001), (8, 8, 6, 4, 0.5, 0.1), (8, 8, 6, 4, 0.5, 0.01), (8, 8, 6, 4, 0.5, 0.005), (8, 8, 6, 4, 0.5, 0.001), (8, 8, 6, 8, 0.2, 0.1), (8, 8, 6, 8, 0.2, 0.01), (8, 8, 6, 8, 0.2, 0.005), (8, 8, 6, 8, 0.2, 0.001), (8, 8, 6, 8, 0.5, 0.1), (8, 8, 6, 8, 0.5, 0.01), (8, 8, 6, 8, 0.5, 0.005), (8, 8, 6, 8, 0.5, 0.001), (8, 8, 8, 2, 0.2, 0.1), (8, 8, 8, 2, 0.2, 0.01), (8, 8, 8, 2, 0.2, 0.005), (8, 8, 8, 2, 0.2, 0.001), (8, 8, 8, 2, 0.5, 0.1), (8, 8, 8, 2, 0.5, 0.01), (8, 8, 8, 2, 0.5, 0.005), (8, 8, 8, 2, 0.5, 0.001), (8, 8, 8, 4, 0.2, 0.1), (8, 8, 8, 4, 0.2, 0.01), (8, 8, 8, 4, 0.2, 0.005), (8, 8, 8, 4, 0.2, 0.001), (8, 8, 8, 4, 0.5, 0.1), (8, 8, 8, 4, 0.5, 0.01), (8, 8, 8, 4, 0.5, 0.005), (8, 8, 8, 4, 0.5, 0.001), (8, 8, 8, 8, 0.2, 0.1), (8, 8, 8, 8, 0.2, 0.01), (8, 8, 8, 8, 0.2, 0.005), (8, 8, 8, 8, 0.2, 0.001), (8, 8, 8, 8, 0.5, 0.1), (8, 8, 8, 8, 0.5, 0.01), (8, 8, 8, 8, 0.5, 0.005), (8, 8, 8, 8, 0.5, 0.001), (8, 32, 2, 2, 0.2, 0.1), (8, 32, 2, 2, 0.2, 0.01), (8, 32, 2, 2, 0.2, 0.005), (8, 32, 2, 2, 0.2, 0.001), (8, 32, 2, 2, 0.5, 0.1), (8, 32, 2, 2, 0.5, 0.01), (8, 32, 2, 2, 0.5, 0.005), (8, 32, 2, 2, 0.5, 0.001), (8, 32, 2, 4, 0.2, 0.1), (8, 32, 2, 4, 0.2, 0.01), (8, 32, 2, 4, 0.2, 0.005), (8, 32, 2, 4, 0.2, 0.001), (8, 32, 2, 4, 0.5, 0.1), (8, 32, 2, 4, 0.5, 0.01), (8, 32, 2, 4, 0.5, 0.005), (8, 32, 2, 4, 0.5, 0.001), (8, 32, 2, 8, 0.2, 0.1), (8, 32, 2, 8, 0.2, 0.01), (8, 32, 2, 8, 0.2, 0.005), (8, 32, 2, 8, 0.2, 0.001), (8, 32, 2, 8, 0.5, 0.1), (8, 32, 2, 8, 0.5, 0.01), (8, 32, 2, 8, 0.5, 0.005), (8, 32, 2, 8, 0.5, 0.001), (8, 32, 4, 2, 0.2, 0.1), (8, 32, 4, 2, 0.2, 0.01), (8, 32, 4, 2, 0.2, 0.005), (8, 32, 4, 2, 0.2, 0.001), (8, 32, 4, 2, 0.5, 0.1), (8, 32, 4, 2, 0.5, 0.01), (8, 32, 4, 2, 0.5, 0.005), (8, 32, 4, 2, 0.5, 0.001), (8, 32, 4, 4, 0.2, 0.1), (8, 32, 4, 4, 0.2, 0.01), (8, 32, 4, 4, 0.2, 0.005), (8, 32, 4, 4, 0.2, 0.001), (8, 32, 4, 4, 0.5, 0.1), (8, 32, 4, 4, 0.5, 0.01), (8, 32, 4, 4, 0.5, 0.005), (8, 32, 4, 4, 0.5, 0.001), (8, 32, 4, 8, 0.2, 0.1), (8, 32, 4, 8, 0.2, 0.01), (8, 32, 4, 8, 0.2, 0.005), (8, 32, 4, 8, 0.2, 0.001), (8, 32, 4, 8, 0.5, 0.1), (8, 32, 4, 8, 0.5, 0.01), (8, 32, 4, 8, 0.5, 0.005), (8, 32, 4, 8, 0.5, 0.001), (8, 32, 6, 2, 0.2, 0.1), (8, 32, 6, 2, 0.2, 0.01), (8, 32, 6, 2, 0.2, 0.005), (8, 32, 6, 2, 0.2, 0.001), (8, 32, 6, 2, 0.5, 0.1), (8, 32, 6, 2, 0.5, 0.01), (8, 32, 6, 2, 0.5, 0.005), (8, 32, 6, 2, 0.5, 0.001), (8, 32, 6, 4, 0.2, 0.1), (8, 32, 6, 4, 0.2, 0.01), (8, 32, 6, 4, 0.2, 0.005), (8, 32, 6, 4, 0.2, 0.001), (8, 32, 6, 4, 0.5, 0.1), (8, 32, 6, 4, 0.5, 0.01), (8, 32, 6, 4, 0.5, 0.005), (8, 32, 6, 4, 0.5, 0.001), (8, 32, 6, 8, 0.2, 0.1), (8, 32, 6, 8, 0.2, 0.01), (8, 32, 6, 8, 0.2, 0.005), (8, 32, 6, 8, 0.2, 0.001), (8, 32, 6, 8, 0.5, 0.1), (8, 32, 6, 8, 0.5, 0.01), (8, 32, 6, 8, 0.5, 0.005), (8, 32, 6, 8, 0.5, 0.001), (8, 32, 8, 2, 0.2, 0.1), (8, 32, 8, 2, 0.2, 0.01), (8, 32, 8, 2, 0.2, 0.005), (8, 32, 8, 2, 0.2, 0.001), (8, 32, 8, 2, 0.5, 0.1), (8, 32, 8, 2, 0.5, 0.01), (8, 32, 8, 2, 0.5, 0.005), (8, 32, 8, 2, 0.5, 0.001), (8, 32, 8, 4, 0.2, 0.1), (8, 32, 8, 4, 0.2, 0.01), (8, 32, 8, 4, 0.2, 0.005), (8, 32, 8, 4, 0.2, 0.001), (8, 32, 8, 4, 0.5, 0.1), (8, 32, 8, 4, 0.5, 0.01), (8, 32, 8, 4, 0.5, 0.005), (8, 32, 8, 4, 0.5, 0.001), (8, 32, 8, 8, 0.2, 0.1), (8, 32, 8, 8, 0.2, 0.01), (8, 32, 8, 8, 0.2, 0.005), (8, 32, 8, 8, 0.2, 0.001), (8, 32, 8, 8, 0.5, 0.1), (8, 32, 8, 8, 0.5, 0.01), (8, 32, 8, 8, 0.5, 0.005), (8, 32, 8, 8, 0.5, 0.001), (8, 64, 2, 2, 0.2, 0.1), (8, 64, 2, 2, 0.2, 0.01), (8, 64, 2, 2, 0.2, 0.005), (8, 64, 2, 2, 0.2, 0.001), (8, 64, 2, 2, 0.5, 0.1), (8, 64, 2, 2, 0.5, 0.01), (8, 64, 2, 2, 0.5, 0.005), (8, 64, 2, 2, 0.5, 0.001), (8, 64, 2, 4, 0.2, 0.1), (8, 64, 2, 4, 0.2, 0.01), (8, 64, 2, 4, 0.2, 0.005), (8, 64, 2, 4, 0.2, 0.001), (8, 64, 2, 4, 0.5, 0.1), (8, 64, 2, 4, 0.5, 0.01), (8, 64, 2, 4, 0.5, 0.005), (8, 64, 2, 4, 0.5, 0.001), (8, 64, 2, 8, 0.2, 0.1), (8, 64, 2, 8, 0.2, 0.01), (8, 64, 2, 8, 0.2, 0.005), (8, 64, 2, 8, 0.2, 0.001), (8, 64, 2, 8, 0.5, 0.1), (8, 64, 2, 8, 0.5, 0.01), (8, 64, 2, 8, 0.5, 0.005), (8, 64, 2, 8, 0.5, 0.001), (8, 64, 4, 2, 0.2, 0.1), (8, 64, 4, 2, 0.2, 0.01), (8, 64, 4, 2, 0.2, 0.005), (8, 64, 4, 2, 0.2, 0.001), (8, 64, 4, 2, 0.5, 0.1), (8, 64, 4, 2, 0.5, 0.01), (8, 64, 4, 2, 0.5, 0.005), (8, 64, 4, 2, 0.5, 0.001), (8, 64, 4, 4, 0.2, 0.1), (8, 64, 4, 4, 0.2, 0.01), (8, 64, 4, 4, 0.2, 0.005), (8, 64, 4, 4, 0.2, 0.001), (8, 64, 4, 4, 0.5, 0.1), (8, 64, 4, 4, 0.5, 0.01), (8, 64, 4, 4, 0.5, 0.005), (8, 64, 4, 4, 0.5, 0.001), (8, 64, 4, 8, 0.2, 0.1), (8, 64, 4, 8, 0.2, 0.01), (8, 64, 4, 8, 0.2, 0.005), (8, 64, 4, 8, 0.2, 0.001), (8, 64, 4, 8, 0.5, 0.1), (8, 64, 4, 8, 0.5, 0.01), (8, 64, 4, 8, 0.5, 0.005), (8, 64, 4, 8, 0.5, 0.001), (8, 64, 6, 2, 0.2, 0.1), (8, 64, 6, 2, 0.2, 0.01), (8, 64, 6, 2, 0.2, 0.005), (8, 64, 6, 2, 0.2, 0.001), (8, 64, 6, 2, 0.5, 0.1), (8, 64, 6, 2, 0.5, 0.01), (8, 64, 6, 2, 0.5, 0.005), (8, 64, 6, 2, 0.5, 0.001), (8, 64, 6, 4, 0.2, 0.1), (8, 64, 6, 4, 0.2, 0.01), (8, 64, 6, 4, 0.2, 0.005), (8, 64, 6, 4, 0.2, 0.001), (8, 64, 6, 4, 0.5, 0.1), (8, 64, 6, 4, 0.5, 0.01), (8, 64, 6, 4, 0.5, 0.005), (8, 64, 6, 4, 0.5, 0.001), (8, 64, 6, 8, 0.2, 0.1), (8, 64, 6, 8, 0.2, 0.01), (8, 64, 6, 8, 0.2, 0.005), (8, 64, 6, 8, 0.2, 0.001), (8, 64, 6, 8, 0.5, 0.1), (8, 64, 6, 8, 0.5, 0.01), (8, 64, 6, 8, 0.5, 0.005), (8, 64, 6, 8, 0.5, 0.001), (8, 64, 8, 2, 0.2, 0.1), (8, 64, 8, 2, 0.2, 0.01), (8, 64, 8, 2, 0.2, 0.005), (8, 64, 8, 2, 0.2, 0.001), (8, 64, 8, 2, 0.5, 0.1), (8, 64, 8, 2, 0.5, 0.01), (8, 64, 8, 2, 0.5, 0.005), (8, 64, 8, 2, 0.5, 0.001), (8, 64, 8, 4, 0.2, 0.1), (8, 64, 8, 4, 0.2, 0.01), (8, 64, 8, 4, 0.2, 0.005), (8, 64, 8, 4, 0.2, 0.001), (8, 64, 8, 4, 0.5, 0.1), (8, 64, 8, 4, 0.5, 0.01), (8, 64, 8, 4, 0.5, 0.005), (8, 64, 8, 4, 0.5, 0.001), (8, 64, 8, 8, 0.2, 0.1), (8, 64, 8, 8, 0.2, 0.01), (8, 64, 8, 8, 0.2, 0.005), (8, 64, 8, 8, 0.2, 0.001), (8, 64, 8, 8, 0.5, 0.1), (8, 64, 8, 8, 0.5, 0.01), (8, 64, 8, 8, 0.5, 0.005), (8, 64, 8, 8, 0.5, 0.001), (8, 128, 2, 2, 0.2, 0.1), (8, 128, 2, 2, 0.2, 0.01), (8, 128, 2, 2, 0.2, 0.005), (8, 128, 2, 2, 0.2, 0.001), (8, 128, 2, 2, 0.5, 0.1), (8, 128, 2, 2, 0.5, 0.01), (8, 128, 2, 2, 0.5, 0.005), (8, 128, 2, 2, 0.5, 0.001), (8, 128, 2, 4, 0.2, 0.1), (8, 128, 2, 4, 0.2, 0.01), (8, 128, 2, 4, 0.2, 0.005), (8, 128, 2, 4, 0.2, 0.001), (8, 128, 2, 4, 0.5, 0.1), (8, 128, 2, 4, 0.5, 0.01), (8, 128, 2, 4, 0.5, 0.005), (8, 128, 2, 4, 0.5, 0.001), (8, 128, 2, 8, 0.2, 0.1), (8, 128, 2, 8, 0.2, 0.01), (8, 128, 2, 8, 0.2, 0.005), (8, 128, 2, 8, 0.2, 0.001), (8, 128, 2, 8, 0.5, 0.1), (8, 128, 2, 8, 0.5, 0.01), (8, 128, 2, 8, 0.5, 0.005), (8, 128, 2, 8, 0.5, 0.001), (8, 128, 4, 2, 0.2, 0.1), (8, 128, 4, 2, 0.2, 0.01), (8, 128, 4, 2, 0.2, 0.005), (8, 128, 4, 2, 0.2, 0.001), (8, 128, 4, 2, 0.5, 0.1), (8, 128, 4, 2, 0.5, 0.01), (8, 128, 4, 2, 0.5, 0.005), (8, 128, 4, 2, 0.5, 0.001), (8, 128, 4, 4, 0.2, 0.1), (8, 128, 4, 4, 0.2, 0.01), (8, 128, 4, 4, 0.2, 0.005), (8, 128, 4, 4, 0.2, 0.001), (8, 128, 4, 4, 0.5, 0.1), (8, 128, 4, 4, 0.5, 0.01), (8, 128, 4, 4, 0.5, 0.005), (8, 128, 4, 4, 0.5, 0.001), (8, 128, 4, 8, 0.2, 0.1), (8, 128, 4, 8, 0.2, 0.01), (8, 128, 4, 8, 0.2, 0.005), (8, 128, 4, 8, 0.2, 0.001), (8, 128, 4, 8, 0.5, 0.1), (8, 128, 4, 8, 0.5, 0.01), (8, 128, 4, 8, 0.5, 0.005), (8, 128, 4, 8, 0.5, 0.001), (8, 128, 6, 2, 0.2, 0.1), (8, 128, 6, 2, 0.2, 0.01), (8, 128, 6, 2, 0.2, 0.005), (8, 128, 6, 2, 0.2, 0.001), (8, 128, 6, 2, 0.5, 0.1), (8, 128, 6, 2, 0.5, 0.01), (8, 128, 6, 2, 0.5, 0.005), (8, 128, 6, 2, 0.5, 0.001), (8, 128, 6, 4, 0.2, 0.1), (8, 128, 6, 4, 0.2, 0.01), (8, 128, 6, 4, 0.2, 0.005), (8, 128, 6, 4, 0.2, 0.001), (8, 128, 6, 4, 0.5, 0.1), (8, 128, 6, 4, 0.5, 0.01), (8, 128, 6, 4, 0.5, 0.005), (8, 128, 6, 4, 0.5, 0.001), (8, 128, 6, 8, 0.2, 0.1), (8, 128, 6, 8, 0.2, 0.01), (8, 128, 6, 8, 0.2, 0.005), (8, 128, 6, 8, 0.2, 0.001), (8, 128, 6, 8, 0.5, 0.1), (8, 128, 6, 8, 0.5, 0.01), (8, 128, 6, 8, 0.5, 0.005), (8, 128, 6, 8, 0.5, 0.001), (8, 128, 8, 2, 0.2, 0.1), (8, 128, 8, 2, 0.2, 0.01), (8, 128, 8, 2, 0.2, 0.005), (8, 128, 8, 2, 0.2, 0.001), (8, 128, 8, 2, 0.5, 0.1), (8, 128, 8, 2, 0.5, 0.01), (8, 128, 8, 2, 0.5, 0.005), (8, 128, 8, 2, 0.5, 0.001), (8, 128, 8, 4, 0.2, 0.1), (8, 128, 8, 4, 0.2, 0.01), (8, 128, 8, 4, 0.2, 0.005), (8, 128, 8, 4, 0.2, 0.001), (8, 128, 8, 4, 0.5, 0.1), (8, 128, 8, 4, 0.5, 0.01), (8, 128, 8, 4, 0.5, 0.005), (8, 128, 8, 4, 0.5, 0.001), (8, 128, 8, 8, 0.2, 0.1), (8, 128, 8, 8, 0.2, 0.01), (8, 128, 8, 8, 0.2, 0.005), (8, 128, 8, 8, 0.2, 0.001), (8, 128, 8, 8, 0.5, 0.1), (8, 128, 8, 8, 0.5, 0.01), (8, 128, 8, 8, 0.5, 0.005), (8, 128, 8, 8, 0.5, 0.001), (8, 256, 2, 2, 0.2, 0.1), (8, 256, 2, 2, 0.2, 0.01), (8, 256, 2, 2, 0.2, 0.005), (8, 256, 2, 2, 0.2, 0.001), (8, 256, 2, 2, 0.5, 0.1), (8, 256, 2, 2, 0.5, 0.01), (8, 256, 2, 2, 0.5, 0.005), (8, 256, 2, 2, 0.5, 0.001), (8, 256, 2, 4, 0.2, 0.1), (8, 256, 2, 4, 0.2, 0.01), (8, 256, 2, 4, 0.2, 0.005), (8, 256, 2, 4, 0.2, 0.001), (8, 256, 2, 4, 0.5, 0.1), (8, 256, 2, 4, 0.5, 0.01), (8, 256, 2, 4, 0.5, 0.005), (8, 256, 2, 4, 0.5, 0.001), (8, 256, 2, 8, 0.2, 0.1), (8, 256, 2, 8, 0.2, 0.01), (8, 256, 2, 8, 0.2, 0.005), (8, 256, 2, 8, 0.2, 0.001), (8, 256, 2, 8, 0.5, 0.1), (8, 256, 2, 8, 0.5, 0.01), (8, 256, 2, 8, 0.5, 0.005), (8, 256, 2, 8, 0.5, 0.001), (8, 256, 4, 2, 0.2, 0.1), (8, 256, 4, 2, 0.2, 0.01), (8, 256, 4, 2, 0.2, 0.005), (8, 256, 4, 2, 0.2, 0.001), (8, 256, 4, 2, 0.5, 0.1), (8, 256, 4, 2, 0.5, 0.01), (8, 256, 4, 2, 0.5, 0.005), (8, 256, 4, 2, 0.5, 0.001), (8, 256, 4, 4, 0.2, 0.1), (8, 256, 4, 4, 0.2, 0.01), (8, 256, 4, 4, 0.2, 0.005), (8, 256, 4, 4, 0.2, 0.001), (8, 256, 4, 4, 0.5, 0.1), (8, 256, 4, 4, 0.5, 0.01), (8, 256, 4, 4, 0.5, 0.005), (8, 256, 4, 4, 0.5, 0.001), (8, 256, 4, 8, 0.2, 0.1), (8, 256, 4, 8, 0.2, 0.01), (8, 256, 4, 8, 0.2, 0.005), (8, 256, 4, 8, 0.2, 0.001), (8, 256, 4, 8, 0.5, 0.1), (8, 256, 4, 8, 0.5, 0.01), (8, 256, 4, 8, 0.5, 0.005), (8, 256, 4, 8, 0.5, 0.001), (8, 256, 6, 2, 0.2, 0.1), (8, 256, 6, 2, 0.2, 0.01), (8, 256, 6, 2, 0.2, 0.005), (8, 256, 6, 2, 0.2, 0.001), (8, 256, 6, 2, 0.5, 0.1), (8, 256, 6, 2, 0.5, 0.01), (8, 256, 6, 2, 0.5, 0.005), (8, 256, 6, 2, 0.5, 0.001), (8, 256, 6, 4, 0.2, 0.1), (8, 256, 6, 4, 0.2, 0.01), (8, 256, 6, 4, 0.2, 0.005), (8, 256, 6, 4, 0.2, 0.001), (8, 256, 6, 4, 0.5, 0.1), (8, 256, 6, 4, 0.5, 0.01), (8, 256, 6, 4, 0.5, 0.005), (8, 256, 6, 4, 0.5, 0.001), (8, 256, 6, 8, 0.2, 0.1), (8, 256, 6, 8, 0.2, 0.01), (8, 256, 6, 8, 0.2, 0.005), (8, 256, 6, 8, 0.2, 0.001), (8, 256, 6, 8, 0.5, 0.1), (8, 256, 6, 8, 0.5, 0.01), (8, 256, 6, 8, 0.5, 0.005), (8, 256, 6, 8, 0.5, 0.001), (8, 256, 8, 2, 0.2, 0.1), (8, 256, 8, 2, 0.2, 0.01), (8, 256, 8, 2, 0.2, 0.005), (8, 256, 8, 2, 0.2, 0.001), (8, 256, 8, 2, 0.5, 0.1), (8, 256, 8, 2, 0.5, 0.01), (8, 256, 8, 2, 0.5, 0.005), (8, 256, 8, 2, 0.5, 0.001), (8, 256, 8, 4, 0.2, 0.1), (8, 256, 8, 4, 0.2, 0.01), (8, 256, 8, 4, 0.2, 0.005), (8, 256, 8, 4, 0.2, 0.001), (8, 256, 8, 4, 0.5, 0.1), (8, 256, 8, 4, 0.5, 0.01), (8, 256, 8, 4, 0.5, 0.005), (8, 256, 8, 4, 0.5, 0.001), (8, 256, 8, 8, 0.2, 0.1), (8, 256, 8, 8, 0.2, 0.01), (8, 256, 8, 8, 0.2, 0.005), (8, 256, 8, 8, 0.2, 0.001), (8, 256, 8, 8, 0.5, 0.1), (8, 256, 8, 8, 0.5, 0.01), (8, 256, 8, 8, 0.5, 0.005), (8, 256, 8, 8, 0.5, 0.001), (32, 8, 2, 2, 0.2, 0.1), (32, 8, 2, 2, 0.2, 0.01), (32, 8, 2, 2, 0.2, 0.005), (32, 8, 2, 2, 0.2, 0.001), (32, 8, 2, 2, 0.5, 0.1), (32, 8, 2, 2, 0.5, 0.01), (32, 8, 2, 2, 0.5, 0.005), (32, 8, 2, 2, 0.5, 0.001), (32, 8, 2, 4, 0.2, 0.1), (32, 8, 2, 4, 0.2, 0.01), (32, 8, 2, 4, 0.2, 0.005), (32, 8, 2, 4, 0.2, 0.001), (32, 8, 2, 4, 0.5, 0.1), (32, 8, 2, 4, 0.5, 0.01), (32, 8, 2, 4, 0.5, 0.005), (32, 8, 2, 4, 0.5, 0.001), (32, 8, 2, 8, 0.2, 0.1), (32, 8, 2, 8, 0.2, 0.01), (32, 8, 2, 8, 0.2, 0.005), (32, 8, 2, 8, 0.2, 0.001), (32, 8, 2, 8, 0.5, 0.1), (32, 8, 2, 8, 0.5, 0.01), (32, 8, 2, 8, 0.5, 0.005), (32, 8, 2, 8, 0.5, 0.001), (32, 8, 4, 2, 0.2, 0.1), (32, 8, 4, 2, 0.2, 0.01), (32, 8, 4, 2, 0.2, 0.005), (32, 8, 4, 2, 0.2, 0.001), (32, 8, 4, 2, 0.5, 0.1), (32, 8, 4, 2, 0.5, 0.01), (32, 8, 4, 2, 0.5, 0.005), (32, 8, 4, 2, 0.5, 0.001), (32, 8, 4, 4, 0.2, 0.1), (32, 8, 4, 4, 0.2, 0.01), (32, 8, 4, 4, 0.2, 0.005), (32, 8, 4, 4, 0.2, 0.001), (32, 8, 4, 4, 0.5, 0.1), (32, 8, 4, 4, 0.5, 0.01), (32, 8, 4, 4, 0.5, 0.005), (32, 8, 4, 4, 0.5, 0.001), (32, 8, 4, 8, 0.2, 0.1), (32, 8, 4, 8, 0.2, 0.01), (32, 8, 4, 8, 0.2, 0.005), (32, 8, 4, 8, 0.2, 0.001), (32, 8, 4, 8, 0.5, 0.1), (32, 8, 4, 8, 0.5, 0.01), (32, 8, 4, 8, 0.5, 0.005), (32, 8, 4, 8, 0.5, 0.001), (32, 8, 6, 2, 0.2, 0.1), (32, 8, 6, 2, 0.2, 0.01), (32, 8, 6, 2, 0.2, 0.005), (32, 8, 6, 2, 0.2, 0.001), (32, 8, 6, 2, 0.5, 0.1), (32, 8, 6, 2, 0.5, 0.01), (32, 8, 6, 2, 0.5, 0.005), (32, 8, 6, 2, 0.5, 0.001), (32, 8, 6, 4, 0.2, 0.1), (32, 8, 6, 4, 0.2, 0.01), (32, 8, 6, 4, 0.2, 0.005), (32, 8, 6, 4, 0.2, 0.001), (32, 8, 6, 4, 0.5, 0.1), (32, 8, 6, 4, 0.5, 0.01), (32, 8, 6, 4, 0.5, 0.005), (32, 8, 6, 4, 0.5, 0.001), (32, 8, 6, 8, 0.2, 0.1), (32, 8, 6, 8, 0.2, 0.01), (32, 8, 6, 8, 0.2, 0.005), (32, 8, 6, 8, 0.2, 0.001), (32, 8, 6, 8, 0.5, 0.1), (32, 8, 6, 8, 0.5, 0.01), (32, 8, 6, 8, 0.5, 0.005), (32, 8, 6, 8, 0.5, 0.001), (32, 8, 8, 2, 0.2, 0.1), (32, 8, 8, 2, 0.2, 0.01), (32, 8, 8, 2, 0.2, 0.005), (32, 8, 8, 2, 0.2, 0.001), (32, 8, 8, 2, 0.5, 0.1), (32, 8, 8, 2, 0.5, 0.01), (32, 8, 8, 2, 0.5, 0.005), (32, 8, 8, 2, 0.5, 0.001), (32, 8, 8, 4, 0.2, 0.1), (32, 8, 8, 4, 0.2, 0.01), (32, 8, 8, 4, 0.2, 0.005), (32, 8, 8, 4, 0.2, 0.001), (32, 8, 8, 4, 0.5, 0.1), (32, 8, 8, 4, 0.5, 0.01), (32, 8, 8, 4, 0.5, 0.005), (32, 8, 8, 4, 0.5, 0.001), (32, 8, 8, 8, 0.2, 0.1), (32, 8, 8, 8, 0.2, 0.01), (32, 8, 8, 8, 0.2, 0.005), (32, 8, 8, 8, 0.2, 0.001), (32, 8, 8, 8, 0.5, 0.1), (32, 8, 8, 8, 0.5, 0.01), (32, 8, 8, 8, 0.5, 0.005), (32, 8, 8, 8, 0.5, 0.001), (32, 32, 2, 2, 0.2, 0.1), (32, 32, 2, 2, 0.2, 0.01), (32, 32, 2, 2, 0.2, 0.005), (32, 32, 2, 2, 0.2, 0.001), (32, 32, 2, 2, 0.5, 0.1), (32, 32, 2, 2, 0.5, 0.01), (32, 32, 2, 2, 0.5, 0.005), (32, 32, 2, 2, 0.5, 0.001), (32, 32, 2, 4, 0.2, 0.1), (32, 32, 2, 4, 0.2, 0.01), (32, 32, 2, 4, 0.2, 0.005), (32, 32, 2, 4, 0.2, 0.001), (32, 32, 2, 4, 0.5, 0.1), (32, 32, 2, 4, 0.5, 0.01), (32, 32, 2, 4, 0.5, 0.005), (32, 32, 2, 4, 0.5, 0.001), (32, 32, 2, 8, 0.2, 0.1), (32, 32, 2, 8, 0.2, 0.01), (32, 32, 2, 8, 0.2, 0.005), (32, 32, 2, 8, 0.2, 0.001), (32, 32, 2, 8, 0.5, 0.1), (32, 32, 2, 8, 0.5, 0.01), (32, 32, 2, 8, 0.5, 0.005), (32, 32, 2, 8, 0.5, 0.001), (32, 32, 4, 2, 0.2, 0.1), (32, 32, 4, 2, 0.2, 0.01), (32, 32, 4, 2, 0.2, 0.005), (32, 32, 4, 2, 0.2, 0.001), (32, 32, 4, 2, 0.5, 0.1), (32, 32, 4, 2, 0.5, 0.01), (32, 32, 4, 2, 0.5, 0.005), (32, 32, 4, 2, 0.5, 0.001), (32, 32, 4, 4, 0.2, 0.1), (32, 32, 4, 4, 0.2, 0.01), (32, 32, 4, 4, 0.2, 0.005), (32, 32, 4, 4, 0.2, 0.001), (32, 32, 4, 4, 0.5, 0.1), (32, 32, 4, 4, 0.5, 0.01), (32, 32, 4, 4, 0.5, 0.005), (32, 32, 4, 4, 0.5, 0.001), (32, 32, 4, 8, 0.2, 0.1), (32, 32, 4, 8, 0.2, 0.01), (32, 32, 4, 8, 0.2, 0.005), (32, 32, 4, 8, 0.2, 0.001), (32, 32, 4, 8, 0.5, 0.1), (32, 32, 4, 8, 0.5, 0.01), (32, 32, 4, 8, 0.5, 0.005), (32, 32, 4, 8, 0.5, 0.001), (32, 32, 6, 2, 0.2, 0.1), (32, 32, 6, 2, 0.2, 0.01), (32, 32, 6, 2, 0.2, 0.005), (32, 32, 6, 2, 0.2, 0.001), (32, 32, 6, 2, 0.5, 0.1), (32, 32, 6, 2, 0.5, 0.01), (32, 32, 6, 2, 0.5, 0.005), (32, 32, 6, 2, 0.5, 0.001), (32, 32, 6, 4, 0.2, 0.1), (32, 32, 6, 4, 0.2, 0.01), (32, 32, 6, 4, 0.2, 0.005), (32, 32, 6, 4, 0.2, 0.001), (32, 32, 6, 4, 0.5, 0.1), (32, 32, 6, 4, 0.5, 0.01), (32, 32, 6, 4, 0.5, 0.005), (32, 32, 6, 4, 0.5, 0.001), (32, 32, 6, 8, 0.2, 0.1), (32, 32, 6, 8, 0.2, 0.01), (32, 32, 6, 8, 0.2, 0.005), (32, 32, 6, 8, 0.2, 0.001), (32, 32, 6, 8, 0.5, 0.1), (32, 32, 6, 8, 0.5, 0.01), (32, 32, 6, 8, 0.5, 0.005), (32, 32, 6, 8, 0.5, 0.001), (32, 32, 8, 2, 0.2, 0.1), (32, 32, 8, 2, 0.2, 0.01), (32, 32, 8, 2, 0.2, 0.005), (32, 32, 8, 2, 0.2, 0.001), (32, 32, 8, 2, 0.5, 0.1), (32, 32, 8, 2, 0.5, 0.01), (32, 32, 8, 2, 0.5, 0.005), (32, 32, 8, 2, 0.5, 0.001), (32, 32, 8, 4, 0.2, 0.1), (32, 32, 8, 4, 0.2, 0.01), (32, 32, 8, 4, 0.2, 0.005), (32, 32, 8, 4, 0.2, 0.001), (32, 32, 8, 4, 0.5, 0.1), (32, 32, 8, 4, 0.5, 0.01), (32, 32, 8, 4, 0.5, 0.005), (32, 32, 8, 4, 0.5, 0.001), (32, 32, 8, 8, 0.2, 0.1), (32, 32, 8, 8, 0.2, 0.01), (32, 32, 8, 8, 0.2, 0.005), (32, 32, 8, 8, 0.2, 0.001), (32, 32, 8, 8, 0.5, 0.1), (32, 32, 8, 8, 0.5, 0.01), (32, 32, 8, 8, 0.5, 0.005), (32, 32, 8, 8, 0.5, 0.001), (32, 64, 2, 2, 0.2, 0.1), (32, 64, 2, 2, 0.2, 0.01), (32, 64, 2, 2, 0.2, 0.005), (32, 64, 2, 2, 0.2, 0.001), (32, 64, 2, 2, 0.5, 0.1), (32, 64, 2, 2, 0.5, 0.01), (32, 64, 2, 2, 0.5, 0.005), (32, 64, 2, 2, 0.5, 0.001), (32, 64, 2, 4, 0.2, 0.1), (32, 64, 2, 4, 0.2, 0.01), (32, 64, 2, 4, 0.2, 0.005), (32, 64, 2, 4, 0.2, 0.001), (32, 64, 2, 4, 0.5, 0.1), (32, 64, 2, 4, 0.5, 0.01), (32, 64, 2, 4, 0.5, 0.005), (32, 64, 2, 4, 0.5, 0.001), (32, 64, 2, 8, 0.2, 0.1), (32, 64, 2, 8, 0.2, 0.01), (32, 64, 2, 8, 0.2, 0.005), (32, 64, 2, 8, 0.2, 0.001), (32, 64, 2, 8, 0.5, 0.1), (32, 64, 2, 8, 0.5, 0.01), (32, 64, 2, 8, 0.5, 0.005), (32, 64, 2, 8, 0.5, 0.001), (32, 64, 4, 2, 0.2, 0.1), (32, 64, 4, 2, 0.2, 0.01), (32, 64, 4, 2, 0.2, 0.005), (32, 64, 4, 2, 0.2, 0.001), (32, 64, 4, 2, 0.5, 0.1), (32, 64, 4, 2, 0.5, 0.01), (32, 64, 4, 2, 0.5, 0.005), (32, 64, 4, 2, 0.5, 0.001), (32, 64, 4, 4, 0.2, 0.1), (32, 64, 4, 4, 0.2, 0.01), (32, 64, 4, 4, 0.2, 0.005), (32, 64, 4, 4, 0.2, 0.001), (32, 64, 4, 4, 0.5, 0.1), (32, 64, 4, 4, 0.5, 0.01), (32, 64, 4, 4, 0.5, 0.005), (32, 64, 4, 4, 0.5, 0.001), (32, 64, 4, 8, 0.2, 0.1), (32, 64, 4, 8, 0.2, 0.01), (32, 64, 4, 8, 0.2, 0.005), (32, 64, 4, 8, 0.2, 0.001), (32, 64, 4, 8, 0.5, 0.1), (32, 64, 4, 8, 0.5, 0.01), (32, 64, 4, 8, 0.5, 0.005), (32, 64, 4, 8, 0.5, 0.001), (32, 64, 6, 2, 0.2, 0.1), (32, 64, 6, 2, 0.2, 0.01), (32, 64, 6, 2, 0.2, 0.005), (32, 64, 6, 2, 0.2, 0.001), (32, 64, 6, 2, 0.5, 0.1), (32, 64, 6, 2, 0.5, 0.01), (32, 64, 6, 2, 0.5, 0.005), (32, 64, 6, 2, 0.5, 0.001), (32, 64, 6, 4, 0.2, 0.1), (32, 64, 6, 4, 0.2, 0.01), (32, 64, 6, 4, 0.2, 0.005), (32, 64, 6, 4, 0.2, 0.001), (32, 64, 6, 4, 0.5, 0.1), (32, 64, 6, 4, 0.5, 0.01), (32, 64, 6, 4, 0.5, 0.005), (32, 64, 6, 4, 0.5, 0.001), (32, 64, 6, 8, 0.2, 0.1), (32, 64, 6, 8, 0.2, 0.01), (32, 64, 6, 8, 0.2, 0.005), (32, 64, 6, 8, 0.2, 0.001), (32, 64, 6, 8, 0.5, 0.1), (32, 64, 6, 8, 0.5, 0.01), (32, 64, 6, 8, 0.5, 0.005), (32, 64, 6, 8, 0.5, 0.001), (32, 64, 8, 2, 0.2, 0.1), (32, 64, 8, 2, 0.2, 0.01), (32, 64, 8, 2, 0.2, 0.005), (32, 64, 8, 2, 0.2, 0.001), (32, 64, 8, 2, 0.5, 0.1), (32, 64, 8, 2, 0.5, 0.01), (32, 64, 8, 2, 0.5, 0.005), (32, 64, 8, 2, 0.5, 0.001), (32, 64, 8, 4, 0.2, 0.1), (32, 64, 8, 4, 0.2, 0.01), (32, 64, 8, 4, 0.2, 0.005), (32, 64, 8, 4, 0.2, 0.001), (32, 64, 8, 4, 0.5, 0.1), (32, 64, 8, 4, 0.5, 0.01), (32, 64, 8, 4, 0.5, 0.005), (32, 64, 8, 4, 0.5, 0.001), (32, 64, 8, 8, 0.2, 0.1), (32, 64, 8, 8, 0.2, 0.01), (32, 64, 8, 8, 0.2, 0.005), (32, 64, 8, 8, 0.2, 0.001), (32, 64, 8, 8, 0.5, 0.1), (32, 64, 8, 8, 0.5, 0.01), (32, 64, 8, 8, 0.5, 0.005), (32, 64, 8, 8, 0.5, 0.001), (32, 128, 2, 2, 0.2, 0.1), (32, 128, 2, 2, 0.2, 0.01), (32, 128, 2, 2, 0.2, 0.005), (32, 128, 2, 2, 0.2, 0.001), (32, 128, 2, 2, 0.5, 0.1), (32, 128, 2, 2, 0.5, 0.01), (32, 128, 2, 2, 0.5, 0.005), (32, 128, 2, 2, 0.5, 0.001), (32, 128, 2, 4, 0.2, 0.1), (32, 128, 2, 4, 0.2, 0.01), (32, 128, 2, 4, 0.2, 0.005), (32, 128, 2, 4, 0.2, 0.001), (32, 128, 2, 4, 0.5, 0.1), (32, 128, 2, 4, 0.5, 0.01), (32, 128, 2, 4, 0.5, 0.005), (32, 128, 2, 4, 0.5, 0.001), (32, 128, 2, 8, 0.2, 0.1), (32, 128, 2, 8, 0.2, 0.01), (32, 128, 2, 8, 0.2, 0.005), (32, 128, 2, 8, 0.2, 0.001), (32, 128, 2, 8, 0.5, 0.1), (32, 128, 2, 8, 0.5, 0.01), (32, 128, 2, 8, 0.5, 0.005), (32, 128, 2, 8, 0.5, 0.001), (32, 128, 4, 2, 0.2, 0.1), (32, 128, 4, 2, 0.2, 0.01), (32, 128, 4, 2, 0.2, 0.005), (32, 128, 4, 2, 0.2, 0.001), (32, 128, 4, 2, 0.5, 0.1), (32, 128, 4, 2, 0.5, 0.01), (32, 128, 4, 2, 0.5, 0.005), (32, 128, 4, 2, 0.5, 0.001), (32, 128, 4, 4, 0.2, 0.1), (32, 128, 4, 4, 0.2, 0.01), (32, 128, 4, 4, 0.2, 0.005), (32, 128, 4, 4, 0.2, 0.001), (32, 128, 4, 4, 0.5, 0.1), (32, 128, 4, 4, 0.5, 0.01), (32, 128, 4, 4, 0.5, 0.005), (32, 128, 4, 4, 0.5, 0.001), (32, 128, 4, 8, 0.2, 0.1), (32, 128, 4, 8, 0.2, 0.01), (32, 128, 4, 8, 0.2, 0.005), (32, 128, 4, 8, 0.2, 0.001), (32, 128, 4, 8, 0.5, 0.1), (32, 128, 4, 8, 0.5, 0.01), (32, 128, 4, 8, 0.5, 0.005), (32, 128, 4, 8, 0.5, 0.001), (32, 128, 6, 2, 0.2, 0.1), (32, 128, 6, 2, 0.2, 0.01), (32, 128, 6, 2, 0.2, 0.005), (32, 128, 6, 2, 0.2, 0.001), (32, 128, 6, 2, 0.5, 0.1), (32, 128, 6, 2, 0.5, 0.01), (32, 128, 6, 2, 0.5, 0.005), (32, 128, 6, 2, 0.5, 0.001), (32, 128, 6, 4, 0.2, 0.1), (32, 128, 6, 4, 0.2, 0.01), (32, 128, 6, 4, 0.2, 0.005), (32, 128, 6, 4, 0.2, 0.001), (32, 128, 6, 4, 0.5, 0.1), (32, 128, 6, 4, 0.5, 0.01), (32, 128, 6, 4, 0.5, 0.005), (32, 128, 6, 4, 0.5, 0.001), (32, 128, 6, 8, 0.2, 0.1), (32, 128, 6, 8, 0.2, 0.01), (32, 128, 6, 8, 0.2, 0.005), (32, 128, 6, 8, 0.2, 0.001), (32, 128, 6, 8, 0.5, 0.1), (32, 128, 6, 8, 0.5, 0.01), (32, 128, 6, 8, 0.5, 0.005), (32, 128, 6, 8, 0.5, 0.001), (32, 128, 8, 2, 0.2, 0.1), (32, 128, 8, 2, 0.2, 0.01), (32, 128, 8, 2, 0.2, 0.005), (32, 128, 8, 2, 0.2, 0.001), (32, 128, 8, 2, 0.5, 0.1), (32, 128, 8, 2, 0.5, 0.01), (32, 128, 8, 2, 0.5, 0.005), (32, 128, 8, 2, 0.5, 0.001), (32, 128, 8, 4, 0.2, 0.1), (32, 128, 8, 4, 0.2, 0.01), (32, 128, 8, 4, 0.2, 0.005), (32, 128, 8, 4, 0.2, 0.001), (32, 128, 8, 4, 0.5, 0.1), (32, 128, 8, 4, 0.5, 0.01), (32, 128, 8, 4, 0.5, 0.005), (32, 128, 8, 4, 0.5, 0.001), (32, 128, 8, 8, 0.2, 0.1), (32, 128, 8, 8, 0.2, 0.01), (32, 128, 8, 8, 0.2, 0.005), (32, 128, 8, 8, 0.2, 0.001), (32, 128, 8, 8, 0.5, 0.1), (32, 128, 8, 8, 0.5, 0.01), (32, 128, 8, 8, 0.5, 0.005), (32, 128, 8, 8, 0.5, 0.001), (32, 256, 2, 2, 0.2, 0.1), (32, 256, 2, 2, 0.2, 0.01), (32, 256, 2, 2, 0.2, 0.005), (32, 256, 2, 2, 0.2, 0.001), (32, 256, 2, 2, 0.5, 0.1), (32, 256, 2, 2, 0.5, 0.01), (32, 256, 2, 2, 0.5, 0.005), (32, 256, 2, 2, 0.5, 0.001), (32, 256, 2, 4, 0.2, 0.1), (32, 256, 2, 4, 0.2, 0.01), (32, 256, 2, 4, 0.2, 0.005), (32, 256, 2, 4, 0.2, 0.001), (32, 256, 2, 4, 0.5, 0.1), (32, 256, 2, 4, 0.5, 0.01), (32, 256, 2, 4, 0.5, 0.005), (32, 256, 2, 4, 0.5, 0.001), (32, 256, 2, 8, 0.2, 0.1), (32, 256, 2, 8, 0.2, 0.01), (32, 256, 2, 8, 0.2, 0.005), (32, 256, 2, 8, 0.2, 0.001), (32, 256, 2, 8, 0.5, 0.1), (32, 256, 2, 8, 0.5, 0.01), (32, 256, 2, 8, 0.5, 0.005), (32, 256, 2, 8, 0.5, 0.001), (32, 256, 4, 2, 0.2, 0.1), (32, 256, 4, 2, 0.2, 0.01), (32, 256, 4, 2, 0.2, 0.005), (32, 256, 4, 2, 0.2, 0.001), (32, 256, 4, 2, 0.5, 0.1), (32, 256, 4, 2, 0.5, 0.01), (32, 256, 4, 2, 0.5, 0.005), (32, 256, 4, 2, 0.5, 0.001), (32, 256, 4, 4, 0.2, 0.1), (32, 256, 4, 4, 0.2, 0.01), (32, 256, 4, 4, 0.2, 0.005), (32, 256, 4, 4, 0.2, 0.001), (32, 256, 4, 4, 0.5, 0.1), (32, 256, 4, 4, 0.5, 0.01), (32, 256, 4, 4, 0.5, 0.005), (32, 256, 4, 4, 0.5, 0.001), (32, 256, 4, 8, 0.2, 0.1), (32, 256, 4, 8, 0.2, 0.01), (32, 256, 4, 8, 0.2, 0.005), (32, 256, 4, 8, 0.2, 0.001), (32, 256, 4, 8, 0.5, 0.1), (32, 256, 4, 8, 0.5, 0.01), (32, 256, 4, 8, 0.5, 0.005), (32, 256, 4, 8, 0.5, 0.001), (32, 256, 6, 2, 0.2, 0.1), (32, 256, 6, 2, 0.2, 0.01), (32, 256, 6, 2, 0.2, 0.005), (32, 256, 6, 2, 0.2, 0.001), (32, 256, 6, 2, 0.5, 0.1), (32, 256, 6, 2, 0.5, 0.01), (32, 256, 6, 2, 0.5, 0.005), (32, 256, 6, 2, 0.5, 0.001), (32, 256, 6, 4, 0.2, 0.1), (32, 256, 6, 4, 0.2, 0.01), (32, 256, 6, 4, 0.2, 0.005), (32, 256, 6, 4, 0.2, 0.001), (32, 256, 6, 4, 0.5, 0.1), (32, 256, 6, 4, 0.5, 0.01), (32, 256, 6, 4, 0.5, 0.005), (32, 256, 6, 4, 0.5, 0.001), (32, 256, 6, 8, 0.2, 0.1), (32, 256, 6, 8, 0.2, 0.01), (32, 256, 6, 8, 0.2, 0.005), (32, 256, 6, 8, 0.2, 0.001), (32, 256, 6, 8, 0.5, 0.1), (32, 256, 6, 8, 0.5, 0.01), (32, 256, 6, 8, 0.5, 0.005), (32, 256, 6, 8, 0.5, 0.001), (32, 256, 8, 2, 0.2, 0.1), (32, 256, 8, 2, 0.2, 0.01), (32, 256, 8, 2, 0.2, 0.005), (32, 256, 8, 2, 0.2, 0.001), (32, 256, 8, 2, 0.5, 0.1), (32, 256, 8, 2, 0.5, 0.01), (32, 256, 8, 2, 0.5, 0.005), (32, 256, 8, 2, 0.5, 0.001), (32, 256, 8, 4, 0.2, 0.1), (32, 256, 8, 4, 0.2, 0.01), (32, 256, 8, 4, 0.2, 0.005), (32, 256, 8, 4, 0.2, 0.001), (32, 256, 8, 4, 0.5, 0.1), (32, 256, 8, 4, 0.5, 0.01), (32, 256, 8, 4, 0.5, 0.005), (32, 256, 8, 4, 0.5, 0.001), (32, 256, 8, 8, 0.2, 0.1), (32, 256, 8, 8, 0.2, 0.01), (32, 256, 8, 8, 0.2, 0.005), (32, 256, 8, 8, 0.2, 0.001), (32, 256, 8, 8, 0.5, 0.1), (32, 256, 8, 8, 0.5, 0.01), (32, 256, 8, 8, 0.5, 0.005), (32, 256, 8, 8, 0.5, 0.001), (64, 8, 2, 2, 0.2, 0.1), (64, 8, 2, 2, 0.2, 0.01), (64, 8, 2, 2, 0.2, 0.005), (64, 8, 2, 2, 0.2, 0.001), (64, 8, 2, 2, 0.5, 0.1), (64, 8, 2, 2, 0.5, 0.01), (64, 8, 2, 2, 0.5, 0.005), (64, 8, 2, 2, 0.5, 0.001), (64, 8, 2, 4, 0.2, 0.1), (64, 8, 2, 4, 0.2, 0.01), (64, 8, 2, 4, 0.2, 0.005), (64, 8, 2, 4, 0.2, 0.001), (64, 8, 2, 4, 0.5, 0.1), (64, 8, 2, 4, 0.5, 0.01), (64, 8, 2, 4, 0.5, 0.005), (64, 8, 2, 4, 0.5, 0.001), (64, 8, 2, 8, 0.2, 0.1), (64, 8, 2, 8, 0.2, 0.01), (64, 8, 2, 8, 0.2, 0.005), (64, 8, 2, 8, 0.2, 0.001), (64, 8, 2, 8, 0.5, 0.1), (64, 8, 2, 8, 0.5, 0.01), (64, 8, 2, 8, 0.5, 0.005), (64, 8, 2, 8, 0.5, 0.001), (64, 8, 4, 2, 0.2, 0.1), (64, 8, 4, 2, 0.2, 0.01), (64, 8, 4, 2, 0.2, 0.005), (64, 8, 4, 2, 0.2, 0.001), (64, 8, 4, 2, 0.5, 0.1), (64, 8, 4, 2, 0.5, 0.01), (64, 8, 4, 2, 0.5, 0.005), (64, 8, 4, 2, 0.5, 0.001), (64, 8, 4, 4, 0.2, 0.1), (64, 8, 4, 4, 0.2, 0.01), (64, 8, 4, 4, 0.2, 0.005), (64, 8, 4, 4, 0.2, 0.001), (64, 8, 4, 4, 0.5, 0.1), (64, 8, 4, 4, 0.5, 0.01), (64, 8, 4, 4, 0.5, 0.005), (64, 8, 4, 4, 0.5, 0.001), (64, 8, 4, 8, 0.2, 0.1), (64, 8, 4, 8, 0.2, 0.01), (64, 8, 4, 8, 0.2, 0.005), (64, 8, 4, 8, 0.2, 0.001), (64, 8, 4, 8, 0.5, 0.1), (64, 8, 4, 8, 0.5, 0.01), (64, 8, 4, 8, 0.5, 0.005), (64, 8, 4, 8, 0.5, 0.001), (64, 8, 6, 2, 0.2, 0.1), (64, 8, 6, 2, 0.2, 0.01), (64, 8, 6, 2, 0.2, 0.005), (64, 8, 6, 2, 0.2, 0.001), (64, 8, 6, 2, 0.5, 0.1), (64, 8, 6, 2, 0.5, 0.01), (64, 8, 6, 2, 0.5, 0.005), (64, 8, 6, 2, 0.5, 0.001), (64, 8, 6, 4, 0.2, 0.1), (64, 8, 6, 4, 0.2, 0.01), (64, 8, 6, 4, 0.2, 0.005), (64, 8, 6, 4, 0.2, 0.001), (64, 8, 6, 4, 0.5, 0.1), (64, 8, 6, 4, 0.5, 0.01), (64, 8, 6, 4, 0.5, 0.005), (64, 8, 6, 4, 0.5, 0.001), (64, 8, 6, 8, 0.2, 0.1), (64, 8, 6, 8, 0.2, 0.01), (64, 8, 6, 8, 0.2, 0.005), (64, 8, 6, 8, 0.2, 0.001), (64, 8, 6, 8, 0.5, 0.1), (64, 8, 6, 8, 0.5, 0.01), (64, 8, 6, 8, 0.5, 0.005), (64, 8, 6, 8, 0.5, 0.001), (64, 8, 8, 2, 0.2, 0.1), (64, 8, 8, 2, 0.2, 0.01), (64, 8, 8, 2, 0.2, 0.005), (64, 8, 8, 2, 0.2, 0.001), (64, 8, 8, 2, 0.5, 0.1), (64, 8, 8, 2, 0.5, 0.01), (64, 8, 8, 2, 0.5, 0.005), (64, 8, 8, 2, 0.5, 0.001), (64, 8, 8, 4, 0.2, 0.1), (64, 8, 8, 4, 0.2, 0.01), (64, 8, 8, 4, 0.2, 0.005), (64, 8, 8, 4, 0.2, 0.001), (64, 8, 8, 4, 0.5, 0.1), (64, 8, 8, 4, 0.5, 0.01), (64, 8, 8, 4, 0.5, 0.005), (64, 8, 8, 4, 0.5, 0.001), (64, 8, 8, 8, 0.2, 0.1), (64, 8, 8, 8, 0.2, 0.01), (64, 8, 8, 8, 0.2, 0.005), (64, 8, 8, 8, 0.2, 0.001), (64, 8, 8, 8, 0.5, 0.1), (64, 8, 8, 8, 0.5, 0.01), (64, 8, 8, 8, 0.5, 0.005), (64, 8, 8, 8, 0.5, 0.001), (64, 32, 2, 2, 0.2, 0.1), (64, 32, 2, 2, 0.2, 0.01), (64, 32, 2, 2, 0.2, 0.005), (64, 32, 2, 2, 0.2, 0.001), (64, 32, 2, 2, 0.5, 0.1), (64, 32, 2, 2, 0.5, 0.01), (64, 32, 2, 2, 0.5, 0.005), (64, 32, 2, 2, 0.5, 0.001), (64, 32, 2, 4, 0.2, 0.1), (64, 32, 2, 4, 0.2, 0.01), (64, 32, 2, 4, 0.2, 0.005), (64, 32, 2, 4, 0.2, 0.001), (64, 32, 2, 4, 0.5, 0.1), (64, 32, 2, 4, 0.5, 0.01), (64, 32, 2, 4, 0.5, 0.005), (64, 32, 2, 4, 0.5, 0.001), (64, 32, 2, 8, 0.2, 0.1), (64, 32, 2, 8, 0.2, 0.01), (64, 32, 2, 8, 0.2, 0.005), (64, 32, 2, 8, 0.2, 0.001), (64, 32, 2, 8, 0.5, 0.1), (64, 32, 2, 8, 0.5, 0.01), (64, 32, 2, 8, 0.5, 0.005), (64, 32, 2, 8, 0.5, 0.001), (64, 32, 4, 2, 0.2, 0.1), (64, 32, 4, 2, 0.2, 0.01), (64, 32, 4, 2, 0.2, 0.005), (64, 32, 4, 2, 0.2, 0.001), (64, 32, 4, 2, 0.5, 0.1), (64, 32, 4, 2, 0.5, 0.01), (64, 32, 4, 2, 0.5, 0.005), (64, 32, 4, 2, 0.5, 0.001), (64, 32, 4, 4, 0.2, 0.1), (64, 32, 4, 4, 0.2, 0.01), (64, 32, 4, 4, 0.2, 0.005), (64, 32, 4, 4, 0.2, 0.001), (64, 32, 4, 4, 0.5, 0.1), (64, 32, 4, 4, 0.5, 0.01), (64, 32, 4, 4, 0.5, 0.005), (64, 32, 4, 4, 0.5, 0.001), (64, 32, 4, 8, 0.2, 0.1), (64, 32, 4, 8, 0.2, 0.01), (64, 32, 4, 8, 0.2, 0.005), (64, 32, 4, 8, 0.2, 0.001), (64, 32, 4, 8, 0.5, 0.1), (64, 32, 4, 8, 0.5, 0.01), (64, 32, 4, 8, 0.5, 0.005), (64, 32, 4, 8, 0.5, 0.001), (64, 32, 6, 2, 0.2, 0.1), (64, 32, 6, 2, 0.2, 0.01), (64, 32, 6, 2, 0.2, 0.005), (64, 32, 6, 2, 0.2, 0.001), (64, 32, 6, 2, 0.5, 0.1), (64, 32, 6, 2, 0.5, 0.01), (64, 32, 6, 2, 0.5, 0.005), (64, 32, 6, 2, 0.5, 0.001), (64, 32, 6, 4, 0.2, 0.1), (64, 32, 6, 4, 0.2, 0.01), (64, 32, 6, 4, 0.2, 0.005), (64, 32, 6, 4, 0.2, 0.001), (64, 32, 6, 4, 0.5, 0.1), (64, 32, 6, 4, 0.5, 0.01), (64, 32, 6, 4, 0.5, 0.005), (64, 32, 6, 4, 0.5, 0.001), (64, 32, 6, 8, 0.2, 0.1), (64, 32, 6, 8, 0.2, 0.01), (64, 32, 6, 8, 0.2, 0.005), (64, 32, 6, 8, 0.2, 0.001), (64, 32, 6, 8, 0.5, 0.1), (64, 32, 6, 8, 0.5, 0.01), (64, 32, 6, 8, 0.5, 0.005), (64, 32, 6, 8, 0.5, 0.001), (64, 32, 8, 2, 0.2, 0.1), (64, 32, 8, 2, 0.2, 0.01), (64, 32, 8, 2, 0.2, 0.005), (64, 32, 8, 2, 0.2, 0.001), (64, 32, 8, 2, 0.5, 0.1), (64, 32, 8, 2, 0.5, 0.01), (64, 32, 8, 2, 0.5, 0.005), (64, 32, 8, 2, 0.5, 0.001), (64, 32, 8, 4, 0.2, 0.1), (64, 32, 8, 4, 0.2, 0.01), (64, 32, 8, 4, 0.2, 0.005), (64, 32, 8, 4, 0.2, 0.001), (64, 32, 8, 4, 0.5, 0.1), (64, 32, 8, 4, 0.5, 0.01), (64, 32, 8, 4, 0.5, 0.005), (64, 32, 8, 4, 0.5, 0.001), (64, 32, 8, 8, 0.2, 0.1), (64, 32, 8, 8, 0.2, 0.01), (64, 32, 8, 8, 0.2, 0.005), (64, 32, 8, 8, 0.2, 0.001), (64, 32, 8, 8, 0.5, 0.1), (64, 32, 8, 8, 0.5, 0.01), (64, 32, 8, 8, 0.5, 0.005), (64, 32, 8, 8, 0.5, 0.001), (64, 64, 2, 2, 0.2, 0.1), (64, 64, 2, 2, 0.2, 0.01), (64, 64, 2, 2, 0.2, 0.005), (64, 64, 2, 2, 0.2, 0.001), (64, 64, 2, 2, 0.5, 0.1), (64, 64, 2, 2, 0.5, 0.01), (64, 64, 2, 2, 0.5, 0.005), (64, 64, 2, 2, 0.5, 0.001), (64, 64, 2, 4, 0.2, 0.1), (64, 64, 2, 4, 0.2, 0.01), (64, 64, 2, 4, 0.2, 0.005), (64, 64, 2, 4, 0.2, 0.001), (64, 64, 2, 4, 0.5, 0.1), (64, 64, 2, 4, 0.5, 0.01), (64, 64, 2, 4, 0.5, 0.005), (64, 64, 2, 4, 0.5, 0.001), (64, 64, 2, 8, 0.2, 0.1), (64, 64, 2, 8, 0.2, 0.01), (64, 64, 2, 8, 0.2, 0.005), (64, 64, 2, 8, 0.2, 0.001), (64, 64, 2, 8, 0.5, 0.1), (64, 64, 2, 8, 0.5, 0.01), (64, 64, 2, 8, 0.5, 0.005), (64, 64, 2, 8, 0.5, 0.001), (64, 64, 4, 2, 0.2, 0.1), (64, 64, 4, 2, 0.2, 0.01), (64, 64, 4, 2, 0.2, 0.005), (64, 64, 4, 2, 0.2, 0.001), (64, 64, 4, 2, 0.5, 0.1), (64, 64, 4, 2, 0.5, 0.01), (64, 64, 4, 2, 0.5, 0.005), (64, 64, 4, 2, 0.5, 0.001), (64, 64, 4, 4, 0.2, 0.1), (64, 64, 4, 4, 0.2, 0.01), (64, 64, 4, 4, 0.2, 0.005), (64, 64, 4, 4, 0.2, 0.001), (64, 64, 4, 4, 0.5, 0.1), (64, 64, 4, 4, 0.5, 0.01), (64, 64, 4, 4, 0.5, 0.005), (64, 64, 4, 4, 0.5, 0.001), (64, 64, 4, 8, 0.2, 0.1), (64, 64, 4, 8, 0.2, 0.01), (64, 64, 4, 8, 0.2, 0.005), (64, 64, 4, 8, 0.2, 0.001), (64, 64, 4, 8, 0.5, 0.1), (64, 64, 4, 8, 0.5, 0.01), (64, 64, 4, 8, 0.5, 0.005), (64, 64, 4, 8, 0.5, 0.001), (64, 64, 6, 2, 0.2, 0.1), (64, 64, 6, 2, 0.2, 0.01), (64, 64, 6, 2, 0.2, 0.005), (64, 64, 6, 2, 0.2, 0.001), (64, 64, 6, 2, 0.5, 0.1), (64, 64, 6, 2, 0.5, 0.01), (64, 64, 6, 2, 0.5, 0.005), (64, 64, 6, 2, 0.5, 0.001), (64, 64, 6, 4, 0.2, 0.1), (64, 64, 6, 4, 0.2, 0.01), (64, 64, 6, 4, 0.2, 0.005), (64, 64, 6, 4, 0.2, 0.001), (64, 64, 6, 4, 0.5, 0.1), (64, 64, 6, 4, 0.5, 0.01), (64, 64, 6, 4, 0.5, 0.005), (64, 64, 6, 4, 0.5, 0.001), (64, 64, 6, 8, 0.2, 0.1), (64, 64, 6, 8, 0.2, 0.01), (64, 64, 6, 8, 0.2, 0.005), (64, 64, 6, 8, 0.2, 0.001), (64, 64, 6, 8, 0.5, 0.1), (64, 64, 6, 8, 0.5, 0.01), (64, 64, 6, 8, 0.5, 0.005), (64, 64, 6, 8, 0.5, 0.001), (64, 64, 8, 2, 0.2, 0.1), (64, 64, 8, 2, 0.2, 0.01), (64, 64, 8, 2, 0.2, 0.005), (64, 64, 8, 2, 0.2, 0.001), (64, 64, 8, 2, 0.5, 0.1), (64, 64, 8, 2, 0.5, 0.01), (64, 64, 8, 2, 0.5, 0.005), (64, 64, 8, 2, 0.5, 0.001), (64, 64, 8, 4, 0.2, 0.1), (64, 64, 8, 4, 0.2, 0.01), (64, 64, 8, 4, 0.2, 0.005), (64, 64, 8, 4, 0.2, 0.001), (64, 64, 8, 4, 0.5, 0.1), (64, 64, 8, 4, 0.5, 0.01), (64, 64, 8, 4, 0.5, 0.005), (64, 64, 8, 4, 0.5, 0.001), (64, 64, 8, 8, 0.2, 0.1), (64, 64, 8, 8, 0.2, 0.01), (64, 64, 8, 8, 0.2, 0.005), (64, 64, 8, 8, 0.2, 0.001), (64, 64, 8, 8, 0.5, 0.1), (64, 64, 8, 8, 0.5, 0.01), (64, 64, 8, 8, 0.5, 0.005), (64, 64, 8, 8, 0.5, 0.001), (64, 128, 2, 2, 0.2, 0.1), (64, 128, 2, 2, 0.2, 0.01), (64, 128, 2, 2, 0.2, 0.005), (64, 128, 2, 2, 0.2, 0.001), (64, 128, 2, 2, 0.5, 0.1), (64, 128, 2, 2, 0.5, 0.01), (64, 128, 2, 2, 0.5, 0.005), (64, 128, 2, 2, 0.5, 0.001), (64, 128, 2, 4, 0.2, 0.1), (64, 128, 2, 4, 0.2, 0.01), (64, 128, 2, 4, 0.2, 0.005), (64, 128, 2, 4, 0.2, 0.001), (64, 128, 2, 4, 0.5, 0.1), (64, 128, 2, 4, 0.5, 0.01), (64, 128, 2, 4, 0.5, 0.005), (64, 128, 2, 4, 0.5, 0.001), (64, 128, 2, 8, 0.2, 0.1), (64, 128, 2, 8, 0.2, 0.01), (64, 128, 2, 8, 0.2, 0.005), (64, 128, 2, 8, 0.2, 0.001), (64, 128, 2, 8, 0.5, 0.1), (64, 128, 2, 8, 0.5, 0.01), (64, 128, 2, 8, 0.5, 0.005), (64, 128, 2, 8, 0.5, 0.001), (64, 128, 4, 2, 0.2, 0.1), (64, 128, 4, 2, 0.2, 0.01), (64, 128, 4, 2, 0.2, 0.005), (64, 128, 4, 2, 0.2, 0.001), (64, 128, 4, 2, 0.5, 0.1), (64, 128, 4, 2, 0.5, 0.01), (64, 128, 4, 2, 0.5, 0.005), (64, 128, 4, 2, 0.5, 0.001), (64, 128, 4, 4, 0.2, 0.1), (64, 128, 4, 4, 0.2, 0.01), (64, 128, 4, 4, 0.2, 0.005), (64, 128, 4, 4, 0.2, 0.001), (64, 128, 4, 4, 0.5, 0.1), (64, 128, 4, 4, 0.5, 0.01), (64, 128, 4, 4, 0.5, 0.005), (64, 128, 4, 4, 0.5, 0.001), (64, 128, 4, 8, 0.2, 0.1), (64, 128, 4, 8, 0.2, 0.01), (64, 128, 4, 8, 0.2, 0.005), (64, 128, 4, 8, 0.2, 0.001), (64, 128, 4, 8, 0.5, 0.1), (64, 128, 4, 8, 0.5, 0.01), (64, 128, 4, 8, 0.5, 0.005), (64, 128, 4, 8, 0.5, 0.001), (64, 128, 6, 2, 0.2, 0.1), (64, 128, 6, 2, 0.2, 0.01), (64, 128, 6, 2, 0.2, 0.005), (64, 128, 6, 2, 0.2, 0.001), (64, 128, 6, 2, 0.5, 0.1), (64, 128, 6, 2, 0.5, 0.01), (64, 128, 6, 2, 0.5, 0.005), (64, 128, 6, 2, 0.5, 0.001), (64, 128, 6, 4, 0.2, 0.1), (64, 128, 6, 4, 0.2, 0.01), (64, 128, 6, 4, 0.2, 0.005), (64, 128, 6, 4, 0.2, 0.001), (64, 128, 6, 4, 0.5, 0.1), (64, 128, 6, 4, 0.5, 0.01), (64, 128, 6, 4, 0.5, 0.005), (64, 128, 6, 4, 0.5, 0.001), (64, 128, 6, 8, 0.2, 0.1), (64, 128, 6, 8, 0.2, 0.01), (64, 128, 6, 8, 0.2, 0.005), (64, 128, 6, 8, 0.2, 0.001), (64, 128, 6, 8, 0.5, 0.1), (64, 128, 6, 8, 0.5, 0.01), (64, 128, 6, 8, 0.5, 0.005), (64, 128, 6, 8, 0.5, 0.001), (64, 128, 8, 2, 0.2, 0.1), (64, 128, 8, 2, 0.2, 0.01), (64, 128, 8, 2, 0.2, 0.005), (64, 128, 8, 2, 0.2, 0.001), (64, 128, 8, 2, 0.5, 0.1), (64, 128, 8, 2, 0.5, 0.01), (64, 128, 8, 2, 0.5, 0.005), (64, 128, 8, 2, 0.5, 0.001), (64, 128, 8, 4, 0.2, 0.1), (64, 128, 8, 4, 0.2, 0.01), (64, 128, 8, 4, 0.2, 0.005), (64, 128, 8, 4, 0.2, 0.001), (64, 128, 8, 4, 0.5, 0.1), (64, 128, 8, 4, 0.5, 0.01), (64, 128, 8, 4, 0.5, 0.005), (64, 128, 8, 4, 0.5, 0.001), (64, 128, 8, 8, 0.2, 0.1), (64, 128, 8, 8, 0.2, 0.01), (64, 128, 8, 8, 0.2, 0.005), (64, 128, 8, 8, 0.2, 0.001), (64, 128, 8, 8, 0.5, 0.1), (64, 128, 8, 8, 0.5, 0.01), (64, 128, 8, 8, 0.5, 0.005), (64, 128, 8, 8, 0.5, 0.001), (64, 256, 2, 2, 0.2, 0.1), (64, 256, 2, 2, 0.2, 0.01), (64, 256, 2, 2, 0.2, 0.005), (64, 256, 2, 2, 0.2, 0.001), (64, 256, 2, 2, 0.5, 0.1), (64, 256, 2, 2, 0.5, 0.01), (64, 256, 2, 2, 0.5, 0.005), (64, 256, 2, 2, 0.5, 0.001), (64, 256, 2, 4, 0.2, 0.1), (64, 256, 2, 4, 0.2, 0.01), (64, 256, 2, 4, 0.2, 0.005), (64, 256, 2, 4, 0.2, 0.001), (64, 256, 2, 4, 0.5, 0.1), (64, 256, 2, 4, 0.5, 0.01), (64, 256, 2, 4, 0.5, 0.005), (64, 256, 2, 4, 0.5, 0.001), (64, 256, 2, 8, 0.2, 0.1), (64, 256, 2, 8, 0.2, 0.01), (64, 256, 2, 8, 0.2, 0.005), (64, 256, 2, 8, 0.2, 0.001), (64, 256, 2, 8, 0.5, 0.1), (64, 256, 2, 8, 0.5, 0.01), (64, 256, 2, 8, 0.5, 0.005), (64, 256, 2, 8, 0.5, 0.001), (64, 256, 4, 2, 0.2, 0.1), (64, 256, 4, 2, 0.2, 0.01), (64, 256, 4, 2, 0.2, 0.005), (64, 256, 4, 2, 0.2, 0.001), (64, 256, 4, 2, 0.5, 0.1), (64, 256, 4, 2, 0.5, 0.01), (64, 256, 4, 2, 0.5, 0.005), (64, 256, 4, 2, 0.5, 0.001), (64, 256, 4, 4, 0.2, 0.1), (64, 256, 4, 4, 0.2, 0.01), (64, 256, 4, 4, 0.2, 0.005), (64, 256, 4, 4, 0.2, 0.001), (64, 256, 4, 4, 0.5, 0.1), (64, 256, 4, 4, 0.5, 0.01), (64, 256, 4, 4, 0.5, 0.005), (64, 256, 4, 4, 0.5, 0.001), (64, 256, 4, 8, 0.2, 0.1), (64, 256, 4, 8, 0.2, 0.01), (64, 256, 4, 8, 0.2, 0.005), (64, 256, 4, 8, 0.2, 0.001), (64, 256, 4, 8, 0.5, 0.1), (64, 256, 4, 8, 0.5, 0.01), (64, 256, 4, 8, 0.5, 0.005), (64, 256, 4, 8, 0.5, 0.001), (64, 256, 6, 2, 0.2, 0.1), (64, 256, 6, 2, 0.2, 0.01), (64, 256, 6, 2, 0.2, 0.005), (64, 256, 6, 2, 0.2, 0.001), (64, 256, 6, 2, 0.5, 0.1), (64, 256, 6, 2, 0.5, 0.01), (64, 256, 6, 2, 0.5, 0.005), (64, 256, 6, 2, 0.5, 0.001), (64, 256, 6, 4, 0.2, 0.1), (64, 256, 6, 4, 0.2, 0.01), (64, 256, 6, 4, 0.2, 0.005), (64, 256, 6, 4, 0.2, 0.001), (64, 256, 6, 4, 0.5, 0.1), (64, 256, 6, 4, 0.5, 0.01), (64, 256, 6, 4, 0.5, 0.005), (64, 256, 6, 4, 0.5, 0.001), (64, 256, 6, 8, 0.2, 0.1), (64, 256, 6, 8, 0.2, 0.01), (64, 256, 6, 8, 0.2, 0.005), (64, 256, 6, 8, 0.2, 0.001), (64, 256, 6, 8, 0.5, 0.1), (64, 256, 6, 8, 0.5, 0.01), (64, 256, 6, 8, 0.5, 0.005), (64, 256, 6, 8, 0.5, 0.001), (64, 256, 8, 2, 0.2, 0.1), (64, 256, 8, 2, 0.2, 0.01), (64, 256, 8, 2, 0.2, 0.005), (64, 256, 8, 2, 0.2, 0.001), (64, 256, 8, 2, 0.5, 0.1), (64, 256, 8, 2, 0.5, 0.01), (64, 256, 8, 2, 0.5, 0.005), (64, 256, 8, 2, 0.5, 0.001), (64, 256, 8, 4, 0.2, 0.1), (64, 256, 8, 4, 0.2, 0.01), (64, 256, 8, 4, 0.2, 0.005), (64, 256, 8, 4, 0.2, 0.001), (64, 256, 8, 4, 0.5, 0.1), (64, 256, 8, 4, 0.5, 0.01), (64, 256, 8, 4, 0.5, 0.005), (64, 256, 8, 4, 0.5, 0.001), (64, 256, 8, 8, 0.2, 0.1), (64, 256, 8, 8, 0.2, 0.01), (64, 256, 8, 8, 0.2, 0.005), (64, 256, 8, 8, 0.2, 0.001), (64, 256, 8, 8, 0.5, 0.1), (64, 256, 8, 8, 0.5, 0.01), (64, 256, 8, 8, 0.5, 0.005), (64, 256, 8, 8, 0.5, 0.001), (128, 8, 2, 2, 0.2, 0.1), (128, 8, 2, 2, 0.2, 0.01), (128, 8, 2, 2, 0.2, 0.005), (128, 8, 2, 2, 0.2, 0.001), (128, 8, 2, 2, 0.5, 0.1), (128, 8, 2, 2, 0.5, 0.01), (128, 8, 2, 2, 0.5, 0.005), (128, 8, 2, 2, 0.5, 0.001), (128, 8, 2, 4, 0.2, 0.1), (128, 8, 2, 4, 0.2, 0.01), (128, 8, 2, 4, 0.2, 0.005), (128, 8, 2, 4, 0.2, 0.001), (128, 8, 2, 4, 0.5, 0.1), (128, 8, 2, 4, 0.5, 0.01), (128, 8, 2, 4, 0.5, 0.005), (128, 8, 2, 4, 0.5, 0.001), (128, 8, 2, 8, 0.2, 0.1), (128, 8, 2, 8, 0.2, 0.01), (128, 8, 2, 8, 0.2, 0.005), (128, 8, 2, 8, 0.2, 0.001), (128, 8, 2, 8, 0.5, 0.1), (128, 8, 2, 8, 0.5, 0.01), (128, 8, 2, 8, 0.5, 0.005), (128, 8, 2, 8, 0.5, 0.001), (128, 8, 4, 2, 0.2, 0.1), (128, 8, 4, 2, 0.2, 0.01), (128, 8, 4, 2, 0.2, 0.005), (128, 8, 4, 2, 0.2, 0.001), (128, 8, 4, 2, 0.5, 0.1), (128, 8, 4, 2, 0.5, 0.01), (128, 8, 4, 2, 0.5, 0.005), (128, 8, 4, 2, 0.5, 0.001), (128, 8, 4, 4, 0.2, 0.1), (128, 8, 4, 4, 0.2, 0.01), (128, 8, 4, 4, 0.2, 0.005), (128, 8, 4, 4, 0.2, 0.001), (128, 8, 4, 4, 0.5, 0.1), (128, 8, 4, 4, 0.5, 0.01), (128, 8, 4, 4, 0.5, 0.005), (128, 8, 4, 4, 0.5, 0.001), (128, 8, 4, 8, 0.2, 0.1), (128, 8, 4, 8, 0.2, 0.01), (128, 8, 4, 8, 0.2, 0.005), (128, 8, 4, 8, 0.2, 0.001), (128, 8, 4, 8, 0.5, 0.1), (128, 8, 4, 8, 0.5, 0.01), (128, 8, 4, 8, 0.5, 0.005), (128, 8, 4, 8, 0.5, 0.001), (128, 8, 6, 2, 0.2, 0.1), (128, 8, 6, 2, 0.2, 0.01), (128, 8, 6, 2, 0.2, 0.005), (128, 8, 6, 2, 0.2, 0.001), (128, 8, 6, 2, 0.5, 0.1), (128, 8, 6, 2, 0.5, 0.01), (128, 8, 6, 2, 0.5, 0.005), (128, 8, 6, 2, 0.5, 0.001), (128, 8, 6, 4, 0.2, 0.1), (128, 8, 6, 4, 0.2, 0.01), (128, 8, 6, 4, 0.2, 0.005), (128, 8, 6, 4, 0.2, 0.001), (128, 8, 6, 4, 0.5, 0.1), (128, 8, 6, 4, 0.5, 0.01), (128, 8, 6, 4, 0.5, 0.005), (128, 8, 6, 4, 0.5, 0.001), (128, 8, 6, 8, 0.2, 0.1), (128, 8, 6, 8, 0.2, 0.01), (128, 8, 6, 8, 0.2, 0.005), (128, 8, 6, 8, 0.2, 0.001), (128, 8, 6, 8, 0.5, 0.1), (128, 8, 6, 8, 0.5, 0.01), (128, 8, 6, 8, 0.5, 0.005), (128, 8, 6, 8, 0.5, 0.001), (128, 8, 8, 2, 0.2, 0.1), (128, 8, 8, 2, 0.2, 0.01), (128, 8, 8, 2, 0.2, 0.005), (128, 8, 8, 2, 0.2, 0.001), (128, 8, 8, 2, 0.5, 0.1), (128, 8, 8, 2, 0.5, 0.01), (128, 8, 8, 2, 0.5, 0.005), (128, 8, 8, 2, 0.5, 0.001), (128, 8, 8, 4, 0.2, 0.1), (128, 8, 8, 4, 0.2, 0.01), (128, 8, 8, 4, 0.2, 0.005), (128, 8, 8, 4, 0.2, 0.001), (128, 8, 8, 4, 0.5, 0.1), (128, 8, 8, 4, 0.5, 0.01), (128, 8, 8, 4, 0.5, 0.005), (128, 8, 8, 4, 0.5, 0.001), (128, 8, 8, 8, 0.2, 0.1), (128, 8, 8, 8, 0.2, 0.01), (128, 8, 8, 8, 0.2, 0.005), (128, 8, 8, 8, 0.2, 0.001), (128, 8, 8, 8, 0.5, 0.1), (128, 8, 8, 8, 0.5, 0.01), (128, 8, 8, 8, 0.5, 0.005), (128, 8, 8, 8, 0.5, 0.001), (128, 32, 2, 2, 0.2, 0.1), (128, 32, 2, 2, 0.2, 0.01), (128, 32, 2, 2, 0.2, 0.005), (128, 32, 2, 2, 0.2, 0.001), (128, 32, 2, 2, 0.5, 0.1), (128, 32, 2, 2, 0.5, 0.01), (128, 32, 2, 2, 0.5, 0.005), (128, 32, 2, 2, 0.5, 0.001), (128, 32, 2, 4, 0.2, 0.1), (128, 32, 2, 4, 0.2, 0.01), (128, 32, 2, 4, 0.2, 0.005), (128, 32, 2, 4, 0.2, 0.001), (128, 32, 2, 4, 0.5, 0.1), (128, 32, 2, 4, 0.5, 0.01), (128, 32, 2, 4, 0.5, 0.005), (128, 32, 2, 4, 0.5, 0.001), (128, 32, 2, 8, 0.2, 0.1), (128, 32, 2, 8, 0.2, 0.01), (128, 32, 2, 8, 0.2, 0.005), (128, 32, 2, 8, 0.2, 0.001), (128, 32, 2, 8, 0.5, 0.1), (128, 32, 2, 8, 0.5, 0.01), (128, 32, 2, 8, 0.5, 0.005), (128, 32, 2, 8, 0.5, 0.001), (128, 32, 4, 2, 0.2, 0.1), (128, 32, 4, 2, 0.2, 0.01), (128, 32, 4, 2, 0.2, 0.005), (128, 32, 4, 2, 0.2, 0.001), (128, 32, 4, 2, 0.5, 0.1), (128, 32, 4, 2, 0.5, 0.01), (128, 32, 4, 2, 0.5, 0.005), (128, 32, 4, 2, 0.5, 0.001), (128, 32, 4, 4, 0.2, 0.1), (128, 32, 4, 4, 0.2, 0.01), (128, 32, 4, 4, 0.2, 0.005), (128, 32, 4, 4, 0.2, 0.001), (128, 32, 4, 4, 0.5, 0.1), (128, 32, 4, 4, 0.5, 0.01), (128, 32, 4, 4, 0.5, 0.005), (128, 32, 4, 4, 0.5, 0.001), (128, 32, 4, 8, 0.2, 0.1), (128, 32, 4, 8, 0.2, 0.01), (128, 32, 4, 8, 0.2, 0.005), (128, 32, 4, 8, 0.2, 0.001), (128, 32, 4, 8, 0.5, 0.1), (128, 32, 4, 8, 0.5, 0.01), (128, 32, 4, 8, 0.5, 0.005), (128, 32, 4, 8, 0.5, 0.001), (128, 32, 6, 2, 0.2, 0.1), (128, 32, 6, 2, 0.2, 0.01), (128, 32, 6, 2, 0.2, 0.005), (128, 32, 6, 2, 0.2, 0.001), (128, 32, 6, 2, 0.5, 0.1), (128, 32, 6, 2, 0.5, 0.01), (128, 32, 6, 2, 0.5, 0.005), (128, 32, 6, 2, 0.5, 0.001), (128, 32, 6, 4, 0.2, 0.1), (128, 32, 6, 4, 0.2, 0.01), (128, 32, 6, 4, 0.2, 0.005), (128, 32, 6, 4, 0.2, 0.001), (128, 32, 6, 4, 0.5, 0.1), (128, 32, 6, 4, 0.5, 0.01), (128, 32, 6, 4, 0.5, 0.005), (128, 32, 6, 4, 0.5, 0.001), (128, 32, 6, 8, 0.2, 0.1), (128, 32, 6, 8, 0.2, 0.01), (128, 32, 6, 8, 0.2, 0.005), (128, 32, 6, 8, 0.2, 0.001), (128, 32, 6, 8, 0.5, 0.1), (128, 32, 6, 8, 0.5, 0.01), (128, 32, 6, 8, 0.5, 0.005), (128, 32, 6, 8, 0.5, 0.001), (128, 32, 8, 2, 0.2, 0.1), (128, 32, 8, 2, 0.2, 0.01), (128, 32, 8, 2, 0.2, 0.005), (128, 32, 8, 2, 0.2, 0.001), (128, 32, 8, 2, 0.5, 0.1), (128, 32, 8, 2, 0.5, 0.01), (128, 32, 8, 2, 0.5, 0.005), (128, 32, 8, 2, 0.5, 0.001), (128, 32, 8, 4, 0.2, 0.1), (128, 32, 8, 4, 0.2, 0.01), (128, 32, 8, 4, 0.2, 0.005), (128, 32, 8, 4, 0.2, 0.001), (128, 32, 8, 4, 0.5, 0.1), (128, 32, 8, 4, 0.5, 0.01), (128, 32, 8, 4, 0.5, 0.005), (128, 32, 8, 4, 0.5, 0.001), (128, 32, 8, 8, 0.2, 0.1), (128, 32, 8, 8, 0.2, 0.01), (128, 32, 8, 8, 0.2, 0.005), (128, 32, 8, 8, 0.2, 0.001), (128, 32, 8, 8, 0.5, 0.1), (128, 32, 8, 8, 0.5, 0.01), (128, 32, 8, 8, 0.5, 0.005), (128, 32, 8, 8, 0.5, 0.001), (128, 64, 2, 2, 0.2, 0.1), (128, 64, 2, 2, 0.2, 0.01), (128, 64, 2, 2, 0.2, 0.005), (128, 64, 2, 2, 0.2, 0.001), (128, 64, 2, 2, 0.5, 0.1), (128, 64, 2, 2, 0.5, 0.01), (128, 64, 2, 2, 0.5, 0.005), (128, 64, 2, 2, 0.5, 0.001), (128, 64, 2, 4, 0.2, 0.1), (128, 64, 2, 4, 0.2, 0.01), (128, 64, 2, 4, 0.2, 0.005), (128, 64, 2, 4, 0.2, 0.001), (128, 64, 2, 4, 0.5, 0.1), (128, 64, 2, 4, 0.5, 0.01), (128, 64, 2, 4, 0.5, 0.005), (128, 64, 2, 4, 0.5, 0.001), (128, 64, 2, 8, 0.2, 0.1), (128, 64, 2, 8, 0.2, 0.01), (128, 64, 2, 8, 0.2, 0.005), (128, 64, 2, 8, 0.2, 0.001), (128, 64, 2, 8, 0.5, 0.1), (128, 64, 2, 8, 0.5, 0.01), (128, 64, 2, 8, 0.5, 0.005), (128, 64, 2, 8, 0.5, 0.001), (128, 64, 4, 2, 0.2, 0.1), (128, 64, 4, 2, 0.2, 0.01), (128, 64, 4, 2, 0.2, 0.005), (128, 64, 4, 2, 0.2, 0.001), (128, 64, 4, 2, 0.5, 0.1), (128, 64, 4, 2, 0.5, 0.01), (128, 64, 4, 2, 0.5, 0.005), (128, 64, 4, 2, 0.5, 0.001), (128, 64, 4, 4, 0.2, 0.1), (128, 64, 4, 4, 0.2, 0.01), (128, 64, 4, 4, 0.2, 0.005), (128, 64, 4, 4, 0.2, 0.001), (128, 64, 4, 4, 0.5, 0.1), (128, 64, 4, 4, 0.5, 0.01), (128, 64, 4, 4, 0.5, 0.005), (128, 64, 4, 4, 0.5, 0.001), (128, 64, 4, 8, 0.2, 0.1), (128, 64, 4, 8, 0.2, 0.01), (128, 64, 4, 8, 0.2, 0.005), (128, 64, 4, 8, 0.2, 0.001), (128, 64, 4, 8, 0.5, 0.1), (128, 64, 4, 8, 0.5, 0.01), (128, 64, 4, 8, 0.5, 0.005), (128, 64, 4, 8, 0.5, 0.001), (128, 64, 6, 2, 0.2, 0.1), (128, 64, 6, 2, 0.2, 0.01), (128, 64, 6, 2, 0.2, 0.005), (128, 64, 6, 2, 0.2, 0.001), (128, 64, 6, 2, 0.5, 0.1), (128, 64, 6, 2, 0.5, 0.01), (128, 64, 6, 2, 0.5, 0.005), (128, 64, 6, 2, 0.5, 0.001), (128, 64, 6, 4, 0.2, 0.1), (128, 64, 6, 4, 0.2, 0.01), (128, 64, 6, 4, 0.2, 0.005), (128, 64, 6, 4, 0.2, 0.001), (128, 64, 6, 4, 0.5, 0.1), (128, 64, 6, 4, 0.5, 0.01), (128, 64, 6, 4, 0.5, 0.005), (128, 64, 6, 4, 0.5, 0.001), (128, 64, 6, 8, 0.2, 0.1), (128, 64, 6, 8, 0.2, 0.01), (128, 64, 6, 8, 0.2, 0.005), (128, 64, 6, 8, 0.2, 0.001), (128, 64, 6, 8, 0.5, 0.1), (128, 64, 6, 8, 0.5, 0.01), (128, 64, 6, 8, 0.5, 0.005), (128, 64, 6, 8, 0.5, 0.001), (128, 64, 8, 2, 0.2, 0.1), (128, 64, 8, 2, 0.2, 0.01), (128, 64, 8, 2, 0.2, 0.005), (128, 64, 8, 2, 0.2, 0.001), (128, 64, 8, 2, 0.5, 0.1), (128, 64, 8, 2, 0.5, 0.01), (128, 64, 8, 2, 0.5, 0.005), (128, 64, 8, 2, 0.5, 0.001), (128, 64, 8, 4, 0.2, 0.1), (128, 64, 8, 4, 0.2, 0.01), (128, 64, 8, 4, 0.2, 0.005), (128, 64, 8, 4, 0.2, 0.001), (128, 64, 8, 4, 0.5, 0.1), (128, 64, 8, 4, 0.5, 0.01), (128, 64, 8, 4, 0.5, 0.005), (128, 64, 8, 4, 0.5, 0.001), (128, 64, 8, 8, 0.2, 0.1), (128, 64, 8, 8, 0.2, 0.01), (128, 64, 8, 8, 0.2, 0.005), (128, 64, 8, 8, 0.2, 0.001), (128, 64, 8, 8, 0.5, 0.1), (128, 64, 8, 8, 0.5, 0.01), (128, 64, 8, 8, 0.5, 0.005), (128, 64, 8, 8, 0.5, 0.001), (128, 128, 2, 2, 0.2, 0.1), (128, 128, 2, 2, 0.2, 0.01), (128, 128, 2, 2, 0.2, 0.005), (128, 128, 2, 2, 0.2, 0.001), (128, 128, 2, 2, 0.5, 0.1), (128, 128, 2, 2, 0.5, 0.01), (128, 128, 2, 2, 0.5, 0.005), (128, 128, 2, 2, 0.5, 0.001), (128, 128, 2, 4, 0.2, 0.1), (128, 128, 2, 4, 0.2, 0.01), (128, 128, 2, 4, 0.2, 0.005), (128, 128, 2, 4, 0.2, 0.001), (128, 128, 2, 4, 0.5, 0.1), (128, 128, 2, 4, 0.5, 0.01), (128, 128, 2, 4, 0.5, 0.005), (128, 128, 2, 4, 0.5, 0.001), (128, 128, 2, 8, 0.2, 0.1), (128, 128, 2, 8, 0.2, 0.01), (128, 128, 2, 8, 0.2, 0.005), (128, 128, 2, 8, 0.2, 0.001), (128, 128, 2, 8, 0.5, 0.1), (128, 128, 2, 8, 0.5, 0.01), (128, 128, 2, 8, 0.5, 0.005), (128, 128, 2, 8, 0.5, 0.001), (128, 128, 4, 2, 0.2, 0.1), (128, 128, 4, 2, 0.2, 0.01), (128, 128, 4, 2, 0.2, 0.005), (128, 128, 4, 2, 0.2, 0.001), (128, 128, 4, 2, 0.5, 0.1), (128, 128, 4, 2, 0.5, 0.01), (128, 128, 4, 2, 0.5, 0.005), (128, 128, 4, 2, 0.5, 0.001), (128, 128, 4, 4, 0.2, 0.1), (128, 128, 4, 4, 0.2, 0.01), (128, 128, 4, 4, 0.2, 0.005), (128, 128, 4, 4, 0.2, 0.001), (128, 128, 4, 4, 0.5, 0.1), (128, 128, 4, 4, 0.5, 0.01), (128, 128, 4, 4, 0.5, 0.005), (128, 128, 4, 4, 0.5, 0.001), (128, 128, 4, 8, 0.2, 0.1), (128, 128, 4, 8, 0.2, 0.01), (128, 128, 4, 8, 0.2, 0.005), (128, 128, 4, 8, 0.2, 0.001), (128, 128, 4, 8, 0.5, 0.1), (128, 128, 4, 8, 0.5, 0.01), (128, 128, 4, 8, 0.5, 0.005), (128, 128, 4, 8, 0.5, 0.001), (128, 128, 6, 2, 0.2, 0.1), (128, 128, 6, 2, 0.2, 0.01), (128, 128, 6, 2, 0.2, 0.005), (128, 128, 6, 2, 0.2, 0.001), (128, 128, 6, 2, 0.5, 0.1), (128, 128, 6, 2, 0.5, 0.01), (128, 128, 6, 2, 0.5, 0.005), (128, 128, 6, 2, 0.5, 0.001), (128, 128, 6, 4, 0.2, 0.1), (128, 128, 6, 4, 0.2, 0.01), (128, 128, 6, 4, 0.2, 0.005), (128, 128, 6, 4, 0.2, 0.001), (128, 128, 6, 4, 0.5, 0.1), (128, 128, 6, 4, 0.5, 0.01), (128, 128, 6, 4, 0.5, 0.005), (128, 128, 6, 4, 0.5, 0.001), (128, 128, 6, 8, 0.2, 0.1), (128, 128, 6, 8, 0.2, 0.01), (128, 128, 6, 8, 0.2, 0.005), (128, 128, 6, 8, 0.2, 0.001), (128, 128, 6, 8, 0.5, 0.1), (128, 128, 6, 8, 0.5, 0.01), (128, 128, 6, 8, 0.5, 0.005), (128, 128, 6, 8, 0.5, 0.001), (128, 128, 8, 2, 0.2, 0.1), (128, 128, 8, 2, 0.2, 0.01), (128, 128, 8, 2, 0.2, 0.005), (128, 128, 8, 2, 0.2, 0.001), (128, 128, 8, 2, 0.5, 0.1), (128, 128, 8, 2, 0.5, 0.01), (128, 128, 8, 2, 0.5, 0.005), (128, 128, 8, 2, 0.5, 0.001), (128, 128, 8, 4, 0.2, 0.1), (128, 128, 8, 4, 0.2, 0.01), (128, 128, 8, 4, 0.2, 0.005), (128, 128, 8, 4, 0.2, 0.001), (128, 128, 8, 4, 0.5, 0.1), (128, 128, 8, 4, 0.5, 0.01), (128, 128, 8, 4, 0.5, 0.005), (128, 128, 8, 4, 0.5, 0.001), (128, 128, 8, 8, 0.2, 0.1), (128, 128, 8, 8, 0.2, 0.01), (128, 128, 8, 8, 0.2, 0.005), (128, 128, 8, 8, 0.2, 0.001), (128, 128, 8, 8, 0.5, 0.1), (128, 128, 8, 8, 0.5, 0.01), (128, 128, 8, 8, 0.5, 0.005), (128, 128, 8, 8, 0.5, 0.001), (128, 256, 2, 2, 0.2, 0.1), (128, 256, 2, 2, 0.2, 0.01), (128, 256, 2, 2, 0.2, 0.005), (128, 256, 2, 2, 0.2, 0.001), (128, 256, 2, 2, 0.5, 0.1), (128, 256, 2, 2, 0.5, 0.01), (128, 256, 2, 2, 0.5, 0.005), (128, 256, 2, 2, 0.5, 0.001), (128, 256, 2, 4, 0.2, 0.1), (128, 256, 2, 4, 0.2, 0.01), (128, 256, 2, 4, 0.2, 0.005), (128, 256, 2, 4, 0.2, 0.001), (128, 256, 2, 4, 0.5, 0.1), (128, 256, 2, 4, 0.5, 0.01), (128, 256, 2, 4, 0.5, 0.005), (128, 256, 2, 4, 0.5, 0.001), (128, 256, 2, 8, 0.2, 0.1), (128, 256, 2, 8, 0.2, 0.01), (128, 256, 2, 8, 0.2, 0.005), (128, 256, 2, 8, 0.2, 0.001), (128, 256, 2, 8, 0.5, 0.1), (128, 256, 2, 8, 0.5, 0.01), (128, 256, 2, 8, 0.5, 0.005), (128, 256, 2, 8, 0.5, 0.001), (128, 256, 4, 2, 0.2, 0.1), (128, 256, 4, 2, 0.2, 0.01), (128, 256, 4, 2, 0.2, 0.005), (128, 256, 4, 2, 0.2, 0.001), (128, 256, 4, 2, 0.5, 0.1), (128, 256, 4, 2, 0.5, 0.01), (128, 256, 4, 2, 0.5, 0.005), (128, 256, 4, 2, 0.5, 0.001), (128, 256, 4, 4, 0.2, 0.1), (128, 256, 4, 4, 0.2, 0.01), (128, 256, 4, 4, 0.2, 0.005), (128, 256, 4, 4, 0.2, 0.001), (128, 256, 4, 4, 0.5, 0.1), (128, 256, 4, 4, 0.5, 0.01), (128, 256, 4, 4, 0.5, 0.005), (128, 256, 4, 4, 0.5, 0.001), (128, 256, 4, 8, 0.2, 0.1), (128, 256, 4, 8, 0.2, 0.01), (128, 256, 4, 8, 0.2, 0.005), (128, 256, 4, 8, 0.2, 0.001), (128, 256, 4, 8, 0.5, 0.1), (128, 256, 4, 8, 0.5, 0.01), (128, 256, 4, 8, 0.5, 0.005), (128, 256, 4, 8, 0.5, 0.001), (128, 256, 6, 2, 0.2, 0.1), (128, 256, 6, 2, 0.2, 0.01), (128, 256, 6, 2, 0.2, 0.005), (128, 256, 6, 2, 0.2, 0.001), (128, 256, 6, 2, 0.5, 0.1), (128, 256, 6, 2, 0.5, 0.01), (128, 256, 6, 2, 0.5, 0.005), (128, 256, 6, 2, 0.5, 0.001), (128, 256, 6, 4, 0.2, 0.1), (128, 256, 6, 4, 0.2, 0.01), (128, 256, 6, 4, 0.2, 0.005), (128, 256, 6, 4, 0.2, 0.001), (128, 256, 6, 4, 0.5, 0.1), (128, 256, 6, 4, 0.5, 0.01), (128, 256, 6, 4, 0.5, 0.005), (128, 256, 6, 4, 0.5, 0.001), (128, 256, 6, 8, 0.2, 0.1), (128, 256, 6, 8, 0.2, 0.01), (128, 256, 6, 8, 0.2, 0.005), (128, 256, 6, 8, 0.2, 0.001), (128, 256, 6, 8, 0.5, 0.1), (128, 256, 6, 8, 0.5, 0.01), (128, 256, 6, 8, 0.5, 0.005), (128, 256, 6, 8, 0.5, 0.001), (128, 256, 8, 2, 0.2, 0.1), (128, 256, 8, 2, 0.2, 0.01), (128, 256, 8, 2, 0.2, 0.005), (128, 256, 8, 2, 0.2, 0.001), (128, 256, 8, 2, 0.5, 0.1), (128, 256, 8, 2, 0.5, 0.01), (128, 256, 8, 2, 0.5, 0.005), (128, 256, 8, 2, 0.5, 0.001), (128, 256, 8, 4, 0.2, 0.1), (128, 256, 8, 4, 0.2, 0.01), (128, 256, 8, 4, 0.2, 0.005), (128, 256, 8, 4, 0.2, 0.001), (128, 256, 8, 4, 0.5, 0.1), (128, 256, 8, 4, 0.5, 0.01), (128, 256, 8, 4, 0.5, 0.005), (128, 256, 8, 4, 0.5, 0.001), (128, 256, 8, 8, 0.2, 0.1), (128, 256, 8, 8, 0.2, 0.01), (128, 256, 8, 8, 0.2, 0.005), (128, 256, 8, 8, 0.2, 0.001), (128, 256, 8, 8, 0.5, 0.1), (128, 256, 8, 8, 0.5, 0.01), (128, 256, 8, 8, 0.5, 0.005), (128, 256, 8, 8, 0.5, 0.001), (256, 8, 2, 2, 0.2, 0.1), (256, 8, 2, 2, 0.2, 0.01), (256, 8, 2, 2, 0.2, 0.005), (256, 8, 2, 2, 0.2, 0.001), (256, 8, 2, 2, 0.5, 0.1), (256, 8, 2, 2, 0.5, 0.01), (256, 8, 2, 2, 0.5, 0.005), (256, 8, 2, 2, 0.5, 0.001), (256, 8, 2, 4, 0.2, 0.1), (256, 8, 2, 4, 0.2, 0.01), (256, 8, 2, 4, 0.2, 0.005), (256, 8, 2, 4, 0.2, 0.001), (256, 8, 2, 4, 0.5, 0.1), (256, 8, 2, 4, 0.5, 0.01), (256, 8, 2, 4, 0.5, 0.005), (256, 8, 2, 4, 0.5, 0.001), (256, 8, 2, 8, 0.2, 0.1), (256, 8, 2, 8, 0.2, 0.01), (256, 8, 2, 8, 0.2, 0.005), (256, 8, 2, 8, 0.2, 0.001), (256, 8, 2, 8, 0.5, 0.1), (256, 8, 2, 8, 0.5, 0.01), (256, 8, 2, 8, 0.5, 0.005), (256, 8, 2, 8, 0.5, 0.001), (256, 8, 4, 2, 0.2, 0.1), (256, 8, 4, 2, 0.2, 0.01), (256, 8, 4, 2, 0.2, 0.005), (256, 8, 4, 2, 0.2, 0.001), (256, 8, 4, 2, 0.5, 0.1), (256, 8, 4, 2, 0.5, 0.01), (256, 8, 4, 2, 0.5, 0.005), (256, 8, 4, 2, 0.5, 0.001), (256, 8, 4, 4, 0.2, 0.1), (256, 8, 4, 4, 0.2, 0.01), (256, 8, 4, 4, 0.2, 0.005), (256, 8, 4, 4, 0.2, 0.001), (256, 8, 4, 4, 0.5, 0.1), (256, 8, 4, 4, 0.5, 0.01), (256, 8, 4, 4, 0.5, 0.005), (256, 8, 4, 4, 0.5, 0.001), (256, 8, 4, 8, 0.2, 0.1), (256, 8, 4, 8, 0.2, 0.01), (256, 8, 4, 8, 0.2, 0.005), (256, 8, 4, 8, 0.2, 0.001), (256, 8, 4, 8, 0.5, 0.1), (256, 8, 4, 8, 0.5, 0.01), (256, 8, 4, 8, 0.5, 0.005), (256, 8, 4, 8, 0.5, 0.001), (256, 8, 6, 2, 0.2, 0.1), (256, 8, 6, 2, 0.2, 0.01), (256, 8, 6, 2, 0.2, 0.005), (256, 8, 6, 2, 0.2, 0.001), (256, 8, 6, 2, 0.5, 0.1), (256, 8, 6, 2, 0.5, 0.01), (256, 8, 6, 2, 0.5, 0.005), (256, 8, 6, 2, 0.5, 0.001), (256, 8, 6, 4, 0.2, 0.1), (256, 8, 6, 4, 0.2, 0.01), (256, 8, 6, 4, 0.2, 0.005), (256, 8, 6, 4, 0.2, 0.001), (256, 8, 6, 4, 0.5, 0.1), (256, 8, 6, 4, 0.5, 0.01), (256, 8, 6, 4, 0.5, 0.005), (256, 8, 6, 4, 0.5, 0.001), (256, 8, 6, 8, 0.2, 0.1), (256, 8, 6, 8, 0.2, 0.01), (256, 8, 6, 8, 0.2, 0.005), (256, 8, 6, 8, 0.2, 0.001), (256, 8, 6, 8, 0.5, 0.1), (256, 8, 6, 8, 0.5, 0.01), (256, 8, 6, 8, 0.5, 0.005), (256, 8, 6, 8, 0.5, 0.001), (256, 8, 8, 2, 0.2, 0.1), (256, 8, 8, 2, 0.2, 0.01), (256, 8, 8, 2, 0.2, 0.005), (256, 8, 8, 2, 0.2, 0.001), (256, 8, 8, 2, 0.5, 0.1), (256, 8, 8, 2, 0.5, 0.01), (256, 8, 8, 2, 0.5, 0.005), (256, 8, 8, 2, 0.5, 0.001), (256, 8, 8, 4, 0.2, 0.1), (256, 8, 8, 4, 0.2, 0.01), (256, 8, 8, 4, 0.2, 0.005), (256, 8, 8, 4, 0.2, 0.001), (256, 8, 8, 4, 0.5, 0.1), (256, 8, 8, 4, 0.5, 0.01), (256, 8, 8, 4, 0.5, 0.005), (256, 8, 8, 4, 0.5, 0.001), (256, 8, 8, 8, 0.2, 0.1), (256, 8, 8, 8, 0.2, 0.01), (256, 8, 8, 8, 0.2, 0.005), (256, 8, 8, 8, 0.2, 0.001), (256, 8, 8, 8, 0.5, 0.1), (256, 8, 8, 8, 0.5, 0.01), (256, 8, 8, 8, 0.5, 0.005), (256, 8, 8, 8, 0.5, 0.001), (256, 32, 2, 2, 0.2, 0.1), (256, 32, 2, 2, 0.2, 0.01), (256, 32, 2, 2, 0.2, 0.005), (256, 32, 2, 2, 0.2, 0.001), (256, 32, 2, 2, 0.5, 0.1), (256, 32, 2, 2, 0.5, 0.01), (256, 32, 2, 2, 0.5, 0.005), (256, 32, 2, 2, 0.5, 0.001), (256, 32, 2, 4, 0.2, 0.1), (256, 32, 2, 4, 0.2, 0.01), (256, 32, 2, 4, 0.2, 0.005), (256, 32, 2, 4, 0.2, 0.001), (256, 32, 2, 4, 0.5, 0.1), (256, 32, 2, 4, 0.5, 0.01), (256, 32, 2, 4, 0.5, 0.005), (256, 32, 2, 4, 0.5, 0.001), (256, 32, 2, 8, 0.2, 0.1), (256, 32, 2, 8, 0.2, 0.01), (256, 32, 2, 8, 0.2, 0.005), (256, 32, 2, 8, 0.2, 0.001), (256, 32, 2, 8, 0.5, 0.1), (256, 32, 2, 8, 0.5, 0.01), (256, 32, 2, 8, 0.5, 0.005), (256, 32, 2, 8, 0.5, 0.001), (256, 32, 4, 2, 0.2, 0.1), (256, 32, 4, 2, 0.2, 0.01), (256, 32, 4, 2, 0.2, 0.005), (256, 32, 4, 2, 0.2, 0.001), (256, 32, 4, 2, 0.5, 0.1), (256, 32, 4, 2, 0.5, 0.01), (256, 32, 4, 2, 0.5, 0.005), (256, 32, 4, 2, 0.5, 0.001), (256, 32, 4, 4, 0.2, 0.1), (256, 32, 4, 4, 0.2, 0.01), (256, 32, 4, 4, 0.2, 0.005), (256, 32, 4, 4, 0.2, 0.001), (256, 32, 4, 4, 0.5, 0.1), (256, 32, 4, 4, 0.5, 0.01), (256, 32, 4, 4, 0.5, 0.005), (256, 32, 4, 4, 0.5, 0.001), (256, 32, 4, 8, 0.2, 0.1), (256, 32, 4, 8, 0.2, 0.01), (256, 32, 4, 8, 0.2, 0.005), (256, 32, 4, 8, 0.2, 0.001), (256, 32, 4, 8, 0.5, 0.1), (256, 32, 4, 8, 0.5, 0.01), (256, 32, 4, 8, 0.5, 0.005), (256, 32, 4, 8, 0.5, 0.001), (256, 32, 6, 2, 0.2, 0.1), (256, 32, 6, 2, 0.2, 0.01), (256, 32, 6, 2, 0.2, 0.005), (256, 32, 6, 2, 0.2, 0.001), (256, 32, 6, 2, 0.5, 0.1), (256, 32, 6, 2, 0.5, 0.01), (256, 32, 6, 2, 0.5, 0.005), (256, 32, 6, 2, 0.5, 0.001), (256, 32, 6, 4, 0.2, 0.1), (256, 32, 6, 4, 0.2, 0.01), (256, 32, 6, 4, 0.2, 0.005), (256, 32, 6, 4, 0.2, 0.001), (256, 32, 6, 4, 0.5, 0.1), (256, 32, 6, 4, 0.5, 0.01), (256, 32, 6, 4, 0.5, 0.005), (256, 32, 6, 4, 0.5, 0.001), (256, 32, 6, 8, 0.2, 0.1), (256, 32, 6, 8, 0.2, 0.01), (256, 32, 6, 8, 0.2, 0.005), (256, 32, 6, 8, 0.2, 0.001), (256, 32, 6, 8, 0.5, 0.1), (256, 32, 6, 8, 0.5, 0.01), (256, 32, 6, 8, 0.5, 0.005), (256, 32, 6, 8, 0.5, 0.001), (256, 32, 8, 2, 0.2, 0.1), (256, 32, 8, 2, 0.2, 0.01), (256, 32, 8, 2, 0.2, 0.005), (256, 32, 8, 2, 0.2, 0.001), (256, 32, 8, 2, 0.5, 0.1), (256, 32, 8, 2, 0.5, 0.01), (256, 32, 8, 2, 0.5, 0.005), (256, 32, 8, 2, 0.5, 0.001), (256, 32, 8, 4, 0.2, 0.1), (256, 32, 8, 4, 0.2, 0.01), (256, 32, 8, 4, 0.2, 0.005), (256, 32, 8, 4, 0.2, 0.001), (256, 32, 8, 4, 0.5, 0.1), (256, 32, 8, 4, 0.5, 0.01), (256, 32, 8, 4, 0.5, 0.005), (256, 32, 8, 4, 0.5, 0.001), (256, 32, 8, 8, 0.2, 0.1), (256, 32, 8, 8, 0.2, 0.01), (256, 32, 8, 8, 0.2, 0.005), (256, 32, 8, 8, 0.2, 0.001), (256, 32, 8, 8, 0.5, 0.1), (256, 32, 8, 8, 0.5, 0.01), (256, 32, 8, 8, 0.5, 0.005), (256, 32, 8, 8, 0.5, 0.001), (256, 64, 2, 2, 0.2, 0.1), (256, 64, 2, 2, 0.2, 0.01), (256, 64, 2, 2, 0.2, 0.005), (256, 64, 2, 2, 0.2, 0.001), (256, 64, 2, 2, 0.5, 0.1), (256, 64, 2, 2, 0.5, 0.01), (256, 64, 2, 2, 0.5, 0.005), (256, 64, 2, 2, 0.5, 0.001), (256, 64, 2, 4, 0.2, 0.1), (256, 64, 2, 4, 0.2, 0.01), (256, 64, 2, 4, 0.2, 0.005), (256, 64, 2, 4, 0.2, 0.001), (256, 64, 2, 4, 0.5, 0.1), (256, 64, 2, 4, 0.5, 0.01), (256, 64, 2, 4, 0.5, 0.005), (256, 64, 2, 4, 0.5, 0.001), (256, 64, 2, 8, 0.2, 0.1), (256, 64, 2, 8, 0.2, 0.01), (256, 64, 2, 8, 0.2, 0.005), (256, 64, 2, 8, 0.2, 0.001), (256, 64, 2, 8, 0.5, 0.1), (256, 64, 2, 8, 0.5, 0.01), (256, 64, 2, 8, 0.5, 0.005), (256, 64, 2, 8, 0.5, 0.001), (256, 64, 4, 2, 0.2, 0.1), (256, 64, 4, 2, 0.2, 0.01), (256, 64, 4, 2, 0.2, 0.005), (256, 64, 4, 2, 0.2, 0.001), (256, 64, 4, 2, 0.5, 0.1), (256, 64, 4, 2, 0.5, 0.01), (256, 64, 4, 2, 0.5, 0.005), (256, 64, 4, 2, 0.5, 0.001), (256, 64, 4, 4, 0.2, 0.1), (256, 64, 4, 4, 0.2, 0.01), (256, 64, 4, 4, 0.2, 0.005), (256, 64, 4, 4, 0.2, 0.001), (256, 64, 4, 4, 0.5, 0.1), (256, 64, 4, 4, 0.5, 0.01), (256, 64, 4, 4, 0.5, 0.005), (256, 64, 4, 4, 0.5, 0.001), (256, 64, 4, 8, 0.2, 0.1), (256, 64, 4, 8, 0.2, 0.01), (256, 64, 4, 8, 0.2, 0.005), (256, 64, 4, 8, 0.2, 0.001), (256, 64, 4, 8, 0.5, 0.1), (256, 64, 4, 8, 0.5, 0.01), (256, 64, 4, 8, 0.5, 0.005), (256, 64, 4, 8, 0.5, 0.001), (256, 64, 6, 2, 0.2, 0.1), (256, 64, 6, 2, 0.2, 0.01), (256, 64, 6, 2, 0.2, 0.005), (256, 64, 6, 2, 0.2, 0.001), (256, 64, 6, 2, 0.5, 0.1), (256, 64, 6, 2, 0.5, 0.01), (256, 64, 6, 2, 0.5, 0.005), (256, 64, 6, 2, 0.5, 0.001), (256, 64, 6, 4, 0.2, 0.1), (256, 64, 6, 4, 0.2, 0.01), (256, 64, 6, 4, 0.2, 0.005), (256, 64, 6, 4, 0.2, 0.001), (256, 64, 6, 4, 0.5, 0.1), (256, 64, 6, 4, 0.5, 0.01), (256, 64, 6, 4, 0.5, 0.005), (256, 64, 6, 4, 0.5, 0.001), (256, 64, 6, 8, 0.2, 0.1), (256, 64, 6, 8, 0.2, 0.01), (256, 64, 6, 8, 0.2, 0.005), (256, 64, 6, 8, 0.2, 0.001), (256, 64, 6, 8, 0.5, 0.1), (256, 64, 6, 8, 0.5, 0.01), (256, 64, 6, 8, 0.5, 0.005), (256, 64, 6, 8, 0.5, 0.001), (256, 64, 8, 2, 0.2, 0.1), (256, 64, 8, 2, 0.2, 0.01), (256, 64, 8, 2, 0.2, 0.005), (256, 64, 8, 2, 0.2, 0.001), (256, 64, 8, 2, 0.5, 0.1), (256, 64, 8, 2, 0.5, 0.01), (256, 64, 8, 2, 0.5, 0.005), (256, 64, 8, 2, 0.5, 0.001), (256, 64, 8, 4, 0.2, 0.1), (256, 64, 8, 4, 0.2, 0.01), (256, 64, 8, 4, 0.2, 0.005), (256, 64, 8, 4, 0.2, 0.001), (256, 64, 8, 4, 0.5, 0.1), (256, 64, 8, 4, 0.5, 0.01), (256, 64, 8, 4, 0.5, 0.005), (256, 64, 8, 4, 0.5, 0.001), (256, 64, 8, 8, 0.2, 0.1), (256, 64, 8, 8, 0.2, 0.01), (256, 64, 8, 8, 0.2, 0.005), (256, 64, 8, 8, 0.2, 0.001), (256, 64, 8, 8, 0.5, 0.1), (256, 64, 8, 8, 0.5, 0.01), (256, 64, 8, 8, 0.5, 0.005), (256, 64, 8, 8, 0.5, 0.001), (256, 128, 2, 2, 0.2, 0.1), (256, 128, 2, 2, 0.2, 0.01), (256, 128, 2, 2, 0.2, 0.005), (256, 128, 2, 2, 0.2, 0.001), (256, 128, 2, 2, 0.5, 0.1), (256, 128, 2, 2, 0.5, 0.01), (256, 128, 2, 2, 0.5, 0.005), (256, 128, 2, 2, 0.5, 0.001), (256, 128, 2, 4, 0.2, 0.1), (256, 128, 2, 4, 0.2, 0.01), (256, 128, 2, 4, 0.2, 0.005), (256, 128, 2, 4, 0.2, 0.001), (256, 128, 2, 4, 0.5, 0.1), (256, 128, 2, 4, 0.5, 0.01), (256, 128, 2, 4, 0.5, 0.005), (256, 128, 2, 4, 0.5, 0.001), (256, 128, 2, 8, 0.2, 0.1), (256, 128, 2, 8, 0.2, 0.01), (256, 128, 2, 8, 0.2, 0.005), (256, 128, 2, 8, 0.2, 0.001), (256, 128, 2, 8, 0.5, 0.1), (256, 128, 2, 8, 0.5, 0.01), (256, 128, 2, 8, 0.5, 0.005), (256, 128, 2, 8, 0.5, 0.001), (256, 128, 4, 2, 0.2, 0.1), (256, 128, 4, 2, 0.2, 0.01), (256, 128, 4, 2, 0.2, 0.005), (256, 128, 4, 2, 0.2, 0.001), (256, 128, 4, 2, 0.5, 0.1), (256, 128, 4, 2, 0.5, 0.01), (256, 128, 4, 2, 0.5, 0.005), (256, 128, 4, 2, 0.5, 0.001), (256, 128, 4, 4, 0.2, 0.1), (256, 128, 4, 4, 0.2, 0.01), (256, 128, 4, 4, 0.2, 0.005), (256, 128, 4, 4, 0.2, 0.001), (256, 128, 4, 4, 0.5, 0.1), (256, 128, 4, 4, 0.5, 0.01), (256, 128, 4, 4, 0.5, 0.005), (256, 128, 4, 4, 0.5, 0.001), (256, 128, 4, 8, 0.2, 0.1), (256, 128, 4, 8, 0.2, 0.01), (256, 128, 4, 8, 0.2, 0.005), (256, 128, 4, 8, 0.2, 0.001), (256, 128, 4, 8, 0.5, 0.1), (256, 128, 4, 8, 0.5, 0.01), (256, 128, 4, 8, 0.5, 0.005), (256, 128, 4, 8, 0.5, 0.001), (256, 128, 6, 2, 0.2, 0.1), (256, 128, 6, 2, 0.2, 0.01), (256, 128, 6, 2, 0.2, 0.005), (256, 128, 6, 2, 0.2, 0.001), (256, 128, 6, 2, 0.5, 0.1), (256, 128, 6, 2, 0.5, 0.01), (256, 128, 6, 2, 0.5, 0.005), (256, 128, 6, 2, 0.5, 0.001), (256, 128, 6, 4, 0.2, 0.1), (256, 128, 6, 4, 0.2, 0.01), (256, 128, 6, 4, 0.2, 0.005), (256, 128, 6, 4, 0.2, 0.001), (256, 128, 6, 4, 0.5, 0.1), (256, 128, 6, 4, 0.5, 0.01), (256, 128, 6, 4, 0.5, 0.005), (256, 128, 6, 4, 0.5, 0.001), (256, 128, 6, 8, 0.2, 0.1), (256, 128, 6, 8, 0.2, 0.01), (256, 128, 6, 8, 0.2, 0.005), (256, 128, 6, 8, 0.2, 0.001), (256, 128, 6, 8, 0.5, 0.1), (256, 128, 6, 8, 0.5, 0.01), (256, 128, 6, 8, 0.5, 0.005), (256, 128, 6, 8, 0.5, 0.001), (256, 128, 8, 2, 0.2, 0.1), (256, 128, 8, 2, 0.2, 0.01), (256, 128, 8, 2, 0.2, 0.005), (256, 128, 8, 2, 0.2, 0.001), (256, 128, 8, 2, 0.5, 0.1), (256, 128, 8, 2, 0.5, 0.01), (256, 128, 8, 2, 0.5, 0.005), (256, 128, 8, 2, 0.5, 0.001), (256, 128, 8, 4, 0.2, 0.1), (256, 128, 8, 4, 0.2, 0.01), (256, 128, 8, 4, 0.2, 0.005), (256, 128, 8, 4, 0.2, 0.001), (256, 128, 8, 4, 0.5, 0.1), (256, 128, 8, 4, 0.5, 0.01), (256, 128, 8, 4, 0.5, 0.005), (256, 128, 8, 4, 0.5, 0.001), (256, 128, 8, 8, 0.2, 0.1), (256, 128, 8, 8, 0.2, 0.01), (256, 128, 8, 8, 0.2, 0.005), (256, 128, 8, 8, 0.2, 0.001), (256, 128, 8, 8, 0.5, 0.1), (256, 128, 8, 8, 0.5, 0.01), (256, 128, 8, 8, 0.5, 0.005), (256, 128, 8, 8, 0.5, 0.001), (256, 256, 2, 2, 0.2, 0.1), (256, 256, 2, 2, 0.2, 0.01), (256, 256, 2, 2, 0.2, 0.005), (256, 256, 2, 2, 0.2, 0.001), (256, 256, 2, 2, 0.5, 0.1), (256, 256, 2, 2, 0.5, 0.01), (256, 256, 2, 2, 0.5, 0.005), (256, 256, 2, 2, 0.5, 0.001), (256, 256, 2, 4, 0.2, 0.1), (256, 256, 2, 4, 0.2, 0.01), (256, 256, 2, 4, 0.2, 0.005), (256, 256, 2, 4, 0.2, 0.001), (256, 256, 2, 4, 0.5, 0.1), (256, 256, 2, 4, 0.5, 0.01), (256, 256, 2, 4, 0.5, 0.005), (256, 256, 2, 4, 0.5, 0.001), (256, 256, 2, 8, 0.2, 0.1), (256, 256, 2, 8, 0.2, 0.01), (256, 256, 2, 8, 0.2, 0.005), (256, 256, 2, 8, 0.2, 0.001), (256, 256, 2, 8, 0.5, 0.1), (256, 256, 2, 8, 0.5, 0.01), (256, 256, 2, 8, 0.5, 0.005), (256, 256, 2, 8, 0.5, 0.001), (256, 256, 4, 2, 0.2, 0.1), (256, 256, 4, 2, 0.2, 0.01), (256, 256, 4, 2, 0.2, 0.005), (256, 256, 4, 2, 0.2, 0.001), (256, 256, 4, 2, 0.5, 0.1), (256, 256, 4, 2, 0.5, 0.01), (256, 256, 4, 2, 0.5, 0.005), (256, 256, 4, 2, 0.5, 0.001), (256, 256, 4, 4, 0.2, 0.1), (256, 256, 4, 4, 0.2, 0.01), (256, 256, 4, 4, 0.2, 0.005), (256, 256, 4, 4, 0.2, 0.001), (256, 256, 4, 4, 0.5, 0.1), (256, 256, 4, 4, 0.5, 0.01), (256, 256, 4, 4, 0.5, 0.005), (256, 256, 4, 4, 0.5, 0.001), (256, 256, 4, 8, 0.2, 0.1), (256, 256, 4, 8, 0.2, 0.01), (256, 256, 4, 8, 0.2, 0.005), (256, 256, 4, 8, 0.2, 0.001), (256, 256, 4, 8, 0.5, 0.1), (256, 256, 4, 8, 0.5, 0.01), (256, 256, 4, 8, 0.5, 0.005), (256, 256, 4, 8, 0.5, 0.001), (256, 256, 6, 2, 0.2, 0.1), (256, 256, 6, 2, 0.2, 0.01), (256, 256, 6, 2, 0.2, 0.005), (256, 256, 6, 2, 0.2, 0.001), (256, 256, 6, 2, 0.5, 0.1), (256, 256, 6, 2, 0.5, 0.01), (256, 256, 6, 2, 0.5, 0.005), (256, 256, 6, 2, 0.5, 0.001), (256, 256, 6, 4, 0.2, 0.1), (256, 256, 6, 4, 0.2, 0.01), (256, 256, 6, 4, 0.2, 0.005), (256, 256, 6, 4, 0.2, 0.001), (256, 256, 6, 4, 0.5, 0.1), (256, 256, 6, 4, 0.5, 0.01), (256, 256, 6, 4, 0.5, 0.005), (256, 256, 6, 4, 0.5, 0.001), (256, 256, 6, 8, 0.2, 0.1), (256, 256, 6, 8, 0.2, 0.01), (256, 256, 6, 8, 0.2, 0.005), (256, 256, 6, 8, 0.2, 0.001), (256, 256, 6, 8, 0.5, 0.1), (256, 256, 6, 8, 0.5, 0.01), (256, 256, 6, 8, 0.5, 0.005), (256, 256, 6, 8, 0.5, 0.001), (256, 256, 8, 2, 0.2, 0.1), (256, 256, 8, 2, 0.2, 0.01), (256, 256, 8, 2, 0.2, 0.005), (256, 256, 8, 2, 0.2, 0.001), (256, 256, 8, 2, 0.5, 0.1), (256, 256, 8, 2, 0.5, 0.01), (256, 256, 8, 2, 0.5, 0.005), (256, 256, 8, 2, 0.5, 0.001), (256, 256, 8, 4, 0.2, 0.1), (256, 256, 8, 4, 0.2, 0.01), (256, 256, 8, 4, 0.2, 0.005), (256, 256, 8, 4, 0.2, 0.001), (256, 256, 8, 4, 0.5, 0.1), (256, 256, 8, 4, 0.5, 0.01), (256, 256, 8, 4, 0.5, 0.005), (256, 256, 8, 4, 0.5, 0.001), (256, 256, 8, 8, 0.2, 0.1), (256, 256, 8, 8, 0.2, 0.01), (256, 256, 8, 8, 0.2, 0.005), (256, 256, 8, 8, 0.2, 0.001), (256, 256, 8, 8, 0.5, 0.1), (256, 256, 8, 8, 0.5, 0.01), (256, 256, 8, 8, 0.5, 0.005), (256, 256, 8, 8, 0.5, 0.001)]\n"
     ]
    }
   ],
   "source": [
    "parameters=dict(\n",
    "    emsize=[8,32,64,128,256],\n",
    "    d_hid=[8,32,64,128,256],\n",
    "    nlayers=[2,4,6,8],\n",
    "    nhead=[2,4,8],\n",
    "    dropout=[0.2,0.5],\n",
    "    lr=[0.1,0.01,0.005,0.001]\n",
    ")\n",
    "param_values=[v for v in parameters.values()]\n",
    "param=list(product(*param_values))\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15884 | test ppl 3.18622|test cor 0.09621\n",
      "=========================================================================================\n",
      "8 8 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17225 | test ppl 3.22925|test cor 0.15771\n",
      "=========================================================================================\n",
      "8 8 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21274 | test ppl 3.36267|test cor -0.04338\n",
      "=========================================================================================\n",
      "8 8 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.29595 | test ppl 3.65447|test cor -0.03868\n",
      "=========================================================================================\n",
      "8 8 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15868 | test ppl 3.18572|test cor 0.01304\n",
      "=========================================================================================\n",
      "8 8 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15953 | test ppl 3.18842|test cor 0.04286\n",
      "=========================================================================================\n",
      "8 8 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17703 | test ppl 3.24473|test cor -0.06827\n",
      "=========================================================================================\n",
      "8 8 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.45594 | test ppl 4.28853|test cor -0.02964\n",
      "=========================================================================================\n",
      "8 8 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15651 | test ppl 3.17881|test cor 0.07304\n",
      "=========================================================================================\n",
      "8 8 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16498 | test ppl 3.20586|test cor -0.01077\n",
      "=========================================================================================\n",
      "8 8 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17073 | test ppl 3.22435|test cor 0.11971\n",
      "=========================================================================================\n",
      "8 8 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.41299 | test ppl 4.10821|test cor 0.01903\n",
      "=========================================================================================\n",
      "8 8 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15717 | test ppl 3.18092|test cor 0.05794\n",
      "=========================================================================================\n",
      "8 8 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15444 | test ppl 3.17225|test cor 0.03261\n",
      "=========================================================================================\n",
      "8 8 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16765 | test ppl 3.21443|test cor 0.03474\n",
      "=========================================================================================\n",
      "8 8 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.34964 | test ppl 3.85603|test cor -0.06180\n",
      "=========================================================================================\n",
      "8 8 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15779 | test ppl 3.18288|test cor 0.00341\n",
      "=========================================================================================\n",
      "8 8 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16184 | test ppl 3.19581|test cor 0.09032\n",
      "=========================================================================================\n",
      "8 8 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17692 | test ppl 3.24437|test cor 0.05109\n",
      "=========================================================================================\n",
      "8 8 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22122 | test ppl 3.39133|test cor 0.07087\n",
      "=========================================================================================\n",
      "8 8 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16113 | test ppl 3.19353|test cor 0.03540\n",
      "=========================================================================================\n",
      "8 8 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16858 | test ppl 3.21743|test cor 0.09125\n",
      "=========================================================================================\n",
      "8 8 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18951 | test ppl 3.28549|test cor -0.12544\n",
      "=========================================================================================\n",
      "8 8 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17472 | test ppl 3.23723|test cor 0.16457\n",
      "=========================================================================================\n",
      "8 8 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16408 | test ppl 3.20299|test cor 0.07690\n",
      "=========================================================================================\n",
      "8 8 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16253 | test ppl 3.19802|test cor -0.20404\n",
      "=========================================================================================\n",
      "8 8 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15680 | test ppl 3.17975|test cor 0.07200\n",
      "=========================================================================================\n",
      "8 8 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.93303 | test ppl 6.91042|test cor 0.04780\n",
      "=========================================================================================\n",
      "8 8 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16004 | test ppl 3.19006|test cor 0.08860\n",
      "=========================================================================================\n",
      "8 8 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16315 | test ppl 3.20000|test cor -0.05899\n",
      "=========================================================================================\n",
      "8 8 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16118 | test ppl 3.19370|test cor 0.16862\n",
      "=========================================================================================\n",
      "8 8 4 2 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.55656 | test ppl 4.74248|test cor -0.09546\n",
      "=========================================================================================\n",
      "8 8 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15603 | test ppl 3.17729|test cor 0.08083\n",
      "=========================================================================================\n",
      "8 8 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15564 | test ppl 3.17604|test cor 0.09604\n",
      "=========================================================================================\n",
      "8 8 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17473 | test ppl 3.23726|test cor -0.05403\n",
      "=========================================================================================\n",
      "8 8 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24998 | test ppl 3.49026|test cor 0.08382\n",
      "=========================================================================================\n",
      "8 8 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15976 | test ppl 3.18918|test cor -0.06313\n",
      "=========================================================================================\n",
      "8 8 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15753 | test ppl 3.18207|test cor 0.13344\n",
      "=========================================================================================\n",
      "8 8 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23204 | test ppl 3.42822|test cor -0.00958\n",
      "=========================================================================================\n",
      "8 8 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.68803 | test ppl 5.40879|test cor 0.18123\n",
      "=========================================================================================\n",
      "8 8 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16872 | test ppl 3.21787|test cor -0.00723\n",
      "=========================================================================================\n",
      "8 8 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16356 | test ppl 3.20132|test cor 0.14096\n",
      "=========================================================================================\n",
      "8 8 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15762 | test ppl 3.18235|test cor -0.06325\n",
      "=========================================================================================\n",
      "8 8 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28051 | test ppl 3.59849|test cor 0.11781\n",
      "=========================================================================================\n",
      "8 8 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15946 | test ppl 3.18821|test cor 0.04715\n",
      "=========================================================================================\n",
      "8 8 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16246 | test ppl 3.19779|test cor 0.10934\n",
      "=========================================================================================\n",
      "8 8 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18325 | test ppl 3.26498|test cor 0.05489\n",
      "=========================================================================================\n",
      "8 8 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16151 | test ppl 3.19475|test cor 0.00106\n",
      "=========================================================================================\n",
      "8 8 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16659 | test ppl 3.21101|test cor 0.21883\n",
      "=========================================================================================\n",
      "8 8 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15986 | test ppl 3.18948|test cor -0.12174\n",
      "=========================================================================================\n",
      "8 8 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17314 | test ppl 3.23214|test cor -0.00100\n",
      "=========================================================================================\n",
      "8 8 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16169 | test ppl 3.19532|test cor 0.09714\n",
      "=========================================================================================\n",
      "8 8 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15960 | test ppl 3.18865|test cor 0.06941\n",
      "=========================================================================================\n",
      "8 8 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16620 | test ppl 3.20976|test cor -0.03555\n",
      "=========================================================================================\n",
      "8 8 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16869 | test ppl 3.21779|test cor 0.05199\n",
      "=========================================================================================\n",
      "8 8 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23498 | test ppl 3.43832|test cor -0.20403\n",
      "=========================================================================================\n",
      "8 8 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16265 | test ppl 3.19839|test cor 0.06177\n",
      "=========================================================================================\n",
      "8 8 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16426 | test ppl 3.20355|test cor 0.14268\n",
      "=========================================================================================\n",
      "8 8 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17019 | test ppl 3.22260|test cor -0.03049\n",
      "=========================================================================================\n",
      "8 8 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.81866 | test ppl 6.16357|test cor -0.08940\n",
      "=========================================================================================\n",
      "8 8 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16117 | test ppl 3.19366|test cor -0.14429\n",
      "=========================================================================================\n",
      "8 8 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16815 | test ppl 3.21605|test cor 0.08818\n",
      "=========================================================================================\n",
      "8 8 6 4 0.5 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16729 | test ppl 3.21328|test cor -0.02822\n",
      "=========================================================================================\n",
      "8 8 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17481 | test ppl 3.23752|test cor -0.21998\n",
      "=========================================================================================\n",
      "8 8 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15874 | test ppl 3.18590|test cor 0.04906\n",
      "=========================================================================================\n",
      "8 8 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16533 | test ppl 3.20699|test cor -0.04941\n",
      "=========================================================================================\n",
      "8 8 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16154 | test ppl 3.19484|test cor 0.03064\n",
      "=========================================================================================\n",
      "8 8 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24390 | test ppl 3.46911|test cor 0.06965\n",
      "=========================================================================================\n",
      "8 8 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16068 | test ppl 3.19212|test cor -0.08271\n",
      "=========================================================================================\n",
      "8 8 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16998 | test ppl 3.22192|test cor -0.01113\n",
      "=========================================================================================\n",
      "8 8 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17649 | test ppl 3.24299|test cor 0.04289\n",
      "=========================================================================================\n",
      "8 8 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19572 | test ppl 3.30595|test cor 0.10328\n",
      "=========================================================================================\n",
      "8 8 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16027 | test ppl 3.19079|test cor -0.16504\n",
      "=========================================================================================\n",
      "8 8 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16381 | test ppl 3.20213|test cor -0.00553\n",
      "=========================================================================================\n",
      "8 8 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16556 | test ppl 3.20771|test cor -0.02166\n",
      "=========================================================================================\n",
      "8 8 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16327 | test ppl 3.20039|test cor -0.03435\n",
      "=========================================================================================\n",
      "8 8 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16096 | test ppl 3.19301|test cor 0.09851\n",
      "=========================================================================================\n",
      "8 8 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16532 | test ppl 3.20694|test cor 0.14989\n",
      "=========================================================================================\n",
      "8 8 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16966 | test ppl 3.22089|test cor -0.01640\n",
      "=========================================================================================\n",
      "8 8 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18575 | test ppl 3.27315|test cor -0.05444\n",
      "=========================================================================================\n",
      "8 8 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16083 | test ppl 3.19257|test cor 0.18693\n",
      "=========================================================================================\n",
      "8 8 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16186 | test ppl 3.19588|test cor -0.08519\n",
      "=========================================================================================\n",
      "8 8 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15491 | test ppl 3.17374|test cor 0.02912\n",
      "=========================================================================================\n",
      "8 8 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18031 | test ppl 3.25539|test cor 0.07982\n",
      "=========================================================================================\n",
      "8 8 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16169 | test ppl 3.19532|test cor 0.02598\n",
      "=========================================================================================\n",
      "8 8 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16232 | test ppl 3.19734|test cor -0.09039\n",
      "=========================================================================================\n",
      "8 8 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20032 | test ppl 3.32119|test cor -0.15719\n",
      "=========================================================================================\n",
      "8 8 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24066 | test ppl 3.45789|test cor 0.19096\n",
      "=========================================================================================\n",
      "8 8 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16082 | test ppl 3.19256|test cor 0.08096\n",
      "=========================================================================================\n",
      "8 8 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16154 | test ppl 3.19485|test cor 0.00706\n",
      "=========================================================================================\n",
      "8 8 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16157 | test ppl 3.19495|test cor -0.08595\n",
      "=========================================================================================\n",
      "8 8 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26621 | test ppl 3.54739|test cor 0.19629\n",
      "=========================================================================================\n",
      "8 8 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16105 | test ppl 3.19328|test cor -0.03317\n",
      "=========================================================================================\n",
      "8 8 8 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16232 | test ppl 3.19735|test cor -0.12906\n",
      "=========================================================================================\n",
      "8 8 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16831 | test ppl 3.21655|test cor -0.06509\n",
      "=========================================================================================\n",
      "8 8 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18867 | test ppl 3.28270|test cor -0.04290\n",
      "=========================================================================================\n",
      "8 32 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15600 | test ppl 3.17721|test cor 0.02757\n",
      "=========================================================================================\n",
      "8 32 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15980 | test ppl 3.18930|test cor -0.05136\n",
      "=========================================================================================\n",
      "8 32 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18879 | test ppl 3.28310|test cor -0.11545\n",
      "=========================================================================================\n",
      "8 32 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.42982 | test ppl 4.17793|test cor -0.03265\n",
      "=========================================================================================\n",
      "8 32 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16058 | test ppl 3.19179|test cor -0.03515\n",
      "=========================================================================================\n",
      "8 32 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15835 | test ppl 3.18469|test cor 0.09649\n",
      "=========================================================================================\n",
      "8 32 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16053 | test ppl 3.19163|test cor 0.20939\n",
      "=========================================================================================\n",
      "8 32 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.35955 | test ppl 3.89446|test cor -0.00135\n",
      "=========================================================================================\n",
      "8 32 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15978 | test ppl 3.18924|test cor 0.02022\n",
      "=========================================================================================\n",
      "8 32 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17139 | test ppl 3.22648|test cor -0.16511\n",
      "=========================================================================================\n",
      "8 32 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15580 | test ppl 3.17657|test cor -0.06435\n",
      "=========================================================================================\n",
      "8 32 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.35998 | test ppl 3.89611|test cor -0.01587\n",
      "=========================================================================================\n",
      "8 32 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15863 | test ppl 3.18558|test cor 0.01894\n",
      "=========================================================================================\n",
      "8 32 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16006 | test ppl 3.19011|test cor 0.02494\n",
      "=========================================================================================\n",
      "8 32 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16418 | test ppl 3.20331|test cor -0.09379\n",
      "=========================================================================================\n",
      "8 32 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.30267 | test ppl 3.67911|test cor -0.01153\n",
      "=========================================================================================\n",
      "8 32 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16115 | test ppl 3.19360|test cor -0.03028\n",
      "=========================================================================================\n",
      "8 32 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15236 | test ppl 3.16564|test cor 0.07216\n",
      "=========================================================================================\n",
      "8 32 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19371 | test ppl 3.29930|test cor 0.10510\n",
      "=========================================================================================\n",
      "8 32 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20704 | test ppl 3.34356|test cor -0.05622\n",
      "=========================================================================================\n",
      "8 32 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15892 | test ppl 3.18648|test cor 0.01486\n",
      "=========================================================================================\n",
      "8 32 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16246 | test ppl 3.19779|test cor 0.10311\n",
      "=========================================================================================\n",
      "8 32 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16984 | test ppl 3.22148|test cor 0.07417\n",
      "=========================================================================================\n",
      "8 32 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23491 | test ppl 3.43807|test cor 0.06486\n",
      "=========================================================================================\n",
      "8 32 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15954 | test ppl 3.18847|test cor -0.00580\n",
      "=========================================================================================\n",
      "8 32 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15803 | test ppl 3.18367|test cor -0.01545\n",
      "=========================================================================================\n",
      "8 32 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16077 | test ppl 3.19237|test cor 0.11431\n",
      "=========================================================================================\n",
      "8 32 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18710 | test ppl 3.27756|test cor -0.01256\n",
      "=========================================================================================\n",
      "8 32 4 2 0.5 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16087 | test ppl 3.19271|test cor 0.04547\n",
      "=========================================================================================\n",
      "8 32 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16359 | test ppl 3.20142|test cor 0.02578\n",
      "=========================================================================================\n",
      "8 32 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16388 | test ppl 3.20235|test cor 0.02458\n",
      "=========================================================================================\n",
      "8 32 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20957 | test ppl 3.35203|test cor -0.01699\n",
      "=========================================================================================\n",
      "8 32 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15598 | test ppl 3.17713|test cor 0.06907\n",
      "=========================================================================================\n",
      "8 32 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16138 | test ppl 3.19434|test cor 0.00011\n",
      "=========================================================================================\n",
      "8 32 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16188 | test ppl 3.19593|test cor -0.15623\n",
      "=========================================================================================\n",
      "8 32 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24501 | test ppl 3.47296|test cor -0.14117\n",
      "=========================================================================================\n",
      "8 32 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15885 | test ppl 3.18628|test cor -0.02636\n",
      "=========================================================================================\n",
      "8 32 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15872 | test ppl 3.18586|test cor -0.01573\n",
      "=========================================================================================\n",
      "8 32 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20461 | test ppl 3.33547|test cor 0.20576\n",
      "=========================================================================================\n",
      "8 32 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.29434 | test ppl 3.64859|test cor -0.10980\n",
      "=========================================================================================\n",
      "8 32 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15784 | test ppl 3.18304|test cor 0.08010\n",
      "=========================================================================================\n",
      "8 32 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15879 | test ppl 3.18609|test cor -0.10351\n",
      "=========================================================================================\n",
      "8 32 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19865 | test ppl 3.31564|test cor 0.18587\n",
      "=========================================================================================\n",
      "8 32 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.51471 | test ppl 4.54808|test cor -0.14325\n",
      "=========================================================================================\n",
      "8 32 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15819 | test ppl 3.18415|test cor -0.00218\n",
      "=========================================================================================\n",
      "8 32 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15990 | test ppl 3.18962|test cor 0.01102\n",
      "=========================================================================================\n",
      "8 32 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15961 | test ppl 3.18868|test cor 0.02643\n",
      "=========================================================================================\n",
      "8 32 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25378 | test ppl 3.50357|test cor 0.03234\n",
      "=========================================================================================\n",
      "8 32 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15669 | test ppl 3.17939|test cor 0.13054\n",
      "=========================================================================================\n",
      "8 32 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15815 | test ppl 3.18404|test cor -0.06688\n",
      "=========================================================================================\n",
      "8 32 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17020 | test ppl 3.22264|test cor 0.00611\n",
      "=========================================================================================\n",
      "8 32 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20973 | test ppl 3.35259|test cor 0.01228\n",
      "=========================================================================================\n",
      "8 32 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16085 | test ppl 3.19265|test cor -0.00937\n",
      "=========================================================================================\n",
      "8 32 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16962 | test ppl 3.22077|test cor 0.15850\n",
      "=========================================================================================\n",
      "8 32 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16656 | test ppl 3.21093|test cor 0.09874\n",
      "=========================================================================================\n",
      "8 32 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17741 | test ppl 3.24594|test cor 0.05927\n",
      "=========================================================================================\n",
      "8 32 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16146 | test ppl 3.19459|test cor 0.01685\n",
      "=========================================================================================\n",
      "8 32 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16453 | test ppl 3.20442|test cor 0.00871\n",
      "=========================================================================================\n",
      "8 32 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16209 | test ppl 3.19661|test cor -0.12391\n",
      "=========================================================================================\n",
      "8 32 6 4 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17189 | test ppl 3.22807|test cor 0.04876\n",
      "=========================================================================================\n",
      "8 32 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15964 | test ppl 3.18877|test cor -0.01929\n",
      "=========================================================================================\n",
      "8 32 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16307 | test ppl 3.19973|test cor -0.15139\n",
      "=========================================================================================\n",
      "8 32 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17491 | test ppl 3.23786|test cor -0.04088\n",
      "=========================================================================================\n",
      "8 32 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.33526 | test ppl 3.80099|test cor -0.09541\n",
      "=========================================================================================\n",
      "8 32 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16019 | test ppl 3.19055|test cor -0.11681\n",
      "=========================================================================================\n",
      "8 32 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16086 | test ppl 3.19267|test cor -0.00111\n",
      "=========================================================================================\n",
      "8 32 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16362 | test ppl 3.20150|test cor 0.13114\n",
      "=========================================================================================\n",
      "8 32 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22767 | test ppl 3.41327|test cor -0.13676\n",
      "=========================================================================================\n",
      "8 32 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16085 | test ppl 3.19265|test cor -0.00279\n",
      "=========================================================================================\n",
      "8 32 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16297 | test ppl 3.19943|test cor -0.17042\n",
      "=========================================================================================\n",
      "8 32 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18063 | test ppl 3.25642|test cor 0.12635\n",
      "=========================================================================================\n",
      "8 32 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.37315 | test ppl 3.94778|test cor 0.06045\n",
      "=========================================================================================\n",
      "8 32 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15958 | test ppl 3.18860|test cor 0.06991\n",
      "=========================================================================================\n",
      "8 32 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15728 | test ppl 3.18125|test cor -0.04802\n",
      "=========================================================================================\n",
      "8 32 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16038 | test ppl 3.19116|test cor -0.07352\n",
      "=========================================================================================\n",
      "8 32 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22975 | test ppl 3.42039|test cor -0.18544\n",
      "=========================================================================================\n",
      "8 32 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16009 | test ppl 3.19022|test cor -0.09377\n",
      "=========================================================================================\n",
      "8 32 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16112 | test ppl 3.19350|test cor 0.20721\n",
      "=========================================================================================\n",
      "8 32 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16854 | test ppl 3.21728|test cor -0.18206\n",
      "=========================================================================================\n",
      "8 32 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18680 | test ppl 3.27656|test cor 0.03127\n",
      "=========================================================================================\n",
      "8 32 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16048 | test ppl 3.19146|test cor 0.18158\n",
      "=========================================================================================\n",
      "8 32 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16516 | test ppl 3.20643|test cor 0.04541\n",
      "=========================================================================================\n",
      "8 32 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16367 | test ppl 3.20167|test cor -0.08110\n",
      "=========================================================================================\n",
      "8 32 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26780 | test ppl 3.55301|test cor -0.15146\n",
      "=========================================================================================\n",
      "8 32 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16050 | test ppl 3.19153|test cor 0.20916\n",
      "=========================================================================================\n",
      "8 32 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16369 | test ppl 3.20173|test cor -0.00075\n",
      "=========================================================================================\n",
      "8 32 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18038 | test ppl 3.25562|test cor 0.18297\n",
      "=========================================================================================\n",
      "8 32 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.66019 | test ppl 5.26030|test cor 0.13688\n",
      "=========================================================================================\n",
      "8 32 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16103 | test ppl 3.19321|test cor -0.10982\n",
      "=========================================================================================\n",
      "8 32 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16182 | test ppl 3.19575|test cor 0.22541\n",
      "=========================================================================================\n",
      "8 32 8 8 0.2 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17484 | test ppl 3.23762|test cor 0.00257\n",
      "=========================================================================================\n",
      "8 32 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28373 | test ppl 3.61008|test cor -0.16589\n",
      "=========================================================================================\n",
      "8 32 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15893 | test ppl 3.18653|test cor 0.01189\n",
      "=========================================================================================\n",
      "8 32 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15938 | test ppl 3.18794|test cor -0.00865\n",
      "=========================================================================================\n",
      "8 32 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16603 | test ppl 3.20922|test cor 0.11398\n",
      "=========================================================================================\n",
      "8 32 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20777 | test ppl 3.34603|test cor 0.17961\n",
      "=========================================================================================\n",
      "8 64 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15983 | test ppl 3.18940|test cor 0.05200\n",
      "=========================================================================================\n",
      "8 64 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17008 | test ppl 3.22226|test cor -0.13425\n",
      "=========================================================================================\n",
      "8 64 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16846 | test ppl 3.21705|test cor -0.05725\n",
      "=========================================================================================\n",
      "8 64 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.31241 | test ppl 3.71511|test cor -0.04565\n",
      "=========================================================================================\n",
      "8 64 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16189 | test ppl 3.19597|test cor 0.00901\n",
      "=========================================================================================\n",
      "8 64 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16827 | test ppl 3.21644|test cor 0.11688\n",
      "=========================================================================================\n",
      "8 64 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16224 | test ppl 3.19708|test cor 0.16095\n",
      "=========================================================================================\n",
      "8 64 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25087 | test ppl 3.49339|test cor -0.23869\n",
      "=========================================================================================\n",
      "8 64 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16045 | test ppl 3.19138|test cor -0.01577\n",
      "=========================================================================================\n",
      "8 64 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16122 | test ppl 3.19384|test cor 0.09209\n",
      "=========================================================================================\n",
      "8 64 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17063 | test ppl 3.22403|test cor -0.05877\n",
      "=========================================================================================\n",
      "8 64 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22641 | test ppl 3.40897|test cor 0.12992\n",
      "=========================================================================================\n",
      "8 64 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15819 | test ppl 3.18415|test cor 0.00406\n",
      "=========================================================================================\n",
      "8 64 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16639 | test ppl 3.21040|test cor 0.07479\n",
      "=========================================================================================\n",
      "8 64 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16688 | test ppl 3.21195|test cor -0.06873\n",
      "=========================================================================================\n",
      "8 64 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24415 | test ppl 3.46999|test cor -0.13333\n",
      "=========================================================================================\n",
      "8 64 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15711 | test ppl 3.18073|test cor -0.02143\n",
      "=========================================================================================\n",
      "8 64 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16278 | test ppl 3.19880|test cor 0.03645\n",
      "=========================================================================================\n",
      "8 64 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16604 | test ppl 3.20926|test cor -0.01803\n",
      "=========================================================================================\n",
      "8 64 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.32505 | test ppl 3.76239|test cor -0.09349\n",
      "=========================================================================================\n",
      "8 64 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15995 | test ppl 3.18977|test cor 0.01314\n",
      "=========================================================================================\n",
      "8 64 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15992 | test ppl 3.18968|test cor -0.05467\n",
      "=========================================================================================\n",
      "8 64 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19612 | test ppl 3.30727|test cor 0.03229\n",
      "=========================================================================================\n",
      "8 64 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20638 | test ppl 3.34138|test cor 0.02096\n",
      "=========================================================================================\n",
      "8 64 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16297 | test ppl 3.19941|test cor 0.24285\n",
      "=========================================================================================\n",
      "8 64 4 2 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16418 | test ppl 3.20330|test cor 0.11249\n",
      "=========================================================================================\n",
      "8 64 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15945 | test ppl 3.18818|test cor -0.12962\n",
      "=========================================================================================\n",
      "8 64 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18342 | test ppl 3.26553|test cor 0.14815\n",
      "=========================================================================================\n",
      "8 64 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16308 | test ppl 3.19978|test cor -0.07528\n",
      "=========================================================================================\n",
      "8 64 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16628 | test ppl 3.21002|test cor -0.11650\n",
      "=========================================================================================\n",
      "8 64 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16723 | test ppl 3.21309|test cor 0.08740\n",
      "=========================================================================================\n",
      "8 64 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25076 | test ppl 3.49300|test cor -0.17526\n",
      "=========================================================================================\n",
      "8 64 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16553 | test ppl 3.20763|test cor 0.20114\n",
      "=========================================================================================\n",
      "8 64 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15966 | test ppl 3.18885|test cor -0.04701\n",
      "=========================================================================================\n",
      "8 64 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16585 | test ppl 3.20866|test cor 0.02323\n",
      "=========================================================================================\n",
      "8 64 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16943 | test ppl 3.22016|test cor -0.00379\n",
      "=========================================================================================\n",
      "8 64 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16078 | test ppl 3.19243|test cor -0.05244\n",
      "=========================================================================================\n",
      "8 64 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16419 | test ppl 3.20333|test cor 0.15522\n",
      "=========================================================================================\n",
      "8 64 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15733 | test ppl 3.18144|test cor 0.12699\n",
      "=========================================================================================\n",
      "8 64 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16724 | test ppl 3.21313|test cor 0.07824\n",
      "=========================================================================================\n",
      "8 64 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16012 | test ppl 3.19032|test cor 0.13460\n",
      "=========================================================================================\n",
      "8 64 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16254 | test ppl 3.19806|test cor -0.06102\n",
      "=========================================================================================\n",
      "8 64 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17798 | test ppl 3.24780|test cor -0.12004\n",
      "=========================================================================================\n",
      "8 64 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.39410 | test ppl 4.03136|test cor 0.02942\n",
      "=========================================================================================\n",
      "8 64 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16144 | test ppl 3.19454|test cor 0.00616\n",
      "=========================================================================================\n",
      "8 64 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16230 | test ppl 3.19727|test cor 0.07857\n",
      "=========================================================================================\n",
      "8 64 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16036 | test ppl 3.19107|test cor -0.01154\n",
      "=========================================================================================\n",
      "8 64 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25165 | test ppl 3.49610|test cor 0.18455\n",
      "=========================================================================================\n",
      "8 64 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15802 | test ppl 3.18362|test cor -0.03239\n",
      "=========================================================================================\n",
      "8 64 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16183 | test ppl 3.19578|test cor 0.04507\n",
      "=========================================================================================\n",
      "8 64 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17855 | test ppl 3.24964|test cor -0.00767\n",
      "=========================================================================================\n",
      "8 64 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21546 | test ppl 3.37183|test cor 0.08327\n",
      "=========================================================================================\n",
      "8 64 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16026 | test ppl 3.19075|test cor -0.05973\n",
      "=========================================================================================\n",
      "8 64 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16753 | test ppl 3.21404|test cor 0.05539\n",
      "=========================================================================================\n",
      "8 64 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17137 | test ppl 3.22642|test cor 0.03934\n",
      "=========================================================================================\n",
      "8 64 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20535 | test ppl 3.33793|test cor -0.04378\n",
      "=========================================================================================\n",
      "8 64 6 4 0.2 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16202 | test ppl 3.19640|test cor 0.08308\n",
      "=========================================================================================\n",
      "8 64 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16403 | test ppl 3.20280|test cor 0.12079\n",
      "=========================================================================================\n",
      "8 64 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18220 | test ppl 3.26153|test cor 0.20594\n",
      "=========================================================================================\n",
      "8 64 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.69627 | test ppl 5.45357|test cor 0.24477\n",
      "=========================================================================================\n",
      "8 64 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16192 | test ppl 3.19607|test cor 0.07003\n",
      "=========================================================================================\n",
      "8 64 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17099 | test ppl 3.22518|test cor -0.15143\n",
      "=========================================================================================\n",
      "8 64 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16207 | test ppl 3.19653|test cor -0.13360\n",
      "=========================================================================================\n",
      "8 64 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.64811 | test ppl 5.19715|test cor -0.04042\n",
      "=========================================================================================\n",
      "8 64 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16112 | test ppl 3.19350|test cor 0.21001\n",
      "=========================================================================================\n",
      "8 64 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15470 | test ppl 3.17307|test cor -0.04654\n",
      "=========================================================================================\n",
      "8 64 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17600 | test ppl 3.24140|test cor 0.14094\n",
      "=========================================================================================\n",
      "8 64 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20313 | test ppl 3.33053|test cor 0.17086\n",
      "=========================================================================================\n",
      "8 64 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16517 | test ppl 3.20646|test cor 0.04521\n",
      "=========================================================================================\n",
      "8 64 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17523 | test ppl 3.23887|test cor 0.02182\n",
      "=========================================================================================\n",
      "8 64 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16871 | test ppl 3.21783|test cor -0.20650\n",
      "=========================================================================================\n",
      "8 64 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19417 | test ppl 3.30081|test cor 0.12139\n",
      "=========================================================================================\n",
      "8 64 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15675 | test ppl 3.17960|test cor 0.03796\n",
      "=========================================================================================\n",
      "8 64 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16241 | test ppl 3.19764|test cor 0.13717\n",
      "=========================================================================================\n",
      "8 64 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16510 | test ppl 3.20625|test cor -0.14516\n",
      "=========================================================================================\n",
      "8 64 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17068 | test ppl 3.22418|test cor -0.03640\n",
      "=========================================================================================\n",
      "8 64 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16106 | test ppl 3.19331|test cor 0.13916\n",
      "=========================================================================================\n",
      "8 64 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16015 | test ppl 3.19040|test cor -0.06814\n",
      "=========================================================================================\n",
      "8 64 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16503 | test ppl 3.20602|test cor -0.02742\n",
      "=========================================================================================\n",
      "8 64 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20084 | test ppl 3.32291|test cor -0.23435\n",
      "=========================================================================================\n",
      "8 64 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15904 | test ppl 3.18687|test cor 0.25320\n",
      "=========================================================================================\n",
      "8 64 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16696 | test ppl 3.21220|test cor -0.13998\n",
      "=========================================================================================\n",
      "8 64 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16867 | test ppl 3.21770|test cor 0.17604\n",
      "=========================================================================================\n",
      "8 64 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26677 | test ppl 3.54937|test cor 0.19052\n",
      "=========================================================================================\n",
      "8 64 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16012 | test ppl 3.19030|test cor -0.00579\n",
      "=========================================================================================\n",
      "8 64 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16531 | test ppl 3.20692|test cor 0.18320\n",
      "=========================================================================================\n",
      "8 64 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16504 | test ppl 3.20605|test cor -0.14521\n",
      "=========================================================================================\n",
      "8 64 8 4 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.29230 | test ppl 3.64115|test cor -0.10393\n",
      "=========================================================================================\n",
      "8 64 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16040 | test ppl 3.19121|test cor -0.00021\n",
      "=========================================================================================\n",
      "8 64 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16072 | test ppl 3.19224|test cor -0.12774\n",
      "=========================================================================================\n",
      "8 64 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15937 | test ppl 3.18793|test cor 0.25383\n",
      "=========================================================================================\n",
      "8 64 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.29417 | test ppl 3.64797|test cor 0.12605\n",
      "=========================================================================================\n",
      "8 64 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16215 | test ppl 3.19678|test cor -0.09396\n",
      "=========================================================================================\n",
      "8 64 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16599 | test ppl 3.20911|test cor 0.00047\n",
      "=========================================================================================\n",
      "8 64 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17928 | test ppl 3.25203|test cor 0.06283\n",
      "=========================================================================================\n",
      "8 64 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.74802 | test ppl 5.74320|test cor -0.13001\n",
      "=========================================================================================\n",
      "8 128 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15641 | test ppl 3.17851|test cor 0.09844\n",
      "=========================================================================================\n",
      "8 128 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16222 | test ppl 3.19704|test cor -0.06949\n",
      "=========================================================================================\n",
      "8 128 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16674 | test ppl 3.21150|test cor 0.06030\n",
      "=========================================================================================\n",
      "8 128 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20133 | test ppl 3.32453|test cor -0.01388\n",
      "=========================================================================================\n",
      "8 128 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15763 | test ppl 3.18238|test cor 0.02643\n",
      "=========================================================================================\n",
      "8 128 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17306 | test ppl 3.23188|test cor -0.08278\n",
      "=========================================================================================\n",
      "8 128 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17900 | test ppl 3.25113|test cor 0.12418\n",
      "=========================================================================================\n",
      "8 128 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.30576 | test ppl 3.69050|test cor 0.05350\n",
      "=========================================================================================\n",
      "8 128 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16269 | test ppl 3.19853|test cor 0.08071\n",
      "=========================================================================================\n",
      "8 128 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16171 | test ppl 3.19538|test cor 0.20583\n",
      "=========================================================================================\n",
      "8 128 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16036 | test ppl 3.19108|test cor -0.15239\n",
      "=========================================================================================\n",
      "8 128 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19492 | test ppl 3.30330|test cor -0.04829\n",
      "=========================================================================================\n",
      "8 128 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15764 | test ppl 3.18243|test cor 0.04451\n",
      "=========================================================================================\n",
      "8 128 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16678 | test ppl 3.21164|test cor 0.09975\n",
      "=========================================================================================\n",
      "8 128 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17235 | test ppl 3.22958|test cor -0.00566\n",
      "=========================================================================================\n",
      "8 128 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.48693 | test ppl 4.42347|test cor 0.09843\n",
      "=========================================================================================\n",
      "8 128 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15492 | test ppl 3.17378|test cor 0.06467\n",
      "=========================================================================================\n",
      "8 128 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16407 | test ppl 3.20295|test cor 0.21746\n",
      "=========================================================================================\n",
      "8 128 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16427 | test ppl 3.20358|test cor -0.03951\n",
      "=========================================================================================\n",
      "8 128 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.35887 | test ppl 3.89181|test cor 0.16201\n",
      "=========================================================================================\n",
      "8 128 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17021 | test ppl 3.22268|test cor -0.03791\n",
      "=========================================================================================\n",
      "8 128 2 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16756 | test ppl 3.21414|test cor 0.08575\n",
      "=========================================================================================\n",
      "8 128 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18272 | test ppl 3.26324|test cor 0.01903\n",
      "=========================================================================================\n",
      "8 128 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21811 | test ppl 3.38078|test cor 0.07558\n",
      "=========================================================================================\n",
      "8 128 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16210 | test ppl 3.19665|test cor -0.06372\n",
      "=========================================================================================\n",
      "8 128 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16468 | test ppl 3.20490|test cor 0.02003\n",
      "=========================================================================================\n",
      "8 128 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16308 | test ppl 3.19979|test cor -0.10665\n",
      "=========================================================================================\n",
      "8 128 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18065 | test ppl 3.25649|test cor -0.26876\n",
      "=========================================================================================\n",
      "8 128 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15827 | test ppl 3.18443|test cor -0.01169\n",
      "=========================================================================================\n",
      "8 128 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16662 | test ppl 3.21111|test cor 0.06999\n",
      "=========================================================================================\n",
      "8 128 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16358 | test ppl 3.20138|test cor -0.11133\n",
      "=========================================================================================\n",
      "8 128 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.48506 | test ppl 4.41525|test cor 0.01367\n",
      "=========================================================================================\n",
      "8 128 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15641 | test ppl 3.17851|test cor 0.01230\n",
      "=========================================================================================\n",
      "8 128 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16184 | test ppl 3.19582|test cor 0.00738\n",
      "=========================================================================================\n",
      "8 128 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15677 | test ppl 3.17966|test cor 0.02643\n",
      "=========================================================================================\n",
      "8 128 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25991 | test ppl 3.52511|test cor -0.01451\n",
      "=========================================================================================\n",
      "8 128 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15857 | test ppl 3.18538|test cor -0.03878\n",
      "=========================================================================================\n",
      "8 128 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15944 | test ppl 3.18814|test cor 0.02850\n",
      "=========================================================================================\n",
      "8 128 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16135 | test ppl 3.19424|test cor 0.14074\n",
      "=========================================================================================\n",
      "8 128 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22108 | test ppl 3.39083|test cor -0.09201\n",
      "=========================================================================================\n",
      "8 128 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16045 | test ppl 3.19136|test cor -0.01749\n",
      "=========================================================================================\n",
      "8 128 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16109 | test ppl 3.19342|test cor 0.01977\n",
      "=========================================================================================\n",
      "8 128 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18834 | test ppl 3.28163|test cor -0.24984\n",
      "=========================================================================================\n",
      "8 128 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.82193 | test ppl 6.18381|test cor 0.11342\n",
      "=========================================================================================\n",
      "8 128 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16108 | test ppl 3.19337|test cor -0.10794\n",
      "=========================================================================================\n",
      "8 128 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17743 | test ppl 3.24603|test cor 0.08659\n",
      "=========================================================================================\n",
      "8 128 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16555 | test ppl 3.20769|test cor 0.07510\n",
      "=========================================================================================\n",
      "8 128 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16611 | test ppl 3.20948|test cor -0.23833\n",
      "=========================================================================================\n",
      "8 128 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16093 | test ppl 3.19291|test cor 0.06334\n",
      "=========================================================================================\n",
      "8 128 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16173 | test ppl 3.19546|test cor -0.15871\n",
      "=========================================================================================\n",
      "8 128 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18992 | test ppl 3.28682|test cor -0.06838\n",
      "=========================================================================================\n",
      "8 128 6 2 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.22504 | test ppl 3.40431|test cor 0.07278\n",
      "=========================================================================================\n",
      "8 128 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15990 | test ppl 3.18962|test cor -0.10958\n",
      "=========================================================================================\n",
      "8 128 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16219 | test ppl 3.19692|test cor 0.02822\n",
      "=========================================================================================\n",
      "8 128 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24118 | test ppl 3.45969|test cor 0.05251\n",
      "=========================================================================================\n",
      "8 128 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17711 | test ppl 3.24497|test cor -0.08811\n",
      "=========================================================================================\n",
      "8 128 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15937 | test ppl 3.18792|test cor 0.16583\n",
      "=========================================================================================\n",
      "8 128 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16304 | test ppl 3.19964|test cor 0.00442\n",
      "=========================================================================================\n",
      "8 128 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16272 | test ppl 3.19863|test cor 0.13824\n",
      "=========================================================================================\n",
      "8 128 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18279 | test ppl 3.26347|test cor -0.24954\n",
      "=========================================================================================\n",
      "8 128 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15921 | test ppl 3.18742|test cor 0.15177\n",
      "=========================================================================================\n",
      "8 128 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15982 | test ppl 3.18935|test cor 0.02126\n",
      "=========================================================================================\n",
      "8 128 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16183 | test ppl 3.19578|test cor -0.00281\n",
      "=========================================================================================\n",
      "8 128 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28313 | test ppl 3.60792|test cor 0.05182\n",
      "=========================================================================================\n",
      "8 128 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15794 | test ppl 3.18337|test cor 0.09034\n",
      "=========================================================================================\n",
      "8 128 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16121 | test ppl 3.19380|test cor 0.21345\n",
      "=========================================================================================\n",
      "8 128 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15960 | test ppl 3.18867|test cor 0.13060\n",
      "=========================================================================================\n",
      "8 128 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.39423 | test ppl 4.03186|test cor -0.02356\n",
      "=========================================================================================\n",
      "8 128 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16176 | test ppl 3.19556|test cor 0.13826\n",
      "=========================================================================================\n",
      "8 128 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16186 | test ppl 3.19588|test cor -0.11773\n",
      "=========================================================================================\n",
      "8 128 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17320 | test ppl 3.23231|test cor 0.20557\n",
      "=========================================================================================\n",
      "8 128 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16173 | test ppl 3.19545|test cor 0.07253\n",
      "=========================================================================================\n",
      "8 128 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16053 | test ppl 3.19161|test cor 0.00156\n",
      "=========================================================================================\n",
      "8 128 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16148 | test ppl 3.19466|test cor 0.04162\n",
      "=========================================================================================\n",
      "8 128 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16502 | test ppl 3.20599|test cor 0.21867\n",
      "=========================================================================================\n",
      "8 128 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18073 | test ppl 3.25677|test cor 0.07362\n",
      "=========================================================================================\n",
      "8 128 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16202 | test ppl 3.19637|test cor 0.07060\n",
      "=========================================================================================\n",
      "8 128 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16407 | test ppl 3.20293|test cor 0.12385\n",
      "=========================================================================================\n",
      "8 128 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16281 | test ppl 3.19889|test cor -0.18331\n",
      "=========================================================================================\n",
      "8 128 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19231 | test ppl 3.29468|test cor -0.01608\n",
      "=========================================================================================\n",
      "8 128 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16302 | test ppl 3.19957|test cor -0.15922\n",
      "=========================================================================================\n",
      "8 128 8 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17406 | test ppl 3.23509|test cor -0.03724\n",
      "=========================================================================================\n",
      "8 128 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16404 | test ppl 3.20284|test cor -0.08970\n",
      "=========================================================================================\n",
      "8 128 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.29521 | test ppl 3.65175|test cor 0.05960\n",
      "=========================================================================================\n",
      "8 128 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16107 | test ppl 3.19336|test cor 0.05677\n",
      "=========================================================================================\n",
      "8 128 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16224 | test ppl 3.19707|test cor -0.12804\n",
      "=========================================================================================\n",
      "8 128 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16991 | test ppl 3.22171|test cor 0.13175\n",
      "=========================================================================================\n",
      "8 128 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.36540 | test ppl 3.91728|test cor 0.10185\n",
      "=========================================================================================\n",
      "8 128 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16124 | test ppl 3.19390|test cor -0.05973\n",
      "=========================================================================================\n",
      "8 128 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16162 | test ppl 3.19511|test cor 0.19616\n",
      "=========================================================================================\n",
      "8 128 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16123 | test ppl 3.19387|test cor -0.08624\n",
      "=========================================================================================\n",
      "8 128 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.33299 | test ppl 3.79236|test cor 0.01587\n",
      "=========================================================================================\n",
      "8 128 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16054 | test ppl 3.19165|test cor -0.01810\n",
      "=========================================================================================\n",
      "8 128 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16523 | test ppl 3.20666|test cor -0.02107\n",
      "=========================================================================================\n",
      "8 128 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16021 | test ppl 3.19059|test cor -0.15683\n",
      "=========================================================================================\n",
      "8 128 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22215 | test ppl 3.39447|test cor -0.03419\n",
      "=========================================================================================\n",
      "8 256 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15866 | test ppl 3.18567|test cor -0.05412\n",
      "=========================================================================================\n",
      "8 256 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16628 | test ppl 3.21002|test cor 0.15013\n",
      "=========================================================================================\n",
      "8 256 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17112 | test ppl 3.22560|test cor -0.04409\n",
      "=========================================================================================\n",
      "8 256 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20367 | test ppl 3.33233|test cor 0.12387\n",
      "=========================================================================================\n",
      "8 256 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15881 | test ppl 3.18613|test cor -0.00981\n",
      "=========================================================================================\n",
      "8 256 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17094 | test ppl 3.22503|test cor 0.05634\n",
      "=========================================================================================\n",
      "8 256 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17497 | test ppl 3.23806|test cor 0.05706\n",
      "=========================================================================================\n",
      "8 256 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19890 | test ppl 3.31646|test cor 0.12391\n",
      "=========================================================================================\n",
      "8 256 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15851 | test ppl 3.18519|test cor -0.04089\n",
      "=========================================================================================\n",
      "8 256 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16255 | test ppl 3.19808|test cor 0.13914\n",
      "=========================================================================================\n",
      "8 256 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16921 | test ppl 3.21944|test cor -0.01509\n",
      "=========================================================================================\n",
      "8 256 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19962 | test ppl 3.31886|test cor -0.00494\n",
      "=========================================================================================\n",
      "8 256 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16203 | test ppl 3.19642|test cor -0.01898\n",
      "=========================================================================================\n",
      "8 256 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16499 | test ppl 3.20590|test cor 0.11592\n",
      "=========================================================================================\n",
      "8 256 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16585 | test ppl 3.20866|test cor -0.14754\n",
      "=========================================================================================\n",
      "8 256 2 4 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.70899 | test ppl 5.52336|test cor 0.02573\n",
      "=========================================================================================\n",
      "8 256 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16399 | test ppl 3.20269|test cor 0.04905\n",
      "=========================================================================================\n",
      "8 256 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15697 | test ppl 3.18029|test cor 0.00716\n",
      "=========================================================================================\n",
      "8 256 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16214 | test ppl 3.19677|test cor 0.26176\n",
      "=========================================================================================\n",
      "8 256 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19221 | test ppl 3.29435|test cor -0.17094\n",
      "=========================================================================================\n",
      "8 256 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16040 | test ppl 3.19121|test cor -0.01735\n",
      "=========================================================================================\n",
      "8 256 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16885 | test ppl 3.21830|test cor -0.08162\n",
      "=========================================================================================\n",
      "8 256 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15983 | test ppl 3.18939|test cor 0.12559\n",
      "=========================================================================================\n",
      "8 256 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.34464 | test ppl 3.83681|test cor -0.05808\n",
      "=========================================================================================\n",
      "8 256 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16017 | test ppl 3.19048|test cor -0.05885\n",
      "=========================================================================================\n",
      "8 256 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15804 | test ppl 3.18367|test cor 0.00796\n",
      "=========================================================================================\n",
      "8 256 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16488 | test ppl 3.20553|test cor -0.05962\n",
      "=========================================================================================\n",
      "8 256 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19512 | test ppl 3.30396|test cor -0.02532\n",
      "=========================================================================================\n",
      "8 256 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16373 | test ppl 3.20186|test cor 0.04382\n",
      "=========================================================================================\n",
      "8 256 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16539 | test ppl 3.20718|test cor 0.16044\n",
      "=========================================================================================\n",
      "8 256 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15832 | test ppl 3.18457|test cor -0.08425\n",
      "=========================================================================================\n",
      "8 256 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16392 | test ppl 3.20246|test cor 0.00094\n",
      "=========================================================================================\n",
      "8 256 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15962 | test ppl 3.18872|test cor 0.10491\n",
      "=========================================================================================\n",
      "8 256 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16335 | test ppl 3.20065|test cor -0.03153\n",
      "=========================================================================================\n",
      "8 256 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17621 | test ppl 3.24205|test cor -0.07170\n",
      "=========================================================================================\n",
      "8 256 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19967 | test ppl 3.31901|test cor 0.02614\n",
      "=========================================================================================\n",
      "8 256 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16140 | test ppl 3.19439|test cor 0.01193\n",
      "=========================================================================================\n",
      "8 256 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16301 | test ppl 3.19955|test cor 0.04878\n",
      "=========================================================================================\n",
      "8 256 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17566 | test ppl 3.24027|test cor -0.13783\n",
      "=========================================================================================\n",
      "8 256 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19009 | test ppl 3.28737|test cor 0.13218\n",
      "=========================================================================================\n",
      "8 256 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16166 | test ppl 3.19524|test cor 0.01600\n",
      "=========================================================================================\n",
      "8 256 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16407 | test ppl 3.20295|test cor -0.17933\n",
      "=========================================================================================\n",
      "8 256 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16324 | test ppl 3.20030|test cor 0.19151\n",
      "=========================================================================================\n",
      "8 256 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17875 | test ppl 3.25031|test cor -0.06304\n",
      "=========================================================================================\n",
      "8 256 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16041 | test ppl 3.19125|test cor 0.11412\n",
      "=========================================================================================\n",
      "8 256 4 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.15957 | test ppl 3.18856|test cor 0.04880\n",
      "=========================================================================================\n",
      "8 256 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16117 | test ppl 3.19368|test cor -0.02013\n",
      "=========================================================================================\n",
      "8 256 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24554 | test ppl 3.47480|test cor 0.02295\n",
      "=========================================================================================\n",
      "8 256 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16184 | test ppl 3.19581|test cor -0.11046\n",
      "=========================================================================================\n",
      "8 256 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16057 | test ppl 3.19175|test cor -0.21292\n",
      "=========================================================================================\n",
      "8 256 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16145 | test ppl 3.19457|test cor -0.03442\n",
      "=========================================================================================\n",
      "8 256 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16858 | test ppl 3.21743|test cor -0.04557\n",
      "=========================================================================================\n",
      "8 256 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16128 | test ppl 3.19402|test cor 0.02570\n",
      "=========================================================================================\n",
      "8 256 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16354 | test ppl 3.20125|test cor -0.14965\n",
      "=========================================================================================\n",
      "8 256 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16732 | test ppl 3.21335|test cor 0.15923\n",
      "=========================================================================================\n",
      "8 256 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18431 | test ppl 3.26844|test cor -0.06608\n",
      "=========================================================================================\n",
      "8 256 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15958 | test ppl 3.18858|test cor 0.05883\n",
      "=========================================================================================\n",
      "8 256 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16596 | test ppl 3.20901|test cor -0.17279\n",
      "=========================================================================================\n",
      "8 256 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17975 | test ppl 3.25355|test cor -0.01326\n",
      "=========================================================================================\n",
      "8 256 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20362 | test ppl 3.33215|test cor -0.02569\n",
      "=========================================================================================\n",
      "8 256 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16170 | test ppl 3.19536|test cor -0.19765\n",
      "=========================================================================================\n",
      "8 256 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16510 | test ppl 3.20625|test cor -0.06154\n",
      "=========================================================================================\n",
      "8 256 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16547 | test ppl 3.20743|test cor -0.18476\n",
      "=========================================================================================\n",
      "8 256 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22213 | test ppl 3.39441|test cor -0.02213\n",
      "=========================================================================================\n",
      "8 256 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16303 | test ppl 3.19960|test cor -0.08690\n",
      "=========================================================================================\n",
      "8 256 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16146 | test ppl 3.19458|test cor -0.09929\n",
      "=========================================================================================\n",
      "8 256 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15706 | test ppl 3.18057|test cor -0.11474\n",
      "=========================================================================================\n",
      "8 256 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18978 | test ppl 3.28637|test cor 0.00700\n",
      "=========================================================================================\n",
      "8 256 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16035 | test ppl 3.19106|test cor -0.10613\n",
      "=========================================================================================\n",
      "8 256 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15574 | test ppl 3.17637|test cor -0.00537\n",
      "=========================================================================================\n",
      "8 256 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16434 | test ppl 3.20381|test cor -0.06889\n",
      "=========================================================================================\n",
      "8 256 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20146 | test ppl 3.32498|test cor 0.07322\n",
      "=========================================================================================\n",
      "8 256 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15657 | test ppl 3.17900|test cor 0.02760\n",
      "=========================================================================================\n",
      "8 256 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16387 | test ppl 3.20231|test cor 0.12410\n",
      "=========================================================================================\n",
      "8 256 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16562 | test ppl 3.20792|test cor 0.16352\n",
      "=========================================================================================\n",
      "8 256 8 2 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.45977 | test ppl 4.30499|test cor 0.05360\n",
      "=========================================================================================\n",
      "8 256 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16156 | test ppl 3.19491|test cor -0.03842\n",
      "=========================================================================================\n",
      "8 256 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16099 | test ppl 3.19308|test cor -0.09944\n",
      "=========================================================================================\n",
      "8 256 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15912 | test ppl 3.18713|test cor 0.03403\n",
      "=========================================================================================\n",
      "8 256 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18338 | test ppl 3.26541|test cor -0.05917\n",
      "=========================================================================================\n",
      "8 256 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16123 | test ppl 3.19385|test cor -0.18474\n",
      "=========================================================================================\n",
      "8 256 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16652 | test ppl 3.21081|test cor 0.08066\n",
      "=========================================================================================\n",
      "8 256 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15962 | test ppl 3.18872|test cor 0.01794\n",
      "=========================================================================================\n",
      "8 256 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16714 | test ppl 3.21278|test cor 0.12635\n",
      "=========================================================================================\n",
      "8 256 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16271 | test ppl 3.19860|test cor -0.04145\n",
      "=========================================================================================\n",
      "8 256 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16388 | test ppl 3.20234|test cor -0.18666\n",
      "=========================================================================================\n",
      "8 256 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16493 | test ppl 3.20569|test cor 0.04048\n",
      "=========================================================================================\n",
      "8 256 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24693 | test ppl 3.47966|test cor -0.01719\n",
      "=========================================================================================\n",
      "8 256 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15998 | test ppl 3.18988|test cor -0.01968\n",
      "=========================================================================================\n",
      "8 256 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16327 | test ppl 3.20038|test cor 0.06740\n",
      "=========================================================================================\n",
      "8 256 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16174 | test ppl 3.19550|test cor 0.03281\n",
      "=========================================================================================\n",
      "8 256 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16771 | test ppl 3.21463|test cor 0.17524\n",
      "=========================================================================================\n",
      "8 256 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16046 | test ppl 3.19140|test cor -0.02634\n",
      "=========================================================================================\n",
      "8 256 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16205 | test ppl 3.19647|test cor 0.13429\n",
      "=========================================================================================\n",
      "8 256 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16278 | test ppl 3.19881|test cor 0.10822\n",
      "=========================================================================================\n",
      "8 256 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16577 | test ppl 3.20840|test cor 0.07813\n",
      "=========================================================================================\n",
      "32 8 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15826 | test ppl 3.18438|test cor 0.06302\n",
      "=========================================================================================\n",
      "32 8 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15863 | test ppl 3.18558|test cor -0.05174\n",
      "=========================================================================================\n",
      "32 8 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15447 | test ppl 3.17234|test cor -0.02102\n",
      "=========================================================================================\n",
      "32 8 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20566 | test ppl 3.33896|test cor -0.05387\n",
      "=========================================================================================\n",
      "32 8 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15781 | test ppl 3.18296|test cor 0.07287\n",
      "=========================================================================================\n",
      "32 8 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17215 | test ppl 3.22891|test cor 0.15189\n",
      "=========================================================================================\n",
      "32 8 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17123 | test ppl 3.22596|test cor 0.13348\n",
      "=========================================================================================\n",
      "32 8 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23655 | test ppl 3.44370|test cor 0.04706\n",
      "=========================================================================================\n",
      "32 8 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17320 | test ppl 3.23233|test cor 0.10418\n",
      "=========================================================================================\n",
      "32 8 2 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16154 | test ppl 3.19485|test cor 0.12475\n",
      "=========================================================================================\n",
      "32 8 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15627 | test ppl 3.17807|test cor 0.14628\n",
      "=========================================================================================\n",
      "32 8 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21984 | test ppl 3.38665|test cor 0.00373\n",
      "=========================================================================================\n",
      "32 8 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16344 | test ppl 3.20091|test cor -0.01074\n",
      "=========================================================================================\n",
      "32 8 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16606 | test ppl 3.20933|test cor 0.04425\n",
      "=========================================================================================\n",
      "32 8 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16169 | test ppl 3.19533|test cor 0.09176\n",
      "=========================================================================================\n",
      "32 8 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22407 | test ppl 3.40099|test cor -0.08129\n",
      "=========================================================================================\n",
      "32 8 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16278 | test ppl 3.19881|test cor 0.05980\n",
      "=========================================================================================\n",
      "32 8 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15720 | test ppl 3.18100|test cor 0.09364\n",
      "=========================================================================================\n",
      "32 8 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16332 | test ppl 3.20055|test cor 0.10303\n",
      "=========================================================================================\n",
      "32 8 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18475 | test ppl 3.26986|test cor 0.07283\n",
      "=========================================================================================\n",
      "32 8 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15849 | test ppl 3.18511|test cor -0.00434\n",
      "=========================================================================================\n",
      "32 8 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17047 | test ppl 3.22350|test cor 0.01399\n",
      "=========================================================================================\n",
      "32 8 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16076 | test ppl 3.19235|test cor -0.02168\n",
      "=========================================================================================\n",
      "32 8 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23051 | test ppl 3.42299|test cor 0.04427\n",
      "=========================================================================================\n",
      "32 8 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18341 | test ppl 3.26548|test cor 0.13438\n",
      "=========================================================================================\n",
      "32 8 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16044 | test ppl 3.19134|test cor 0.10360\n",
      "=========================================================================================\n",
      "32 8 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15877 | test ppl 3.18601|test cor 0.04845\n",
      "=========================================================================================\n",
      "32 8 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22765 | test ppl 3.41319|test cor -0.18142\n",
      "=========================================================================================\n",
      "32 8 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15933 | test ppl 3.18781|test cor 0.16317\n",
      "=========================================================================================\n",
      "32 8 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17610 | test ppl 3.24172|test cor 0.08184\n",
      "=========================================================================================\n",
      "32 8 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18772 | test ppl 3.27958|test cor -0.17000\n",
      "=========================================================================================\n",
      "32 8 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17404 | test ppl 3.23504|test cor -0.13676\n",
      "=========================================================================================\n",
      "32 8 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16512 | test ppl 3.20630|test cor 0.15636\n",
      "=========================================================================================\n",
      "32 8 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16093 | test ppl 3.19291|test cor 0.16661\n",
      "=========================================================================================\n",
      "32 8 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16478 | test ppl 3.20522|test cor 0.06599\n",
      "=========================================================================================\n",
      "32 8 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19077 | test ppl 3.28961|test cor -0.02129\n",
      "=========================================================================================\n",
      "32 8 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16115 | test ppl 3.19360|test cor 0.15678\n",
      "=========================================================================================\n",
      "32 8 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17459 | test ppl 3.23683|test cor 0.06532\n",
      "=========================================================================================\n",
      "32 8 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17360 | test ppl 3.23363|test cor 0.03171\n",
      "=========================================================================================\n",
      "32 8 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20167 | test ppl 3.32567|test cor 0.12586\n",
      "=========================================================================================\n",
      "32 8 4 8 0.2 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16263 | test ppl 3.19833|test cor 0.10826\n",
      "=========================================================================================\n",
      "32 8 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16270 | test ppl 3.19855|test cor -0.01011\n",
      "=========================================================================================\n",
      "32 8 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16532 | test ppl 3.20695|test cor 0.16137\n",
      "=========================================================================================\n",
      "32 8 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.30929 | test ppl 3.70356|test cor 0.06000\n",
      "=========================================================================================\n",
      "32 8 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17076 | test ppl 3.22443|test cor 0.12768\n",
      "=========================================================================================\n",
      "32 8 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15903 | test ppl 3.18685|test cor -0.04379\n",
      "=========================================================================================\n",
      "32 8 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16662 | test ppl 3.21111|test cor 0.18771\n",
      "=========================================================================================\n",
      "32 8 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26174 | test ppl 3.53155|test cor -0.06798\n",
      "=========================================================================================\n",
      "32 8 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15964 | test ppl 3.18879|test cor 0.18563\n",
      "=========================================================================================\n",
      "32 8 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16534 | test ppl 3.20701|test cor 0.25177\n",
      "=========================================================================================\n",
      "32 8 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15871 | test ppl 3.18582|test cor 0.08679\n",
      "=========================================================================================\n",
      "32 8 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18893 | test ppl 3.28356|test cor 0.00356\n",
      "=========================================================================================\n",
      "32 8 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16567 | test ppl 3.20808|test cor 0.11074\n",
      "=========================================================================================\n",
      "32 8 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16441 | test ppl 3.20403|test cor -0.14160\n",
      "=========================================================================================\n",
      "32 8 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15956 | test ppl 3.18854|test cor 0.15844\n",
      "=========================================================================================\n",
      "32 8 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17452 | test ppl 3.23661|test cor 0.19008\n",
      "=========================================================================================\n",
      "32 8 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16895 | test ppl 3.21862|test cor 0.21729\n",
      "=========================================================================================\n",
      "32 8 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16338 | test ppl 3.20075|test cor 0.21509\n",
      "=========================================================================================\n",
      "32 8 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16998 | test ppl 3.22193|test cor 0.19286\n",
      "=========================================================================================\n",
      "32 8 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16342 | test ppl 3.20086|test cor -0.17927\n",
      "=========================================================================================\n",
      "32 8 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16276 | test ppl 3.19875|test cor 0.21505\n",
      "=========================================================================================\n",
      "32 8 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16610 | test ppl 3.20945|test cor -0.13754\n",
      "=========================================================================================\n",
      "32 8 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16503 | test ppl 3.20601|test cor -0.12201\n",
      "=========================================================================================\n",
      "32 8 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21998 | test ppl 3.38714|test cor 0.02030\n",
      "=========================================================================================\n",
      "32 8 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16190 | test ppl 3.19599|test cor 0.16292\n",
      "=========================================================================================\n",
      "32 8 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16235 | test ppl 3.19745|test cor 0.15120\n",
      "=========================================================================================\n",
      "32 8 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16136 | test ppl 3.19428|test cor -0.19142\n",
      "=========================================================================================\n",
      "32 8 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16491 | test ppl 3.20564|test cor 0.01614\n",
      "=========================================================================================\n",
      "32 8 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17236 | test ppl 3.22961|test cor 0.12945\n",
      "=========================================================================================\n",
      "32 8 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16160 | test ppl 3.19503|test cor 0.21066\n",
      "=========================================================================================\n",
      "32 8 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16421 | test ppl 3.20339|test cor 0.11693\n",
      "=========================================================================================\n",
      "32 8 6 8 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.18104 | test ppl 3.25775|test cor 0.01001\n",
      "=========================================================================================\n",
      "32 8 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16649 | test ppl 3.21070|test cor 0.14400\n",
      "=========================================================================================\n",
      "32 8 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16928 | test ppl 3.21967|test cor 0.26101\n",
      "=========================================================================================\n",
      "32 8 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15887 | test ppl 3.18634|test cor -0.22902\n",
      "=========================================================================================\n",
      "32 8 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18678 | test ppl 3.27652|test cor -0.18514\n",
      "=========================================================================================\n",
      "32 8 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16245 | test ppl 3.19775|test cor 0.14511\n",
      "=========================================================================================\n",
      "32 8 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16207 | test ppl 3.19655|test cor 0.02481\n",
      "=========================================================================================\n",
      "32 8 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16150 | test ppl 3.19472|test cor -0.10686\n",
      "=========================================================================================\n",
      "32 8 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.33972 | test ppl 3.81798|test cor -0.20998\n",
      "=========================================================================================\n",
      "32 8 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16915 | test ppl 3.21927|test cor 0.15951\n",
      "=========================================================================================\n",
      "32 8 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16484 | test ppl 3.20540|test cor -0.08773\n",
      "=========================================================================================\n",
      "32 8 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17476 | test ppl 3.23738|test cor -0.25311\n",
      "=========================================================================================\n",
      "32 8 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24825 | test ppl 3.48423|test cor -0.00099\n",
      "=========================================================================================\n",
      "32 8 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17268 | test ppl 3.23063|test cor 0.18496\n",
      "=========================================================================================\n",
      "32 8 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16220 | test ppl 3.19695|test cor -0.04404\n",
      "=========================================================================================\n",
      "32 8 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15928 | test ppl 3.18763|test cor 0.03184\n",
      "=========================================================================================\n",
      "32 8 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17548 | test ppl 3.23970|test cor -0.22468\n",
      "=========================================================================================\n",
      "32 8 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16904 | test ppl 3.21889|test cor 0.16985\n",
      "=========================================================================================\n",
      "32 8 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16212 | test ppl 3.19671|test cor 0.13185\n",
      "=========================================================================================\n",
      "32 8 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16969 | test ppl 3.22101|test cor -0.25082\n",
      "=========================================================================================\n",
      "32 8 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16407 | test ppl 3.20293|test cor -0.06423\n",
      "=========================================================================================\n",
      "32 8 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16385 | test ppl 3.20225|test cor 0.18605\n",
      "=========================================================================================\n",
      "32 8 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16221 | test ppl 3.19699|test cor -0.01325\n",
      "=========================================================================================\n",
      "32 8 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15846 | test ppl 3.18502|test cor 0.08599\n",
      "=========================================================================================\n",
      "32 8 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19093 | test ppl 3.29015|test cor -0.12144\n",
      "=========================================================================================\n",
      "32 32 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15621 | test ppl 3.17787|test cor 0.05150\n",
      "=========================================================================================\n",
      "32 32 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16927 | test ppl 3.21964|test cor -0.06818\n",
      "=========================================================================================\n",
      "32 32 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16781 | test ppl 3.21496|test cor -0.05635\n",
      "=========================================================================================\n",
      "32 32 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19539 | test ppl 3.30485|test cor -0.02227\n",
      "=========================================================================================\n",
      "32 32 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16101 | test ppl 3.19316|test cor -0.00783\n",
      "=========================================================================================\n",
      "32 32 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16350 | test ppl 3.20113|test cor 0.06488\n",
      "=========================================================================================\n",
      "32 32 2 2 0.5 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16931 | test ppl 3.21976|test cor 0.07962\n",
      "=========================================================================================\n",
      "32 32 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.34553 | test ppl 3.84022|test cor -0.04892\n",
      "=========================================================================================\n",
      "32 32 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17058 | test ppl 3.22387|test cor 0.00525\n",
      "=========================================================================================\n",
      "32 32 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16088 | test ppl 3.19274|test cor 0.10696\n",
      "=========================================================================================\n",
      "32 32 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16408 | test ppl 3.20299|test cor -0.04028\n",
      "=========================================================================================\n",
      "32 32 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19901 | test ppl 3.31684|test cor 0.10410\n",
      "=========================================================================================\n",
      "32 32 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15989 | test ppl 3.18958|test cor -0.00907\n",
      "=========================================================================================\n",
      "32 32 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16711 | test ppl 3.21268|test cor 0.01311\n",
      "=========================================================================================\n",
      "32 32 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16202 | test ppl 3.19638|test cor 0.07333\n",
      "=========================================================================================\n",
      "32 32 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20240 | test ppl 3.32809|test cor -0.02118\n",
      "=========================================================================================\n",
      "32 32 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16096 | test ppl 3.19299|test cor 0.05646\n",
      "=========================================================================================\n",
      "32 32 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15781 | test ppl 3.18295|test cor 0.04746\n",
      "=========================================================================================\n",
      "32 32 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17081 | test ppl 3.22460|test cor -0.15899\n",
      "=========================================================================================\n",
      "32 32 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16696 | test ppl 3.21223|test cor -0.12371\n",
      "=========================================================================================\n",
      "32 32 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16171 | test ppl 3.19541|test cor -0.03223\n",
      "=========================================================================================\n",
      "32 32 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16540 | test ppl 3.20721|test cor -0.15899\n",
      "=========================================================================================\n",
      "32 32 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16402 | test ppl 3.20278|test cor -0.01634\n",
      "=========================================================================================\n",
      "32 32 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28547 | test ppl 3.61635|test cor -0.11055\n",
      "=========================================================================================\n",
      "32 32 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17184 | test ppl 3.22794|test cor 0.06204\n",
      "=========================================================================================\n",
      "32 32 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16383 | test ppl 3.20219|test cor 0.12552\n",
      "=========================================================================================\n",
      "32 32 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17116 | test ppl 3.22575|test cor -0.12212\n",
      "=========================================================================================\n",
      "32 32 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17810 | test ppl 3.24819|test cor -0.10719\n",
      "=========================================================================================\n",
      "32 32 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15867 | test ppl 3.18568|test cor 0.04123\n",
      "=========================================================================================\n",
      "32 32 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15687 | test ppl 3.17997|test cor -0.07864\n",
      "=========================================================================================\n",
      "32 32 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16606 | test ppl 3.20934|test cor 0.11351\n",
      "=========================================================================================\n",
      "32 32 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21144 | test ppl 3.35830|test cor 0.22290\n",
      "=========================================================================================\n",
      "32 32 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16204 | test ppl 3.19645|test cor 0.07986\n",
      "=========================================================================================\n",
      "32 32 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16201 | test ppl 3.19636|test cor 0.20690\n",
      "=========================================================================================\n",
      "32 32 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15946 | test ppl 3.18820|test cor -0.16455\n",
      "=========================================================================================\n",
      "32 32 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22393 | test ppl 3.40053|test cor 0.05273\n",
      "=========================================================================================\n",
      "32 32 4 4 0.5 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.15996 | test ppl 3.18980|test cor 0.03970\n",
      "=========================================================================================\n",
      "32 32 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16546 | test ppl 3.20741|test cor 0.00743\n",
      "=========================================================================================\n",
      "32 32 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16336 | test ppl 3.20067|test cor -0.03090\n",
      "=========================================================================================\n",
      "32 32 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.40829 | test ppl 4.08894|test cor 0.16104\n",
      "=========================================================================================\n",
      "32 32 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15656 | test ppl 3.17897|test cor 0.08062\n",
      "=========================================================================================\n",
      "32 32 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16080 | test ppl 3.19249|test cor 0.14236\n",
      "=========================================================================================\n",
      "32 32 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15974 | test ppl 3.18909|test cor 0.15058\n",
      "=========================================================================================\n",
      "32 32 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.55415 | test ppl 4.73108|test cor -0.04641\n",
      "=========================================================================================\n",
      "32 32 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16320 | test ppl 3.20016|test cor 0.13376\n",
      "=========================================================================================\n",
      "32 32 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16420 | test ppl 3.20335|test cor -0.15837\n",
      "=========================================================================================\n",
      "32 32 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16960 | test ppl 3.22069|test cor 0.10508\n",
      "=========================================================================================\n",
      "32 32 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20595 | test ppl 3.33993|test cor -0.18567\n",
      "=========================================================================================\n",
      "32 32 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18009 | test ppl 3.25465|test cor 0.07389\n",
      "=========================================================================================\n",
      "32 32 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16074 | test ppl 3.19228|test cor 0.05084\n",
      "=========================================================================================\n",
      "32 32 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16234 | test ppl 3.19740|test cor -0.03999\n",
      "=========================================================================================\n",
      "32 32 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18687 | test ppl 3.27681|test cor 0.05137\n",
      "=========================================================================================\n",
      "32 32 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16340 | test ppl 3.20078|test cor -0.04883\n",
      "=========================================================================================\n",
      "32 32 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16075 | test ppl 3.19233|test cor -0.10910\n",
      "=========================================================================================\n",
      "32 32 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17110 | test ppl 3.22552|test cor -0.05520\n",
      "=========================================================================================\n",
      "32 32 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19507 | test ppl 3.30380|test cor -0.12672\n",
      "=========================================================================================\n",
      "32 32 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18121 | test ppl 3.25832|test cor 0.18811\n",
      "=========================================================================================\n",
      "32 32 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16338 | test ppl 3.20075|test cor -0.18321\n",
      "=========================================================================================\n",
      "32 32 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16431 | test ppl 3.20370|test cor -0.00705\n",
      "=========================================================================================\n",
      "32 32 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19558 | test ppl 3.30547|test cor 0.04020\n",
      "=========================================================================================\n",
      "32 32 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16298 | test ppl 3.19945|test cor 0.17044\n",
      "=========================================================================================\n",
      "32 32 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16208 | test ppl 3.19658|test cor 0.06852\n",
      "=========================================================================================\n",
      "32 32 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16271 | test ppl 3.19860|test cor -0.13275\n",
      "=========================================================================================\n",
      "32 32 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21390 | test ppl 3.36661|test cor 0.03809\n",
      "=========================================================================================\n",
      "32 32 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16504 | test ppl 3.20606|test cor 0.19981\n",
      "=========================================================================================\n",
      "32 32 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16329 | test ppl 3.20045|test cor -0.07373\n",
      "=========================================================================================\n",
      "32 32 6 8 0.2 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17469 | test ppl 3.23714|test cor 0.08522\n",
      "=========================================================================================\n",
      "32 32 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17012 | test ppl 3.22239|test cor 0.10454\n",
      "=========================================================================================\n",
      "32 32 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15935 | test ppl 3.18784|test cor 0.13659\n",
      "=========================================================================================\n",
      "32 32 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16551 | test ppl 3.20755|test cor 0.00131\n",
      "=========================================================================================\n",
      "32 32 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17409 | test ppl 3.23520|test cor 0.05840\n",
      "=========================================================================================\n",
      "32 32 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18911 | test ppl 3.28416|test cor 0.04399\n",
      "=========================================================================================\n",
      "32 32 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16819 | test ppl 3.21617|test cor 0.22137\n",
      "=========================================================================================\n",
      "32 32 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16027 | test ppl 3.19080|test cor 0.09840\n",
      "=========================================================================================\n",
      "32 32 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17073 | test ppl 3.22436|test cor -0.11225\n",
      "=========================================================================================\n",
      "32 32 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16470 | test ppl 3.20495|test cor -0.09562\n",
      "=========================================================================================\n",
      "32 32 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16271 | test ppl 3.19859|test cor 0.15166\n",
      "=========================================================================================\n",
      "32 32 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17374 | test ppl 3.23405|test cor 0.22551\n",
      "=========================================================================================\n",
      "32 32 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16822 | test ppl 3.21626|test cor -0.14294\n",
      "=========================================================================================\n",
      "32 32 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24949 | test ppl 3.48856|test cor 0.00614\n",
      "=========================================================================================\n",
      "32 32 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18033 | test ppl 3.25546|test cor 0.06201\n",
      "=========================================================================================\n",
      "32 32 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16465 | test ppl 3.20480|test cor -0.21219\n",
      "=========================================================================================\n",
      "32 32 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16370 | test ppl 3.20177|test cor -0.11519\n",
      "=========================================================================================\n",
      "32 32 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20286 | test ppl 3.32964|test cor 0.16254\n",
      "=========================================================================================\n",
      "32 32 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16308 | test ppl 3.19978|test cor 0.20347\n",
      "=========================================================================================\n",
      "32 32 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16073 | test ppl 3.19225|test cor 0.09970\n",
      "=========================================================================================\n",
      "32 32 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16073 | test ppl 3.19228|test cor -0.14057\n",
      "=========================================================================================\n",
      "32 32 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17453 | test ppl 3.23662|test cor -0.15303\n",
      "=========================================================================================\n",
      "32 32 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17900 | test ppl 3.25113|test cor 0.19605\n",
      "=========================================================================================\n",
      "32 32 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16665 | test ppl 3.21121|test cor -0.04781\n",
      "=========================================================================================\n",
      "32 32 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16475 | test ppl 3.20512|test cor 0.09348\n",
      "=========================================================================================\n",
      "32 32 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.61045 | test ppl 5.00508|test cor -0.04146\n",
      "=========================================================================================\n",
      "32 32 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16465 | test ppl 3.20479|test cor 0.19396\n",
      "=========================================================================================\n",
      "32 32 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16309 | test ppl 3.19981|test cor 0.02965\n",
      "=========================================================================================\n",
      "32 32 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16093 | test ppl 3.19289|test cor -0.17249\n",
      "=========================================================================================\n",
      "32 32 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17139 | test ppl 3.22647|test cor 0.16662\n",
      "=========================================================================================\n",
      "32 64 2 2 0.2 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.18259 | test ppl 3.26283|test cor 0.07725\n",
      "=========================================================================================\n",
      "32 64 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16381 | test ppl 3.20211|test cor -0.06266\n",
      "=========================================================================================\n",
      "32 64 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16292 | test ppl 3.19926|test cor -0.10187\n",
      "=========================================================================================\n",
      "32 64 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.33407 | test ppl 3.79646|test cor -0.01921\n",
      "=========================================================================================\n",
      "32 64 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16029 | test ppl 3.19086|test cor -0.01844\n",
      "=========================================================================================\n",
      "32 64 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15628 | test ppl 3.17808|test cor 0.03474\n",
      "=========================================================================================\n",
      "32 64 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18881 | test ppl 3.28316|test cor 0.01050\n",
      "=========================================================================================\n",
      "32 64 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17882 | test ppl 3.25055|test cor 0.10660\n",
      "=========================================================================================\n",
      "32 64 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15644 | test ppl 3.17859|test cor 0.04798\n",
      "=========================================================================================\n",
      "32 64 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16144 | test ppl 3.19454|test cor 0.02451\n",
      "=========================================================================================\n",
      "32 64 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16490 | test ppl 3.20560|test cor -0.02960\n",
      "=========================================================================================\n",
      "32 64 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.70828 | test ppl 5.51946|test cor 0.02070\n",
      "=========================================================================================\n",
      "32 64 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15940 | test ppl 3.18804|test cor 0.02250\n",
      "=========================================================================================\n",
      "32 64 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16406 | test ppl 3.20292|test cor 0.06831\n",
      "=========================================================================================\n",
      "32 64 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16668 | test ppl 3.21131|test cor 0.05938\n",
      "=========================================================================================\n",
      "32 64 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17493 | test ppl 3.23793|test cor -0.01441\n",
      "=========================================================================================\n",
      "32 64 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17769 | test ppl 3.24686|test cor 0.06489\n",
      "=========================================================================================\n",
      "32 64 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16101 | test ppl 3.19314|test cor 0.01682\n",
      "=========================================================================================\n",
      "32 64 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17002 | test ppl 3.22206|test cor 0.01399\n",
      "=========================================================================================\n",
      "32 64 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18286 | test ppl 3.26370|test cor -0.02552\n",
      "=========================================================================================\n",
      "32 64 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17418 | test ppl 3.23548|test cor -0.00575\n",
      "=========================================================================================\n",
      "32 64 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15709 | test ppl 3.18065|test cor 0.15031\n",
      "=========================================================================================\n",
      "32 64 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16568 | test ppl 3.20809|test cor 0.08742\n",
      "=========================================================================================\n",
      "32 64 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.40202 | test ppl 4.06342|test cor -0.03167\n",
      "=========================================================================================\n",
      "32 64 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15817 | test ppl 3.18409|test cor 0.06613\n",
      "=========================================================================================\n",
      "32 64 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16058 | test ppl 3.19178|test cor -0.13917\n",
      "=========================================================================================\n",
      "32 64 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15987 | test ppl 3.18953|test cor -0.13522\n",
      "=========================================================================================\n",
      "32 64 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17436 | test ppl 3.23607|test cor 0.06377\n",
      "=========================================================================================\n",
      "32 64 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16203 | test ppl 3.19641|test cor 0.00702\n",
      "=========================================================================================\n",
      "32 64 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16700 | test ppl 3.21233|test cor -0.00272\n",
      "=========================================================================================\n",
      "32 64 4 2 0.5 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16972 | test ppl 3.22109|test cor -0.17601\n",
      "=========================================================================================\n",
      "32 64 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.50457 | test ppl 4.50223|test cor -0.05158\n",
      "=========================================================================================\n",
      "32 64 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17502 | test ppl 3.23821|test cor 0.17238\n",
      "=========================================================================================\n",
      "32 64 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15850 | test ppl 3.18514|test cor 0.15894\n",
      "=========================================================================================\n",
      "32 64 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16322 | test ppl 3.20023|test cor 0.15369\n",
      "=========================================================================================\n",
      "32 64 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24351 | test ppl 3.46777|test cor -0.00178\n",
      "=========================================================================================\n",
      "32 64 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15691 | test ppl 3.18009|test cor 0.08442\n",
      "=========================================================================================\n",
      "32 64 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16316 | test ppl 3.20003|test cor 0.07690\n",
      "=========================================================================================\n",
      "32 64 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16700 | test ppl 3.21235|test cor -0.14279\n",
      "=========================================================================================\n",
      "32 64 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25554 | test ppl 3.50974|test cor 0.00162\n",
      "=========================================================================================\n",
      "32 64 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16189 | test ppl 3.19596|test cor 0.12868\n",
      "=========================================================================================\n",
      "32 64 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15816 | test ppl 3.18408|test cor -0.04868\n",
      "=========================================================================================\n",
      "32 64 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16603 | test ppl 3.20922|test cor 0.02130\n",
      "=========================================================================================\n",
      "32 64 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18356 | test ppl 3.26597|test cor -0.05605\n",
      "=========================================================================================\n",
      "32 64 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15962 | test ppl 3.18871|test cor 0.01602\n",
      "=========================================================================================\n",
      "32 64 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16439 | test ppl 3.20397|test cor 0.08286\n",
      "=========================================================================================\n",
      "32 64 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18359 | test ppl 3.26608|test cor 0.14020\n",
      "=========================================================================================\n",
      "32 64 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.43713 | test ppl 4.20860|test cor -0.09196\n",
      "=========================================================================================\n",
      "32 64 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16323 | test ppl 3.20025|test cor 0.18872\n",
      "=========================================================================================\n",
      "32 64 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16385 | test ppl 3.20224|test cor 0.01729\n",
      "=========================================================================================\n",
      "32 64 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16033 | test ppl 3.19100|test cor 0.23006\n",
      "=========================================================================================\n",
      "32 64 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26938 | test ppl 3.55865|test cor -0.20215\n",
      "=========================================================================================\n",
      "32 64 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16560 | test ppl 3.20785|test cor 0.04997\n",
      "=========================================================================================\n",
      "32 64 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15881 | test ppl 3.18615|test cor 0.14407\n",
      "=========================================================================================\n",
      "32 64 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18890 | test ppl 3.28348|test cor 0.06554\n",
      "=========================================================================================\n",
      "32 64 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18134 | test ppl 3.25873|test cor -0.19190\n",
      "=========================================================================================\n",
      "32 64 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16273 | test ppl 3.19865|test cor 0.18778\n",
      "=========================================================================================\n",
      "32 64 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16487 | test ppl 3.20552|test cor -0.01071\n",
      "=========================================================================================\n",
      "32 64 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15626 | test ppl 3.17801|test cor 0.10438\n",
      "=========================================================================================\n",
      "32 64 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19442 | test ppl 3.30164|test cor -0.11387\n",
      "=========================================================================================\n",
      "32 64 6 4 0.5 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16026 | test ppl 3.19075|test cor -0.03535\n",
      "=========================================================================================\n",
      "32 64 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16521 | test ppl 3.20661|test cor -0.10411\n",
      "=========================================================================================\n",
      "32 64 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16618 | test ppl 3.20972|test cor 0.18790\n",
      "=========================================================================================\n",
      "32 64 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23053 | test ppl 3.42306|test cor 0.18700\n",
      "=========================================================================================\n",
      "32 64 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16011 | test ppl 3.19029|test cor 0.19078\n",
      "=========================================================================================\n",
      "32 64 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15839 | test ppl 3.18480|test cor -0.08840\n",
      "=========================================================================================\n",
      "32 64 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16824 | test ppl 3.21634|test cor 0.02288\n",
      "=========================================================================================\n",
      "32 64 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20346 | test ppl 3.33163|test cor 0.09520\n",
      "=========================================================================================\n",
      "32 64 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17407 | test ppl 3.23515|test cor 0.08515\n",
      "=========================================================================================\n",
      "32 64 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16053 | test ppl 3.19161|test cor 0.16816\n",
      "=========================================================================================\n",
      "32 64 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17144 | test ppl 3.22663|test cor -0.12185\n",
      "=========================================================================================\n",
      "32 64 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.60505 | test ppl 4.97813|test cor -0.15074\n",
      "=========================================================================================\n",
      "32 64 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16183 | test ppl 3.19578|test cor 0.14426\n",
      "=========================================================================================\n",
      "32 64 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16604 | test ppl 3.20925|test cor -0.21623\n",
      "=========================================================================================\n",
      "32 64 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16592 | test ppl 3.20887|test cor 0.27698\n",
      "=========================================================================================\n",
      "32 64 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16242 | test ppl 3.19767|test cor 0.13450\n",
      "=========================================================================================\n",
      "32 64 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16684 | test ppl 3.21183|test cor 0.13279\n",
      "=========================================================================================\n",
      "32 64 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16514 | test ppl 3.20638|test cor 0.23196\n",
      "=========================================================================================\n",
      "32 64 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19097 | test ppl 3.29027|test cor 0.11730\n",
      "=========================================================================================\n",
      "32 64 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26124 | test ppl 3.52979|test cor -0.06081\n",
      "=========================================================================================\n",
      "32 64 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17480 | test ppl 3.23749|test cor 0.20322\n",
      "=========================================================================================\n",
      "32 64 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16276 | test ppl 3.19874|test cor 0.21655\n",
      "=========================================================================================\n",
      "32 64 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16258 | test ppl 3.19816|test cor 0.03078\n",
      "=========================================================================================\n",
      "32 64 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23044 | test ppl 3.42272|test cor -0.03829\n",
      "=========================================================================================\n",
      "32 64 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16208 | test ppl 3.19656|test cor -0.10915\n",
      "=========================================================================================\n",
      "32 64 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16555 | test ppl 3.20769|test cor 0.16864\n",
      "=========================================================================================\n",
      "32 64 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16793 | test ppl 3.21533|test cor 0.12430\n",
      "=========================================================================================\n",
      "32 64 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17299 | test ppl 3.23164|test cor -0.18254\n",
      "=========================================================================================\n",
      "32 64 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17598 | test ppl 3.24132|test cor 0.17954\n",
      "=========================================================================================\n",
      "32 64 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16006 | test ppl 3.19013|test cor 0.19912\n",
      "=========================================================================================\n",
      "32 64 8 8 0.2 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16815 | test ppl 3.21605|test cor -0.05426\n",
      "=========================================================================================\n",
      "32 64 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18029 | test ppl 3.25530|test cor 0.05815\n",
      "=========================================================================================\n",
      "32 64 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16513 | test ppl 3.20634|test cor 0.04105\n",
      "=========================================================================================\n",
      "32 64 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16241 | test ppl 3.19763|test cor 0.14707\n",
      "=========================================================================================\n",
      "32 64 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16926 | test ppl 3.21961|test cor 0.15505\n",
      "=========================================================================================\n",
      "32 64 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18203 | test ppl 3.26098|test cor 0.24855\n",
      "=========================================================================================\n",
      "32 128 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16033 | test ppl 3.19098|test cor 0.08102\n",
      "=========================================================================================\n",
      "32 128 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15821 | test ppl 3.18424|test cor 0.19777\n",
      "=========================================================================================\n",
      "32 128 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16193 | test ppl 3.19609|test cor -0.06587\n",
      "=========================================================================================\n",
      "32 128 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.33300 | test ppl 3.79240|test cor -0.05120\n",
      "=========================================================================================\n",
      "32 128 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16721 | test ppl 3.21300|test cor -0.00779\n",
      "=========================================================================================\n",
      "32 128 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16614 | test ppl 3.20957|test cor -0.06967\n",
      "=========================================================================================\n",
      "32 128 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15600 | test ppl 3.17720|test cor -0.02780\n",
      "=========================================================================================\n",
      "32 128 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22643 | test ppl 3.40903|test cor 0.15478\n",
      "=========================================================================================\n",
      "32 128 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18087 | test ppl 3.25721|test cor 0.03072\n",
      "=========================================================================================\n",
      "32 128 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16480 | test ppl 3.20527|test cor 0.18801\n",
      "=========================================================================================\n",
      "32 128 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15879 | test ppl 3.18609|test cor 0.03079\n",
      "=========================================================================================\n",
      "32 128 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16663 | test ppl 3.21115|test cor -0.13420\n",
      "=========================================================================================\n",
      "32 128 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17466 | test ppl 3.23703|test cor 0.00069\n",
      "=========================================================================================\n",
      "32 128 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16389 | test ppl 3.20238|test cor 0.08482\n",
      "=========================================================================================\n",
      "32 128 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17457 | test ppl 3.23677|test cor 0.04577\n",
      "=========================================================================================\n",
      "32 128 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21177 | test ppl 3.35943|test cor -0.05367\n",
      "=========================================================================================\n",
      "32 128 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15748 | test ppl 3.18190|test cor 0.05902\n",
      "=========================================================================================\n",
      "32 128 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15656 | test ppl 3.17898|test cor 0.08445\n",
      "=========================================================================================\n",
      "32 128 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18632 | test ppl 3.27501|test cor 0.08166\n",
      "=========================================================================================\n",
      "32 128 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19945 | test ppl 3.31828|test cor 0.08718\n",
      "=========================================================================================\n",
      "32 128 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16254 | test ppl 3.19803|test cor -0.00547\n",
      "=========================================================================================\n",
      "32 128 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16441 | test ppl 3.20402|test cor 0.04102\n",
      "=========================================================================================\n",
      "32 128 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17015 | test ppl 3.22247|test cor 0.02609\n",
      "=========================================================================================\n",
      "32 128 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.30147 | test ppl 3.67469|test cor 0.00527\n",
      "=========================================================================================\n",
      "32 128 4 2 0.2 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16110 | test ppl 3.19345|test cor 0.15953\n",
      "=========================================================================================\n",
      "32 128 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16191 | test ppl 3.19604|test cor 0.11657\n",
      "=========================================================================================\n",
      "32 128 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16269 | test ppl 3.19852|test cor -0.00374\n",
      "=========================================================================================\n",
      "32 128 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24274 | test ppl 3.46510|test cor -0.07015\n",
      "=========================================================================================\n",
      "32 128 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15973 | test ppl 3.18906|test cor -0.02310\n",
      "=========================================================================================\n",
      "32 128 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16762 | test ppl 3.21434|test cor -0.05407\n",
      "=========================================================================================\n",
      "32 128 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16650 | test ppl 3.21074|test cor -0.02004\n",
      "=========================================================================================\n",
      "32 128 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17207 | test ppl 3.22868|test cor -0.13291\n",
      "=========================================================================================\n",
      "32 128 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15832 | test ppl 3.18458|test cor 0.19301\n",
      "=========================================================================================\n",
      "32 128 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15717 | test ppl 3.18092|test cor 0.06587\n",
      "=========================================================================================\n",
      "32 128 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17205 | test ppl 3.22859|test cor 0.22697\n",
      "=========================================================================================\n",
      "32 128 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17474 | test ppl 3.23729|test cor 0.12118\n",
      "=========================================================================================\n",
      "32 128 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16142 | test ppl 3.19448|test cor 0.00727\n",
      "=========================================================================================\n",
      "32 128 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16000 | test ppl 3.18993|test cor -0.06158\n",
      "=========================================================================================\n",
      "32 128 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16320 | test ppl 3.20016|test cor -0.01594\n",
      "=========================================================================================\n",
      "32 128 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26071 | test ppl 3.52794|test cor -0.14163\n",
      "=========================================================================================\n",
      "32 128 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16837 | test ppl 3.21674|test cor 0.10605\n",
      "=========================================================================================\n",
      "32 128 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16677 | test ppl 3.21159|test cor 0.21902\n",
      "=========================================================================================\n",
      "32 128 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15914 | test ppl 3.18718|test cor 0.09585\n",
      "=========================================================================================\n",
      "32 128 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17562 | test ppl 3.24015|test cor 0.07985\n",
      "=========================================================================================\n",
      "32 128 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16297 | test ppl 3.19942|test cor 0.02287\n",
      "=========================================================================================\n",
      "32 128 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16494 | test ppl 3.20575|test cor 0.05816\n",
      "=========================================================================================\n",
      "32 128 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17673 | test ppl 3.24374|test cor 0.16313\n",
      "=========================================================================================\n",
      "32 128 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20749 | test ppl 3.34509|test cor -0.05298\n",
      "=========================================================================================\n",
      "32 128 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16296 | test ppl 3.19938|test cor 0.12604\n",
      "=========================================================================================\n",
      "32 128 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16057 | test ppl 3.19175|test cor 0.13402\n",
      "=========================================================================================\n",
      "32 128 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15926 | test ppl 3.18758|test cor -0.05480\n",
      "=========================================================================================\n",
      "32 128 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18686 | test ppl 3.27677|test cor -0.04385\n",
      "=========================================================================================\n",
      "32 128 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15863 | test ppl 3.18557|test cor 0.10977\n",
      "=========================================================================================\n",
      "32 128 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16222 | test ppl 3.19702|test cor -0.09909\n",
      "=========================================================================================\n",
      "32 128 6 2 0.5 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.18040 | test ppl 3.25569|test cor 0.08774\n",
      "=========================================================================================\n",
      "32 128 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17237 | test ppl 3.22964|test cor 0.00863\n",
      "=========================================================================================\n",
      "32 128 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17030 | test ppl 3.22296|test cor 0.15988\n",
      "=========================================================================================\n",
      "32 128 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16833 | test ppl 3.21662|test cor -0.03734\n",
      "=========================================================================================\n",
      "32 128 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16340 | test ppl 3.20080|test cor -0.05591\n",
      "=========================================================================================\n",
      "32 128 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16623 | test ppl 3.20988|test cor -0.02600\n",
      "=========================================================================================\n",
      "32 128 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16351 | test ppl 3.20116|test cor 0.09709\n",
      "=========================================================================================\n",
      "32 128 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16172 | test ppl 3.19543|test cor 0.04059\n",
      "=========================================================================================\n",
      "32 128 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19882 | test ppl 3.31622|test cor -0.07965\n",
      "=========================================================================================\n",
      "32 128 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18371 | test ppl 3.26647|test cor 0.01440\n",
      "=========================================================================================\n",
      "32 128 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16944 | test ppl 3.22018|test cor 0.09769\n",
      "=========================================================================================\n",
      "32 128 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15499 | test ppl 3.17398|test cor 0.02887\n",
      "=========================================================================================\n",
      "32 128 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16545 | test ppl 3.20735|test cor -0.13893\n",
      "=========================================================================================\n",
      "32 128 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17261 | test ppl 3.23041|test cor -0.05173\n",
      "=========================================================================================\n",
      "32 128 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16962 | test ppl 3.22077|test cor 0.04123\n",
      "=========================================================================================\n",
      "32 128 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16148 | test ppl 3.19465|test cor -0.06600\n",
      "=========================================================================================\n",
      "32 128 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18140 | test ppl 3.25894|test cor -0.21404\n",
      "=========================================================================================\n",
      "32 128 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.48089 | test ppl 4.39684|test cor 0.12965\n",
      "=========================================================================================\n",
      "32 128 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16416 | test ppl 3.20322|test cor 0.17752\n",
      "=========================================================================================\n",
      "32 128 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16374 | test ppl 3.20187|test cor 0.21646\n",
      "=========================================================================================\n",
      "32 128 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17808 | test ppl 3.24814|test cor 0.06174\n",
      "=========================================================================================\n",
      "32 128 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17626 | test ppl 3.24221|test cor -0.05028\n",
      "=========================================================================================\n",
      "32 128 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16280 | test ppl 3.19888|test cor 0.09558\n",
      "=========================================================================================\n",
      "32 128 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16883 | test ppl 3.21823|test cor 0.12147\n",
      "=========================================================================================\n",
      "32 128 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15891 | test ppl 3.18645|test cor 0.16162\n",
      "=========================================================================================\n",
      "32 128 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17985 | test ppl 3.25389|test cor -0.07617\n",
      "=========================================================================================\n",
      "32 128 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16722 | test ppl 3.21304|test cor 0.19434\n",
      "=========================================================================================\n",
      "32 128 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15967 | test ppl 3.18888|test cor 0.20893\n",
      "=========================================================================================\n",
      "32 128 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16427 | test ppl 3.20359|test cor 0.17339\n",
      "=========================================================================================\n",
      "32 128 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17298 | test ppl 3.23160|test cor -0.14067\n",
      "=========================================================================================\n",
      "32 128 8 4 0.5 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16230 | test ppl 3.19728|test cor 0.21297\n",
      "=========================================================================================\n",
      "32 128 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16385 | test ppl 3.20223|test cor -0.08767\n",
      "=========================================================================================\n",
      "32 128 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17623 | test ppl 3.24212|test cor -0.19571\n",
      "=========================================================================================\n",
      "32 128 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16315 | test ppl 3.20001|test cor -0.12529\n",
      "=========================================================================================\n",
      "32 128 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17199 | test ppl 3.22840|test cor 0.02856\n",
      "=========================================================================================\n",
      "32 128 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16367 | test ppl 3.20166|test cor 0.06569\n",
      "=========================================================================================\n",
      "32 128 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15924 | test ppl 3.18750|test cor 0.19382\n",
      "=========================================================================================\n",
      "32 128 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20656 | test ppl 3.34195|test cor 0.14037\n",
      "=========================================================================================\n",
      "32 128 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16257 | test ppl 3.19815|test cor 0.16069\n",
      "=========================================================================================\n",
      "32 128 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16918 | test ppl 3.21936|test cor 0.07296\n",
      "=========================================================================================\n",
      "32 128 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16499 | test ppl 3.20589|test cor -0.16123\n",
      "=========================================================================================\n",
      "32 128 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.34283 | test ppl 3.82986|test cor 0.20301\n",
      "=========================================================================================\n",
      "32 256 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15529 | test ppl 3.17496|test cor 0.06408\n",
      "=========================================================================================\n",
      "32 256 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16025 | test ppl 3.19073|test cor 0.11080\n",
      "=========================================================================================\n",
      "32 256 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17095 | test ppl 3.22506|test cor 0.04735\n",
      "=========================================================================================\n",
      "32 256 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.38394 | test ppl 3.99059|test cor 0.05723\n",
      "=========================================================================================\n",
      "32 256 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15989 | test ppl 3.18957|test cor -0.01089\n",
      "=========================================================================================\n",
      "32 256 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16598 | test ppl 3.20907|test cor 0.13736\n",
      "=========================================================================================\n",
      "32 256 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17003 | test ppl 3.22209|test cor 0.15946\n",
      "=========================================================================================\n",
      "32 256 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.34512 | test ppl 3.83866|test cor 0.09448\n",
      "=========================================================================================\n",
      "32 256 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16752 | test ppl 3.21401|test cor 0.00155\n",
      "=========================================================================================\n",
      "32 256 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15977 | test ppl 3.18921|test cor 0.24329\n",
      "=========================================================================================\n",
      "32 256 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16251 | test ppl 3.19796|test cor 0.12725\n",
      "=========================================================================================\n",
      "32 256 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18716 | test ppl 3.27778|test cor -0.10712\n",
      "=========================================================================================\n",
      "32 256 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16730 | test ppl 3.21330|test cor 0.01282\n",
      "=========================================================================================\n",
      "32 256 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15992 | test ppl 3.18969|test cor 0.15365\n",
      "=========================================================================================\n",
      "32 256 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16603 | test ppl 3.20921|test cor 0.06433\n",
      "=========================================================================================\n",
      "32 256 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17436 | test ppl 3.23606|test cor 0.03189\n",
      "=========================================================================================\n",
      "32 256 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15692 | test ppl 3.18013|test cor 0.06633\n",
      "=========================================================================================\n",
      "32 256 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16220 | test ppl 3.19697|test cor 0.09019\n",
      "=========================================================================================\n",
      "32 256 2 8 0.2 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16019 | test ppl 3.19055|test cor 0.17423\n",
      "=========================================================================================\n",
      "32 256 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19037 | test ppl 3.28831|test cor 0.00668\n",
      "=========================================================================================\n",
      "32 256 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16341 | test ppl 3.20081|test cor 0.01829\n",
      "=========================================================================================\n",
      "32 256 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17677 | test ppl 3.24389|test cor 0.04069\n",
      "=========================================================================================\n",
      "32 256 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16821 | test ppl 3.21623|test cor 0.06609\n",
      "=========================================================================================\n",
      "32 256 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26507 | test ppl 3.54336|test cor -0.08410\n",
      "=========================================================================================\n",
      "32 256 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17323 | test ppl 3.23240|test cor 0.17633\n",
      "=========================================================================================\n",
      "32 256 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16491 | test ppl 3.20563|test cor 0.17406\n",
      "=========================================================================================\n",
      "32 256 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15421 | test ppl 3.17153|test cor 0.06598\n",
      "=========================================================================================\n",
      "32 256 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26397 | test ppl 3.53943|test cor -0.13655\n",
      "=========================================================================================\n",
      "32 256 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16017 | test ppl 3.19049|test cor -0.08108\n",
      "=========================================================================================\n",
      "32 256 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16632 | test ppl 3.21016|test cor 0.15145\n",
      "=========================================================================================\n",
      "32 256 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17553 | test ppl 3.23986|test cor -0.14766\n",
      "=========================================================================================\n",
      "32 256 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16861 | test ppl 3.21751|test cor 0.02992\n",
      "=========================================================================================\n",
      "32 256 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17417 | test ppl 3.23544|test cor 0.14127\n",
      "=========================================================================================\n",
      "32 256 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15978 | test ppl 3.18924|test cor 0.07257\n",
      "=========================================================================================\n",
      "32 256 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15894 | test ppl 3.18655|test cor 0.02956\n",
      "=========================================================================================\n",
      "32 256 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17809 | test ppl 3.24818|test cor 0.15107\n",
      "=========================================================================================\n",
      "32 256 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15954 | test ppl 3.18848|test cor -0.02603\n",
      "=========================================================================================\n",
      "32 256 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16398 | test ppl 3.20264|test cor 0.10374\n",
      "=========================================================================================\n",
      "32 256 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16575 | test ppl 3.20834|test cor -0.02752\n",
      "=========================================================================================\n",
      "32 256 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23886 | test ppl 3.45169|test cor 0.01187\n",
      "=========================================================================================\n",
      "32 256 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16213 | test ppl 3.19672|test cor 0.12175\n",
      "=========================================================================================\n",
      "32 256 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16332 | test ppl 3.20054|test cor -0.14840\n",
      "=========================================================================================\n",
      "32 256 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16422 | test ppl 3.20342|test cor 0.23870\n",
      "=========================================================================================\n",
      "32 256 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.35248 | test ppl 3.86699|test cor -0.15460\n",
      "=========================================================================================\n",
      "32 256 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16092 | test ppl 3.19286|test cor 0.03431\n",
      "=========================================================================================\n",
      "32 256 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16436 | test ppl 3.20386|test cor 0.05977\n",
      "=========================================================================================\n",
      "32 256 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19495 | test ppl 3.30339|test cor -0.00187\n",
      "=========================================================================================\n",
      "32 256 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20789 | test ppl 3.34643|test cor 0.14195\n",
      "=========================================================================================\n",
      "32 256 6 2 0.2 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17170 | test ppl 3.22748|test cor -0.02781\n",
      "=========================================================================================\n",
      "32 256 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16075 | test ppl 3.19231|test cor -0.03515\n",
      "=========================================================================================\n",
      "32 256 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16810 | test ppl 3.21589|test cor 0.10104\n",
      "=========================================================================================\n",
      "32 256 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20156 | test ppl 3.32530|test cor -0.14400\n",
      "=========================================================================================\n",
      "32 256 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16941 | test ppl 3.22010|test cor 0.19901\n",
      "=========================================================================================\n",
      "32 256 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16271 | test ppl 3.19859|test cor 0.01910\n",
      "=========================================================================================\n",
      "32 256 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16231 | test ppl 3.19730|test cor -0.05707\n",
      "=========================================================================================\n",
      "32 256 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.27507 | test ppl 3.57895|test cor 0.10867\n",
      "=========================================================================================\n",
      "32 256 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16689 | test ppl 3.21200|test cor 0.15419\n",
      "=========================================================================================\n",
      "32 256 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16063 | test ppl 3.19194|test cor 0.17499\n",
      "=========================================================================================\n",
      "32 256 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16732 | test ppl 3.21335|test cor -0.05742\n",
      "=========================================================================================\n",
      "32 256 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16332 | test ppl 3.20055|test cor -0.13669\n",
      "=========================================================================================\n",
      "32 256 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16003 | test ppl 3.19004|test cor 0.20446\n",
      "=========================================================================================\n",
      "32 256 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15870 | test ppl 3.18580|test cor -0.12465\n",
      "=========================================================================================\n",
      "32 256 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15788 | test ppl 3.18317|test cor -0.01676\n",
      "=========================================================================================\n",
      "32 256 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21185 | test ppl 3.35970|test cor -0.01469\n",
      "=========================================================================================\n",
      "32 256 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17263 | test ppl 3.23048|test cor 0.16246\n",
      "=========================================================================================\n",
      "32 256 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16325 | test ppl 3.20031|test cor 0.03597\n",
      "=========================================================================================\n",
      "32 256 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17032 | test ppl 3.22302|test cor 0.13511\n",
      "=========================================================================================\n",
      "32 256 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17372 | test ppl 3.23399|test cor -0.26639\n",
      "=========================================================================================\n",
      "32 256 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15785 | test ppl 3.18308|test cor 0.17580\n",
      "=========================================================================================\n",
      "32 256 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16189 | test ppl 3.19597|test cor 0.14800\n",
      "=========================================================================================\n",
      "32 256 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16394 | test ppl 3.20252|test cor 0.08143\n",
      "=========================================================================================\n",
      "32 256 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17335 | test ppl 3.23280|test cor 0.01409\n",
      "=========================================================================================\n",
      "32 256 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16234 | test ppl 3.19739|test cor 0.17089\n",
      "=========================================================================================\n",
      "32 256 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17074 | test ppl 3.22439|test cor 0.24559\n",
      "=========================================================================================\n",
      "32 256 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16231 | test ppl 3.19732|test cor -0.10041\n",
      "=========================================================================================\n",
      "32 256 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18432 | test ppl 3.26846|test cor -0.04649\n",
      "=========================================================================================\n",
      "32 256 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16430 | test ppl 3.20367|test cor 0.10873\n",
      "=========================================================================================\n",
      "32 256 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16143 | test ppl 3.19449|test cor -0.14538\n",
      "=========================================================================================\n",
      "32 256 8 2 0.5 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17070 | test ppl 3.22426|test cor -0.17026\n",
      "=========================================================================================\n",
      "32 256 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20969 | test ppl 3.35246|test cor -0.10232\n",
      "=========================================================================================\n",
      "32 256 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16422 | test ppl 3.20343|test cor 0.16240\n",
      "=========================================================================================\n",
      "32 256 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16269 | test ppl 3.19852|test cor 0.18539\n",
      "=========================================================================================\n",
      "32 256 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17095 | test ppl 3.22506|test cor 0.18976\n",
      "=========================================================================================\n",
      "32 256 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19293 | test ppl 3.29672|test cor 0.21173\n",
      "=========================================================================================\n",
      "32 256 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16153 | test ppl 3.19483|test cor 0.15836\n",
      "=========================================================================================\n",
      "32 256 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16393 | test ppl 3.20249|test cor -0.08210\n",
      "=========================================================================================\n",
      "32 256 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17055 | test ppl 3.22375|test cor 0.06010\n",
      "=========================================================================================\n",
      "32 256 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.34335 | test ppl 3.83187|test cor 0.06749\n",
      "=========================================================================================\n",
      "32 256 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18294 | test ppl 3.26394|test cor 0.24464\n",
      "=========================================================================================\n",
      "32 256 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16014 | test ppl 3.19039|test cor 0.21506\n",
      "=========================================================================================\n",
      "32 256 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16899 | test ppl 3.21876|test cor -0.15086\n",
      "=========================================================================================\n",
      "32 256 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17266 | test ppl 3.23056|test cor 0.09626\n",
      "=========================================================================================\n",
      "32 256 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16833 | test ppl 3.21662|test cor 0.17800\n",
      "=========================================================================================\n",
      "32 256 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16250 | test ppl 3.19792|test cor -0.06120\n",
      "=========================================================================================\n",
      "32 256 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17315 | test ppl 3.23215|test cor 0.25999\n",
      "=========================================================================================\n",
      "32 256 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16437 | test ppl 3.20390|test cor 0.15848\n",
      "=========================================================================================\n",
      "64 8 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20491 | test ppl 3.33645|test cor 0.12759\n",
      "=========================================================================================\n",
      "64 8 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15982 | test ppl 3.18936|test cor 0.06898\n",
      "=========================================================================================\n",
      "64 8 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16219 | test ppl 3.19692|test cor 0.03713\n",
      "=========================================================================================\n",
      "64 8 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17972 | test ppl 3.25346|test cor 0.10882\n",
      "=========================================================================================\n",
      "64 8 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17158 | test ppl 3.22709|test cor 0.03171\n",
      "=========================================================================================\n",
      "64 8 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15913 | test ppl 3.18716|test cor 0.05546\n",
      "=========================================================================================\n",
      "64 8 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16072 | test ppl 3.19224|test cor 0.09196\n",
      "=========================================================================================\n",
      "64 8 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17096 | test ppl 3.22510|test cor -0.02453\n",
      "=========================================================================================\n",
      "64 8 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16611 | test ppl 3.20947|test cor 0.06170\n",
      "=========================================================================================\n",
      "64 8 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17035 | test ppl 3.22312|test cor 0.14761\n",
      "=========================================================================================\n",
      "64 8 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17308 | test ppl 3.23195|test cor 0.07343\n",
      "=========================================================================================\n",
      "64 8 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18329 | test ppl 3.26509|test cor 0.04132\n",
      "=========================================================================================\n",
      "64 8 2 4 0.5 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17118 | test ppl 3.22581|test cor 0.02838\n",
      "=========================================================================================\n",
      "64 8 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16796 | test ppl 3.21541|test cor 0.15407\n",
      "=========================================================================================\n",
      "64 8 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16793 | test ppl 3.21532|test cor 0.04005\n",
      "=========================================================================================\n",
      "64 8 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.33872 | test ppl 3.81415|test cor 0.01225\n",
      "=========================================================================================\n",
      "64 8 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16699 | test ppl 3.21230|test cor 0.08525\n",
      "=========================================================================================\n",
      "64 8 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16430 | test ppl 3.20369|test cor 0.08763\n",
      "=========================================================================================\n",
      "64 8 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15810 | test ppl 3.18388|test cor 0.06308\n",
      "=========================================================================================\n",
      "64 8 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28644 | test ppl 3.61986|test cor 0.05134\n",
      "=========================================================================================\n",
      "64 8 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17591 | test ppl 3.24110|test cor 0.00013\n",
      "=========================================================================================\n",
      "64 8 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16256 | test ppl 3.19810|test cor -0.04127\n",
      "=========================================================================================\n",
      "64 8 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19164 | test ppl 3.29247|test cor 0.02258\n",
      "=========================================================================================\n",
      "64 8 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19624 | test ppl 3.30766|test cor -0.05120\n",
      "=========================================================================================\n",
      "64 8 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16286 | test ppl 3.19905|test cor 0.20022\n",
      "=========================================================================================\n",
      "64 8 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16164 | test ppl 3.19517|test cor -0.07859\n",
      "=========================================================================================\n",
      "64 8 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16503 | test ppl 3.20602|test cor -0.21860\n",
      "=========================================================================================\n",
      "64 8 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17143 | test ppl 3.22661|test cor 0.08680\n",
      "=========================================================================================\n",
      "64 8 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16966 | test ppl 3.22089|test cor 0.15143\n",
      "=========================================================================================\n",
      "64 8 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16633 | test ppl 3.21019|test cor 0.20586\n",
      "=========================================================================================\n",
      "64 8 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16288 | test ppl 3.19912|test cor -0.15144\n",
      "=========================================================================================\n",
      "64 8 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.30993 | test ppl 3.70592|test cor -0.15083\n",
      "=========================================================================================\n",
      "64 8 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17011 | test ppl 3.22235|test cor 0.20842\n",
      "=========================================================================================\n",
      "64 8 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15947 | test ppl 3.18824|test cor 0.20748\n",
      "=========================================================================================\n",
      "64 8 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16313 | test ppl 3.19993|test cor 0.12613\n",
      "=========================================================================================\n",
      "64 8 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18059 | test ppl 3.25631|test cor 0.07316\n",
      "=========================================================================================\n",
      "64 8 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16859 | test ppl 3.21745|test cor 0.19641\n",
      "=========================================================================================\n",
      "64 8 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17032 | test ppl 3.22304|test cor 0.17333\n",
      "=========================================================================================\n",
      "64 8 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15988 | test ppl 3.18956|test cor 0.02686\n",
      "=========================================================================================\n",
      "64 8 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21306 | test ppl 3.36376|test cor 0.12272\n",
      "=========================================================================================\n",
      "64 8 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18575 | test ppl 3.27316|test cor 0.17067\n",
      "=========================================================================================\n",
      "64 8 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16038 | test ppl 3.19115|test cor 0.19461\n",
      "=========================================================================================\n",
      "64 8 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17316 | test ppl 3.23218|test cor 0.12693\n",
      "=========================================================================================\n",
      "64 8 4 8 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17872 | test ppl 3.25020|test cor 0.10851\n",
      "=========================================================================================\n",
      "64 8 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17090 | test ppl 3.22488|test cor 0.15395\n",
      "=========================================================================================\n",
      "64 8 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16524 | test ppl 3.20670|test cor 0.11297\n",
      "=========================================================================================\n",
      "64 8 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17512 | test ppl 3.23852|test cor 0.15655\n",
      "=========================================================================================\n",
      "64 8 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19396 | test ppl 3.30012|test cor 0.10394\n",
      "=========================================================================================\n",
      "64 8 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17767 | test ppl 3.24679|test cor 0.20630\n",
      "=========================================================================================\n",
      "64 8 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16258 | test ppl 3.19818|test cor -0.04961\n",
      "=========================================================================================\n",
      "64 8 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16602 | test ppl 3.20920|test cor -0.22121\n",
      "=========================================================================================\n",
      "64 8 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16421 | test ppl 3.20338|test cor -0.23413\n",
      "=========================================================================================\n",
      "64 8 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16425 | test ppl 3.20352|test cor 0.14249\n",
      "=========================================================================================\n",
      "64 8 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16733 | test ppl 3.21340|test cor -0.07340\n",
      "=========================================================================================\n",
      "64 8 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16489 | test ppl 3.20557|test cor 0.12246\n",
      "=========================================================================================\n",
      "64 8 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.36019 | test ppl 3.89695|test cor 0.16319\n",
      "=========================================================================================\n",
      "64 8 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17813 | test ppl 3.24828|test cor 0.17370\n",
      "=========================================================================================\n",
      "64 8 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16313 | test ppl 3.19992|test cor -0.13670\n",
      "=========================================================================================\n",
      "64 8 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18251 | test ppl 3.26256|test cor -0.11815\n",
      "=========================================================================================\n",
      "64 8 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.37489 | test ppl 3.95462|test cor -0.05619\n",
      "=========================================================================================\n",
      "64 8 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16513 | test ppl 3.20633|test cor 0.19803\n",
      "=========================================================================================\n",
      "64 8 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15866 | test ppl 3.18567|test cor -0.08618\n",
      "=========================================================================================\n",
      "64 8 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16449 | test ppl 3.20430|test cor 0.20731\n",
      "=========================================================================================\n",
      "64 8 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16629 | test ppl 3.21006|test cor 0.12711\n",
      "=========================================================================================\n",
      "64 8 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16540 | test ppl 3.20720|test cor 0.19759\n",
      "=========================================================================================\n",
      "64 8 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16105 | test ppl 3.19327|test cor 0.12462\n",
      "=========================================================================================\n",
      "64 8 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16833 | test ppl 3.21663|test cor 0.20448\n",
      "=========================================================================================\n",
      "64 8 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20206 | test ppl 3.32696|test cor -0.07351\n",
      "=========================================================================================\n",
      "64 8 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16817 | test ppl 3.21609|test cor 0.16346\n",
      "=========================================================================================\n",
      "64 8 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17153 | test ppl 3.22694|test cor 0.14072\n",
      "=========================================================================================\n",
      "64 8 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16609 | test ppl 3.20942|test cor -0.04527\n",
      "=========================================================================================\n",
      "64 8 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17827 | test ppl 3.24874|test cor -0.13365\n",
      "=========================================================================================\n",
      "64 8 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16783 | test ppl 3.21500|test cor 0.18041\n",
      "=========================================================================================\n",
      "64 8 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16025 | test ppl 3.19073|test cor 0.10265\n",
      "=========================================================================================\n",
      "64 8 8 2 0.2 0.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16453 | test ppl 3.20440|test cor 0.07119\n",
      "=========================================================================================\n",
      "64 8 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17290 | test ppl 3.23134|test cor 0.19142\n",
      "=========================================================================================\n",
      "64 8 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16621 | test ppl 3.20982|test cor 0.05968\n",
      "=========================================================================================\n",
      "64 8 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16426 | test ppl 3.20354|test cor -0.15205\n",
      "=========================================================================================\n",
      "64 8 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16327 | test ppl 3.20037|test cor -0.17355\n",
      "=========================================================================================\n",
      "64 8 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19570 | test ppl 3.30588|test cor -0.15675\n",
      "=========================================================================================\n",
      "64 8 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17878 | test ppl 3.25040|test cor 0.23601\n",
      "=========================================================================================\n",
      "64 8 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16762 | test ppl 3.21434|test cor 0.07112\n",
      "=========================================================================================\n",
      "64 8 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16480 | test ppl 3.20529|test cor -0.02177\n",
      "=========================================================================================\n",
      "64 8 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17190 | test ppl 3.22811|test cor 0.09051\n",
      "=========================================================================================\n",
      "64 8 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17563 | test ppl 3.24018|test cor 0.15683\n",
      "=========================================================================================\n",
      "64 8 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16716 | test ppl 3.21287|test cor 0.05572\n",
      "=========================================================================================\n",
      "64 8 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17256 | test ppl 3.23024|test cor 0.14123\n",
      "=========================================================================================\n",
      "64 8 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16635 | test ppl 3.21024|test cor 0.08512\n",
      "=========================================================================================\n",
      "64 8 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18064 | test ppl 3.25645|test cor 0.14427\n",
      "=========================================================================================\n",
      "64 8 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16634 | test ppl 3.21021|test cor 0.03992\n",
      "=========================================================================================\n",
      "64 8 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16265 | test ppl 3.19841|test cor 0.19250\n",
      "=========================================================================================\n",
      "64 8 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15934 | test ppl 3.18783|test cor -0.01858\n",
      "=========================================================================================\n",
      "64 8 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16674 | test ppl 3.21152|test cor 0.02171\n",
      "=========================================================================================\n",
      "64 8 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16238 | test ppl 3.19754|test cor -0.17602\n",
      "=========================================================================================\n",
      "64 8 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17485 | test ppl 3.23765|test cor 0.13626\n",
      "=========================================================================================\n",
      "64 8 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17853 | test ppl 3.24960|test cor -0.19022\n",
      "=========================================================================================\n",
      "64 32 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16645 | test ppl 3.21056|test cor 0.06349\n",
      "=========================================================================================\n",
      "64 32 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16403 | test ppl 3.20281|test cor 0.00824\n",
      "=========================================================================================\n",
      "64 32 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16409 | test ppl 3.20301|test cor 0.15685\n",
      "=========================================================================================\n",
      "64 32 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16594 | test ppl 3.20894|test cor -0.00301\n",
      "=========================================================================================\n",
      "64 32 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17068 | test ppl 3.22419|test cor -0.00061\n",
      "=========================================================================================\n",
      "64 32 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15811 | test ppl 3.18389|test cor 0.06424\n",
      "=========================================================================================\n",
      "64 32 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16455 | test ppl 3.20449|test cor 0.10964\n",
      "=========================================================================================\n",
      "64 32 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20386 | test ppl 3.33295|test cor 0.04586\n",
      "=========================================================================================\n",
      "64 32 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17481 | test ppl 3.23753|test cor 0.07238\n",
      "=========================================================================================\n",
      "64 32 2 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.15995 | test ppl 3.18978|test cor 0.11162\n",
      "=========================================================================================\n",
      "64 32 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17376 | test ppl 3.23412|test cor -0.25654\n",
      "=========================================================================================\n",
      "64 32 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16615 | test ppl 3.20961|test cor 0.15430\n",
      "=========================================================================================\n",
      "64 32 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18123 | test ppl 3.25837|test cor -0.00086\n",
      "=========================================================================================\n",
      "64 32 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16129 | test ppl 3.19406|test cor 0.01972\n",
      "=========================================================================================\n",
      "64 32 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18711 | test ppl 3.27758|test cor -0.00562\n",
      "=========================================================================================\n",
      "64 32 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25906 | test ppl 3.52212|test cor -0.03387\n",
      "=========================================================================================\n",
      "64 32 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16094 | test ppl 3.19292|test cor 0.10727\n",
      "=========================================================================================\n",
      "64 32 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16893 | test ppl 3.21856|test cor 0.04321\n",
      "=========================================================================================\n",
      "64 32 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17383 | test ppl 3.23436|test cor 0.08443\n",
      "=========================================================================================\n",
      "64 32 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19300 | test ppl 3.29696|test cor 0.00940\n",
      "=========================================================================================\n",
      "64 32 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16968 | test ppl 3.22097|test cor 0.00952\n",
      "=========================================================================================\n",
      "64 32 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16838 | test ppl 3.21679|test cor 0.19785\n",
      "=========================================================================================\n",
      "64 32 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17704 | test ppl 3.24474|test cor 0.07596\n",
      "=========================================================================================\n",
      "64 32 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17872 | test ppl 3.25023|test cor -0.07278\n",
      "=========================================================================================\n",
      "64 32 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16449 | test ppl 3.20430|test cor 0.17622\n",
      "=========================================================================================\n",
      "64 32 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16399 | test ppl 3.20270|test cor -0.14871\n",
      "=========================================================================================\n",
      "64 32 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17275 | test ppl 3.23087|test cor 0.13305\n",
      "=========================================================================================\n",
      "64 32 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18266 | test ppl 3.26303|test cor 0.06873\n",
      "=========================================================================================\n",
      "64 32 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16805 | test ppl 3.21570|test cor 0.07555\n",
      "=========================================================================================\n",
      "64 32 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16422 | test ppl 3.20342|test cor 0.16016\n",
      "=========================================================================================\n",
      "64 32 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16724 | test ppl 3.21311|test cor 0.03589\n",
      "=========================================================================================\n",
      "64 32 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16651 | test ppl 3.21077|test cor 0.10657\n",
      "=========================================================================================\n",
      "64 32 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16168 | test ppl 3.19530|test cor 0.16135\n",
      "=========================================================================================\n",
      "64 32 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15935 | test ppl 3.18786|test cor 0.11794\n",
      "=========================================================================================\n",
      "64 32 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16391 | test ppl 3.20242|test cor -0.04317\n",
      "=========================================================================================\n",
      "64 32 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17296 | test ppl 3.23155|test cor 0.14788\n",
      "=========================================================================================\n",
      "64 32 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16991 | test ppl 3.22172|test cor 0.03228\n",
      "=========================================================================================\n",
      "64 32 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16549 | test ppl 3.20751|test cor 0.18526\n",
      "=========================================================================================\n",
      "64 32 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16806 | test ppl 3.21575|test cor -0.00679\n",
      "=========================================================================================\n",
      "64 32 4 4 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.24320 | test ppl 3.46669|test cor -0.11002\n",
      "=========================================================================================\n",
      "64 32 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18639 | test ppl 3.27524|test cor 0.16392\n",
      "=========================================================================================\n",
      "64 32 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16039 | test ppl 3.19116|test cor -0.01537\n",
      "=========================================================================================\n",
      "64 32 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16393 | test ppl 3.20249|test cor -0.09113\n",
      "=========================================================================================\n",
      "64 32 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19106 | test ppl 3.29055|test cor -0.04105\n",
      "=========================================================================================\n",
      "64 32 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16027 | test ppl 3.19080|test cor 0.04590\n",
      "=========================================================================================\n",
      "64 32 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16313 | test ppl 3.19994|test cor 0.18050\n",
      "=========================================================================================\n",
      "64 32 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17334 | test ppl 3.23277|test cor -0.07103\n",
      "=========================================================================================\n",
      "64 32 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17206 | test ppl 3.22863|test cor 0.14444\n",
      "=========================================================================================\n",
      "64 32 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18347 | test ppl 3.26568|test cor -0.05910\n",
      "=========================================================================================\n",
      "64 32 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16487 | test ppl 3.20550|test cor 0.10555\n",
      "=========================================================================================\n",
      "64 32 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16908 | test ppl 3.21902|test cor -0.01993\n",
      "=========================================================================================\n",
      "64 32 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17624 | test ppl 3.24215|test cor -0.17922\n",
      "=========================================================================================\n",
      "64 32 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16861 | test ppl 3.21752|test cor 0.21921\n",
      "=========================================================================================\n",
      "64 32 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15938 | test ppl 3.18796|test cor 0.11839\n",
      "=========================================================================================\n",
      "64 32 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16430 | test ppl 3.20366|test cor 0.07378\n",
      "=========================================================================================\n",
      "64 32 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18757 | test ppl 3.27909|test cor -0.14387\n",
      "=========================================================================================\n",
      "64 32 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17431 | test ppl 3.23591|test cor 0.17570\n",
      "=========================================================================================\n",
      "64 32 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16244 | test ppl 3.19773|test cor 0.00009\n",
      "=========================================================================================\n",
      "64 32 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17817 | test ppl 3.24843|test cor 0.21060\n",
      "=========================================================================================\n",
      "64 32 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16388 | test ppl 3.20234|test cor 0.08011\n",
      "=========================================================================================\n",
      "64 32 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16792 | test ppl 3.21528|test cor 0.18177\n",
      "=========================================================================================\n",
      "64 32 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16654 | test ppl 3.21085|test cor 0.06242\n",
      "=========================================================================================\n",
      "64 32 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17118 | test ppl 3.22579|test cor 0.20044\n",
      "=========================================================================================\n",
      "64 32 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19815 | test ppl 3.31399|test cor 0.03853\n",
      "=========================================================================================\n",
      "64 32 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17657 | test ppl 3.24324|test cor 0.14530\n",
      "=========================================================================================\n",
      "64 32 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16184 | test ppl 3.19581|test cor -0.09079\n",
      "=========================================================================================\n",
      "64 32 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16421 | test ppl 3.20339|test cor 0.06386\n",
      "=========================================================================================\n",
      "64 32 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16980 | test ppl 3.22136|test cor -0.00051\n",
      "=========================================================================================\n",
      "64 32 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16530 | test ppl 3.20689|test cor 0.13097\n",
      "=========================================================================================\n",
      "64 32 6 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16443 | test ppl 3.20411|test cor -0.08306\n",
      "=========================================================================================\n",
      "64 32 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18048 | test ppl 3.25595|test cor 0.12062\n",
      "=========================================================================================\n",
      "64 32 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17197 | test ppl 3.22833|test cor 0.20406\n",
      "=========================================================================================\n",
      "64 32 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17636 | test ppl 3.24254|test cor 0.18989\n",
      "=========================================================================================\n",
      "64 32 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16289 | test ppl 3.19916|test cor -0.15708\n",
      "=========================================================================================\n",
      "64 32 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16168 | test ppl 3.19530|test cor -0.13732\n",
      "=========================================================================================\n",
      "64 32 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17936 | test ppl 3.25230|test cor -0.05317\n",
      "=========================================================================================\n",
      "64 32 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17335 | test ppl 3.23281|test cor 0.19007\n",
      "=========================================================================================\n",
      "64 32 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16311 | test ppl 3.19988|test cor 0.11259\n",
      "=========================================================================================\n",
      "64 32 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16105 | test ppl 3.19329|test cor -0.04064\n",
      "=========================================================================================\n",
      "64 32 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17094 | test ppl 3.22502|test cor -0.01136\n",
      "=========================================================================================\n",
      "64 32 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17339 | test ppl 3.23294|test cor 0.17550\n",
      "=========================================================================================\n",
      "64 32 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16464 | test ppl 3.20478|test cor 0.06116\n",
      "=========================================================================================\n",
      "64 32 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16768 | test ppl 3.21453|test cor -0.07638\n",
      "=========================================================================================\n",
      "64 32 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19314 | test ppl 3.29743|test cor -0.01708\n",
      "=========================================================================================\n",
      "64 32 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18520 | test ppl 3.27134|test cor 0.15842\n",
      "=========================================================================================\n",
      "64 32 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16062 | test ppl 3.19190|test cor -0.07003\n",
      "=========================================================================================\n",
      "64 32 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16681 | test ppl 3.21173|test cor -0.09766\n",
      "=========================================================================================\n",
      "64 32 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20571 | test ppl 3.33914|test cor 0.08541\n",
      "=========================================================================================\n",
      "64 32 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18259 | test ppl 3.26280|test cor 0.16703\n",
      "=========================================================================================\n",
      "64 32 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16839 | test ppl 3.21681|test cor -0.09439\n",
      "=========================================================================================\n",
      "64 32 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17016 | test ppl 3.22250|test cor 0.19828\n",
      "=========================================================================================\n",
      "64 32 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17961 | test ppl 3.25312|test cor -0.16806\n",
      "=========================================================================================\n",
      "64 32 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16950 | test ppl 3.22039|test cor 0.12754\n",
      "=========================================================================================\n",
      "64 32 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15796 | test ppl 3.18344|test cor 0.11763\n",
      "=========================================================================================\n",
      "64 32 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16731 | test ppl 3.21333|test cor -0.08745\n",
      "=========================================================================================\n",
      "64 32 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.29330 | test ppl 3.64479|test cor 0.09351\n",
      "=========================================================================================\n",
      "64 64 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16903 | test ppl 3.21886|test cor 0.06988\n",
      "=========================================================================================\n",
      "64 64 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15742 | test ppl 3.18172|test cor 0.03984\n",
      "=========================================================================================\n",
      "64 64 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15670 | test ppl 3.17943|test cor -0.01669\n",
      "=========================================================================================\n",
      "64 64 2 2 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16993 | test ppl 3.22178|test cor -0.01587\n",
      "=========================================================================================\n",
      "64 64 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17560 | test ppl 3.24009|test cor 0.03110\n",
      "=========================================================================================\n",
      "64 64 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15921 | test ppl 3.18742|test cor 0.10344\n",
      "=========================================================================================\n",
      "64 64 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16455 | test ppl 3.20447|test cor 0.03623\n",
      "=========================================================================================\n",
      "64 64 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23014 | test ppl 3.42172|test cor 0.11379\n",
      "=========================================================================================\n",
      "64 64 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16659 | test ppl 3.21104|test cor 0.05769\n",
      "=========================================================================================\n",
      "64 64 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15697 | test ppl 3.18029|test cor 0.12128\n",
      "=========================================================================================\n",
      "64 64 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16563 | test ppl 3.20796|test cor -0.07083\n",
      "=========================================================================================\n",
      "64 64 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22590 | test ppl 3.40723|test cor -0.15894\n",
      "=========================================================================================\n",
      "64 64 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16693 | test ppl 3.21210|test cor 0.00889\n",
      "=========================================================================================\n",
      "64 64 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16278 | test ppl 3.19882|test cor 0.08347\n",
      "=========================================================================================\n",
      "64 64 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16948 | test ppl 3.22031|test cor -0.05102\n",
      "=========================================================================================\n",
      "64 64 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22842 | test ppl 3.41583|test cor -0.06731\n",
      "=========================================================================================\n",
      "64 64 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17507 | test ppl 3.23836|test cor 0.00660\n",
      "=========================================================================================\n",
      "64 64 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17269 | test ppl 3.23068|test cor -0.01885\n",
      "=========================================================================================\n",
      "64 64 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16915 | test ppl 3.21926|test cor -0.01818\n",
      "=========================================================================================\n",
      "64 64 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17401 | test ppl 3.23494|test cor 0.11070\n",
      "=========================================================================================\n",
      "64 64 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16307 | test ppl 3.19973|test cor 0.00551\n",
      "=========================================================================================\n",
      "64 64 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16337 | test ppl 3.20070|test cor 0.19999\n",
      "=========================================================================================\n",
      "64 64 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16042 | test ppl 3.19127|test cor -0.02365\n",
      "=========================================================================================\n",
      "64 64 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21790 | test ppl 3.38008|test cor -0.04284\n",
      "=========================================================================================\n",
      "64 64 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15941 | test ppl 3.18806|test cor 0.12366\n",
      "=========================================================================================\n",
      "64 64 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16005 | test ppl 3.19009|test cor -0.05551\n",
      "=========================================================================================\n",
      "64 64 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16103 | test ppl 3.19321|test cor -0.11801\n",
      "=========================================================================================\n",
      "64 64 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16043 | test ppl 3.19130|test cor -0.13793\n",
      "=========================================================================================\n",
      "64 64 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16116 | test ppl 3.19364|test cor 0.05001\n",
      "=========================================================================================\n",
      "64 64 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16514 | test ppl 3.20637|test cor 0.21952\n",
      "=========================================================================================\n",
      "64 64 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17124 | test ppl 3.22599|test cor -0.19582\n",
      "=========================================================================================\n",
      "64 64 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16155 | test ppl 3.19490|test cor -0.04872\n",
      "=========================================================================================\n",
      "64 64 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17921 | test ppl 3.25181|test cor 0.15194\n",
      "=========================================================================================\n",
      "64 64 4 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.15968 | test ppl 3.18891|test cor 0.04473\n",
      "=========================================================================================\n",
      "64 64 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17230 | test ppl 3.22940|test cor -0.01350\n",
      "=========================================================================================\n",
      "64 64 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17100 | test ppl 3.22523|test cor 0.06823\n",
      "=========================================================================================\n",
      "64 64 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16104 | test ppl 3.19325|test cor 0.02001\n",
      "=========================================================================================\n",
      "64 64 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16071 | test ppl 3.19221|test cor 0.05195\n",
      "=========================================================================================\n",
      "64 64 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17424 | test ppl 3.23569|test cor 0.04312\n",
      "=========================================================================================\n",
      "64 64 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23547 | test ppl 3.43999|test cor 0.10574\n",
      "=========================================================================================\n",
      "64 64 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16257 | test ppl 3.19813|test cor 0.13077\n",
      "=========================================================================================\n",
      "64 64 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16127 | test ppl 3.19397|test cor 0.19433\n",
      "=========================================================================================\n",
      "64 64 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15945 | test ppl 3.18820|test cor 0.05451\n",
      "=========================================================================================\n",
      "64 64 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17120 | test ppl 3.22585|test cor -0.12290\n",
      "=========================================================================================\n",
      "64 64 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18823 | test ppl 3.28126|test cor 0.08544\n",
      "=========================================================================================\n",
      "64 64 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16691 | test ppl 3.21207|test cor -0.00593\n",
      "=========================================================================================\n",
      "64 64 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18218 | test ppl 3.26149|test cor 0.19215\n",
      "=========================================================================================\n",
      "64 64 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19890 | test ppl 3.31646|test cor 0.12436\n",
      "=========================================================================================\n",
      "64 64 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18714 | test ppl 3.27768|test cor 0.21020\n",
      "=========================================================================================\n",
      "64 64 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16042 | test ppl 3.19129|test cor -0.25929\n",
      "=========================================================================================\n",
      "64 64 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16754 | test ppl 3.21409|test cor -0.06187\n",
      "=========================================================================================\n",
      "64 64 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16603 | test ppl 3.20921|test cor -0.18674\n",
      "=========================================================================================\n",
      "64 64 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16898 | test ppl 3.21872|test cor 0.09705\n",
      "=========================================================================================\n",
      "64 64 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17387 | test ppl 3.23449|test cor 0.07578\n",
      "=========================================================================================\n",
      "64 64 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17935 | test ppl 3.25226|test cor -0.12560\n",
      "=========================================================================================\n",
      "64 64 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.32847 | test ppl 3.77528|test cor -0.19298\n",
      "=========================================================================================\n",
      "64 64 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16925 | test ppl 3.21957|test cor 0.10446\n",
      "=========================================================================================\n",
      "64 64 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16601 | test ppl 3.20915|test cor 0.06918\n",
      "=========================================================================================\n",
      "64 64 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16348 | test ppl 3.20106|test cor 0.05775\n",
      "=========================================================================================\n",
      "64 64 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18555 | test ppl 3.27250|test cor -0.03853\n",
      "=========================================================================================\n",
      "64 64 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18259 | test ppl 3.26280|test cor 0.09794\n",
      "=========================================================================================\n",
      "64 64 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15979 | test ppl 3.18926|test cor 0.00427\n",
      "=========================================================================================\n",
      "64 64 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17792 | test ppl 3.24761|test cor 0.02359\n",
      "=========================================================================================\n",
      "64 64 6 4 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.20614 | test ppl 3.34055|test cor 0.09098\n",
      "=========================================================================================\n",
      "64 64 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18016 | test ppl 3.25488|test cor 0.10005\n",
      "=========================================================================================\n",
      "64 64 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16103 | test ppl 3.19323|test cor 0.17946\n",
      "=========================================================================================\n",
      "64 64 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16997 | test ppl 3.22189|test cor -0.12245\n",
      "=========================================================================================\n",
      "64 64 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18079 | test ppl 3.25693|test cor -0.17144\n",
      "=========================================================================================\n",
      "64 64 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16053 | test ppl 3.19161|test cor 0.19273\n",
      "=========================================================================================\n",
      "64 64 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16570 | test ppl 3.20817|test cor -0.04962\n",
      "=========================================================================================\n",
      "64 64 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19080 | test ppl 3.28972|test cor -0.06753\n",
      "=========================================================================================\n",
      "64 64 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26706 | test ppl 3.55038|test cor -0.07271\n",
      "=========================================================================================\n",
      "64 64 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19552 | test ppl 3.30527|test cor 0.14452\n",
      "=========================================================================================\n",
      "64 64 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16438 | test ppl 3.20394|test cor -0.21464\n",
      "=========================================================================================\n",
      "64 64 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16340 | test ppl 3.20079|test cor -0.16633\n",
      "=========================================================================================\n",
      "64 64 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18633 | test ppl 3.27504|test cor 0.00053\n",
      "=========================================================================================\n",
      "64 64 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17132 | test ppl 3.22624|test cor 0.12683\n",
      "=========================================================================================\n",
      "64 64 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16158 | test ppl 3.19498|test cor 0.12270\n",
      "=========================================================================================\n",
      "64 64 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16454 | test ppl 3.20446|test cor 0.08661\n",
      "=========================================================================================\n",
      "64 64 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17062 | test ppl 3.22399|test cor 0.15461\n",
      "=========================================================================================\n",
      "64 64 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17554 | test ppl 3.23991|test cor 0.15743\n",
      "=========================================================================================\n",
      "64 64 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17312 | test ppl 3.23206|test cor -0.15533\n",
      "=========================================================================================\n",
      "64 64 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16653 | test ppl 3.21083|test cor 0.20153\n",
      "=========================================================================================\n",
      "64 64 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23891 | test ppl 3.45185|test cor 0.08311\n",
      "=========================================================================================\n",
      "64 64 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16274 | test ppl 3.19868|test cor 0.16158\n",
      "=========================================================================================\n",
      "64 64 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16539 | test ppl 3.20716|test cor 0.08998\n",
      "=========================================================================================\n",
      "64 64 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16416 | test ppl 3.20323|test cor -0.07984\n",
      "=========================================================================================\n",
      "64 64 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16045 | test ppl 3.19136|test cor 0.13130\n",
      "=========================================================================================\n",
      "64 64 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17155 | test ppl 3.22699|test cor 0.16851\n",
      "=========================================================================================\n",
      "64 64 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16558 | test ppl 3.20779|test cor 0.03144\n",
      "=========================================================================================\n",
      "64 64 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16010 | test ppl 3.19026|test cor -0.05689\n",
      "=========================================================================================\n",
      "64 64 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17283 | test ppl 3.23113|test cor -0.11692\n",
      "=========================================================================================\n",
      "64 64 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16171 | test ppl 3.19540|test cor 0.10945\n",
      "=========================================================================================\n",
      "64 64 8 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16312 | test ppl 3.19989|test cor 0.08670\n",
      "=========================================================================================\n",
      "64 64 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15985 | test ppl 3.18946|test cor 0.03710\n",
      "=========================================================================================\n",
      "64 64 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19812 | test ppl 3.31389|test cor -0.10348\n",
      "=========================================================================================\n",
      "64 128 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17201 | test ppl 3.22846|test cor 0.10023\n",
      "=========================================================================================\n",
      "64 128 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16091 | test ppl 3.19283|test cor 0.12323\n",
      "=========================================================================================\n",
      "64 128 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16508 | test ppl 3.20618|test cor 0.11367\n",
      "=========================================================================================\n",
      "64 128 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24867 | test ppl 3.48571|test cor 0.12507\n",
      "=========================================================================================\n",
      "64 128 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17867 | test ppl 3.25005|test cor -0.01483\n",
      "=========================================================================================\n",
      "64 128 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16347 | test ppl 3.20101|test cor -0.00809\n",
      "=========================================================================================\n",
      "64 128 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17170 | test ppl 3.22747|test cor 0.22271\n",
      "=========================================================================================\n",
      "64 128 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19676 | test ppl 3.30939|test cor 0.07180\n",
      "=========================================================================================\n",
      "64 128 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16282 | test ppl 3.19894|test cor 0.10013\n",
      "=========================================================================================\n",
      "64 128 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16029 | test ppl 3.19086|test cor 0.09412\n",
      "=========================================================================================\n",
      "64 128 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16193 | test ppl 3.19609|test cor 0.04550\n",
      "=========================================================================================\n",
      "64 128 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28011 | test ppl 3.59702|test cor 0.01495\n",
      "=========================================================================================\n",
      "64 128 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17137 | test ppl 3.22641|test cor 0.01608\n",
      "=========================================================================================\n",
      "64 128 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16575 | test ppl 3.20834|test cor 0.15351\n",
      "=========================================================================================\n",
      "64 128 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17317 | test ppl 3.23224|test cor -0.05235\n",
      "=========================================================================================\n",
      "64 128 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17953 | test ppl 3.25283|test cor -0.04214\n",
      "=========================================================================================\n",
      "64 128 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16429 | test ppl 3.20363|test cor 0.07867\n",
      "=========================================================================================\n",
      "64 128 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16017 | test ppl 3.19047|test cor 0.11138\n",
      "=========================================================================================\n",
      "64 128 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15986 | test ppl 3.18949|test cor 0.03489\n",
      "=========================================================================================\n",
      "64 128 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24360 | test ppl 3.46806|test cor -0.04808\n",
      "=========================================================================================\n",
      "64 128 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16797 | test ppl 3.21545|test cor 0.02470\n",
      "=========================================================================================\n",
      "64 128 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16618 | test ppl 3.20972|test cor 0.00685\n",
      "=========================================================================================\n",
      "64 128 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17399 | test ppl 3.23487|test cor 0.03216\n",
      "=========================================================================================\n",
      "64 128 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22085 | test ppl 3.39007|test cor -0.01741\n",
      "=========================================================================================\n",
      "64 128 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17940 | test ppl 3.25242|test cor 0.15128\n",
      "=========================================================================================\n",
      "64 128 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16068 | test ppl 3.19211|test cor 0.09179\n",
      "=========================================================================================\n",
      "64 128 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16739 | test ppl 3.21359|test cor 0.21954\n",
      "=========================================================================================\n",
      "64 128 4 2 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16560 | test ppl 3.20784|test cor 0.23824\n",
      "=========================================================================================\n",
      "64 128 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16163 | test ppl 3.19513|test cor 0.10534\n",
      "=========================================================================================\n",
      "64 128 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15973 | test ppl 3.18909|test cor 0.12418\n",
      "=========================================================================================\n",
      "64 128 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16217 | test ppl 3.19687|test cor -0.13949\n",
      "=========================================================================================\n",
      "64 128 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20717 | test ppl 3.34399|test cor 0.01842\n",
      "=========================================================================================\n",
      "64 128 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18507 | test ppl 3.27092|test cor 0.12669\n",
      "=========================================================================================\n",
      "64 128 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16354 | test ppl 3.20125|test cor -0.12089\n",
      "=========================================================================================\n",
      "64 128 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15556 | test ppl 3.17580|test cor 0.03467\n",
      "=========================================================================================\n",
      "64 128 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.54269 | test ppl 4.67717|test cor -0.10848\n",
      "=========================================================================================\n",
      "64 128 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16812 | test ppl 3.21594|test cor 0.08147\n",
      "=========================================================================================\n",
      "64 128 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16541 | test ppl 3.20723|test cor 0.00463\n",
      "=========================================================================================\n",
      "64 128 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17759 | test ppl 3.24654|test cor -0.10442\n",
      "=========================================================================================\n",
      "64 128 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21267 | test ppl 3.36244|test cor -0.14548\n",
      "=========================================================================================\n",
      "64 128 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18633 | test ppl 3.27506|test cor 0.03437\n",
      "=========================================================================================\n",
      "64 128 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16047 | test ppl 3.19142|test cor 0.02693\n",
      "=========================================================================================\n",
      "64 128 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16944 | test ppl 3.22019|test cor -0.04341\n",
      "=========================================================================================\n",
      "64 128 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16925 | test ppl 3.21956|test cor -0.16414\n",
      "=========================================================================================\n",
      "64 128 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16321 | test ppl 3.20019|test cor 0.05664\n",
      "=========================================================================================\n",
      "64 128 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16794 | test ppl 3.21535|test cor 0.10477\n",
      "=========================================================================================\n",
      "64 128 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17627 | test ppl 3.24225|test cor -0.19781\n",
      "=========================================================================================\n",
      "64 128 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17401 | test ppl 3.23494|test cor 0.07988\n",
      "=========================================================================================\n",
      "64 128 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17236 | test ppl 3.22959|test cor 0.24492\n",
      "=========================================================================================\n",
      "64 128 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15513 | test ppl 3.17443|test cor 0.08083\n",
      "=========================================================================================\n",
      "64 128 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16247 | test ppl 3.19783|test cor -0.00977\n",
      "=========================================================================================\n",
      "64 128 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17303 | test ppl 3.23176|test cor -0.02411\n",
      "=========================================================================================\n",
      "64 128 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16373 | test ppl 3.20185|test cor 0.20804\n",
      "=========================================================================================\n",
      "64 128 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16080 | test ppl 3.19247|test cor 0.15586\n",
      "=========================================================================================\n",
      "64 128 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16810 | test ppl 3.21587|test cor 0.22416\n",
      "=========================================================================================\n",
      "64 128 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17516 | test ppl 3.23865|test cor 0.14243\n",
      "=========================================================================================\n",
      "64 128 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16384 | test ppl 3.20220|test cor 0.15449\n",
      "=========================================================================================\n",
      "64 128 6 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16138 | test ppl 3.19433|test cor 0.12166\n",
      "=========================================================================================\n",
      "64 128 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16575 | test ppl 3.20831|test cor 0.15308\n",
      "=========================================================================================\n",
      "64 128 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18504 | test ppl 3.27083|test cor 0.06386\n",
      "=========================================================================================\n",
      "64 128 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17183 | test ppl 3.22789|test cor 0.14931\n",
      "=========================================================================================\n",
      "64 128 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16568 | test ppl 3.20811|test cor 0.09364\n",
      "=========================================================================================\n",
      "64 128 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16712 | test ppl 3.21273|test cor -0.15759\n",
      "=========================================================================================\n",
      "64 128 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20871 | test ppl 3.34917|test cor 0.18362\n",
      "=========================================================================================\n",
      "64 128 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16550 | test ppl 3.20752|test cor 0.02377\n",
      "=========================================================================================\n",
      "64 128 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16267 | test ppl 3.19846|test cor 0.11553\n",
      "=========================================================================================\n",
      "64 128 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17258 | test ppl 3.23033|test cor -0.16276\n",
      "=========================================================================================\n",
      "64 128 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16679 | test ppl 3.21168|test cor 0.09093\n",
      "=========================================================================================\n",
      "64 128 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18427 | test ppl 3.26830|test cor 0.19452\n",
      "=========================================================================================\n",
      "64 128 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16141 | test ppl 3.19443|test cor -0.16244\n",
      "=========================================================================================\n",
      "64 128 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16792 | test ppl 3.21529|test cor 0.08047\n",
      "=========================================================================================\n",
      "64 128 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18379 | test ppl 3.26673|test cor -0.10288\n",
      "=========================================================================================\n",
      "64 128 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18331 | test ppl 3.26518|test cor 0.15191\n",
      "=========================================================================================\n",
      "64 128 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15931 | test ppl 3.18775|test cor -0.10158\n",
      "=========================================================================================\n",
      "64 128 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16221 | test ppl 3.19701|test cor -0.11015\n",
      "=========================================================================================\n",
      "64 128 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20348 | test ppl 3.33169|test cor -0.12750\n",
      "=========================================================================================\n",
      "64 128 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17499 | test ppl 3.23810|test cor 0.18112\n",
      "=========================================================================================\n",
      "64 128 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16338 | test ppl 3.20073|test cor 0.20271\n",
      "=========================================================================================\n",
      "64 128 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16270 | test ppl 3.19855|test cor 0.11413\n",
      "=========================================================================================\n",
      "64 128 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17985 | test ppl 3.25388|test cor -0.16646\n",
      "=========================================================================================\n",
      "64 128 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16544 | test ppl 3.20734|test cor 0.20527\n",
      "=========================================================================================\n",
      "64 128 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16216 | test ppl 3.19683|test cor -0.13405\n",
      "=========================================================================================\n",
      "64 128 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16436 | test ppl 3.20386|test cor 0.11430\n",
      "=========================================================================================\n",
      "64 128 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18338 | test ppl 3.26539|test cor -0.02831\n",
      "=========================================================================================\n",
      "64 128 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17353 | test ppl 3.23339|test cor 0.16560\n",
      "=========================================================================================\n",
      "64 128 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16156 | test ppl 3.19492|test cor 0.12005\n",
      "=========================================================================================\n",
      "64 128 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16600 | test ppl 3.20912|test cor 0.22235\n",
      "=========================================================================================\n",
      "64 128 8 4 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.21081 | test ppl 3.35619|test cor 0.20772\n",
      "=========================================================================================\n",
      "64 128 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19154 | test ppl 3.29214|test cor 0.13856\n",
      "=========================================================================================\n",
      "64 128 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16477 | test ppl 3.20518|test cor -0.20250\n",
      "=========================================================================================\n",
      "64 128 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16030 | test ppl 3.19090|test cor -0.03899\n",
      "=========================================================================================\n",
      "64 128 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17442 | test ppl 3.23626|test cor -0.02702\n",
      "=========================================================================================\n",
      "64 128 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16386 | test ppl 3.20229|test cor 0.11458\n",
      "=========================================================================================\n",
      "64 128 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15900 | test ppl 3.18675|test cor 0.07715\n",
      "=========================================================================================\n",
      "64 128 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16311 | test ppl 3.19987|test cor 0.18748\n",
      "=========================================================================================\n",
      "64 128 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19276 | test ppl 3.29618|test cor 0.20288\n",
      "=========================================================================================\n",
      "64 256 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16695 | test ppl 3.21220|test cor 0.05233\n",
      "=========================================================================================\n",
      "64 256 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15908 | test ppl 3.18702|test cor 0.08324\n",
      "=========================================================================================\n",
      "64 256 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15970 | test ppl 3.18899|test cor 0.12294\n",
      "=========================================================================================\n",
      "64 256 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16753 | test ppl 3.21403|test cor -0.15177\n",
      "=========================================================================================\n",
      "64 256 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18721 | test ppl 3.27792|test cor -0.00458\n",
      "=========================================================================================\n",
      "64 256 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16189 | test ppl 3.19596|test cor -0.03629\n",
      "=========================================================================================\n",
      "64 256 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16688 | test ppl 3.21195|test cor 0.09073\n",
      "=========================================================================================\n",
      "64 256 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21160 | test ppl 3.35886|test cor -0.00536\n",
      "=========================================================================================\n",
      "64 256 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17219 | test ppl 3.22905|test cor 0.09311\n",
      "=========================================================================================\n",
      "64 256 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15576 | test ppl 3.17643|test cor 0.09171\n",
      "=========================================================================================\n",
      "64 256 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15906 | test ppl 3.18694|test cor 0.09323\n",
      "=========================================================================================\n",
      "64 256 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17692 | test ppl 3.24438|test cor 0.14484\n",
      "=========================================================================================\n",
      "64 256 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17002 | test ppl 3.22207|test cor 0.00618\n",
      "=========================================================================================\n",
      "64 256 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16076 | test ppl 3.19235|test cor 0.01295\n",
      "=========================================================================================\n",
      "64 256 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16461 | test ppl 3.20467|test cor 0.10697\n",
      "=========================================================================================\n",
      "64 256 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28127 | test ppl 3.60121|test cor 0.04050\n",
      "=========================================================================================\n",
      "64 256 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16320 | test ppl 3.20016|test cor 0.08073\n",
      "=========================================================================================\n",
      "64 256 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16291 | test ppl 3.19924|test cor 0.09572\n",
      "=========================================================================================\n",
      "64 256 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16453 | test ppl 3.20443|test cor 0.00697\n",
      "=========================================================================================\n",
      "64 256 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17948 | test ppl 3.25267|test cor -0.13722\n",
      "=========================================================================================\n",
      "64 256 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16627 | test ppl 3.20998|test cor 0.01765\n",
      "=========================================================================================\n",
      "64 256 2 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.15623 | test ppl 3.17792|test cor -0.01902\n",
      "=========================================================================================\n",
      "64 256 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17499 | test ppl 3.23809|test cor 0.05982\n",
      "=========================================================================================\n",
      "64 256 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20874 | test ppl 3.34927|test cor 0.09580\n",
      "=========================================================================================\n",
      "64 256 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18889 | test ppl 3.28342|test cor 0.13628\n",
      "=========================================================================================\n",
      "64 256 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16017 | test ppl 3.19048|test cor 0.23152\n",
      "=========================================================================================\n",
      "64 256 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16508 | test ppl 3.20619|test cor 0.12675\n",
      "=========================================================================================\n",
      "64 256 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24903 | test ppl 3.48698|test cor 0.08745\n",
      "=========================================================================================\n",
      "64 256 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16660 | test ppl 3.21107|test cor 0.15506\n",
      "=========================================================================================\n",
      "64 256 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16807 | test ppl 3.21578|test cor 0.22736\n",
      "=========================================================================================\n",
      "64 256 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17225 | test ppl 3.22924|test cor -0.07270\n",
      "=========================================================================================\n",
      "64 256 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18053 | test ppl 3.25610|test cor 0.04463\n",
      "=========================================================================================\n",
      "64 256 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16804 | test ppl 3.21567|test cor 0.10768\n",
      "=========================================================================================\n",
      "64 256 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16415 | test ppl 3.20320|test cor -0.05764\n",
      "=========================================================================================\n",
      "64 256 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16427 | test ppl 3.20357|test cor 0.01251\n",
      "=========================================================================================\n",
      "64 256 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.40079 | test ppl 4.05842|test cor 0.04802\n",
      "=========================================================================================\n",
      "64 256 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16571 | test ppl 3.20821|test cor 0.09593\n",
      "=========================================================================================\n",
      "64 256 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16482 | test ppl 3.20533|test cor 0.21415\n",
      "=========================================================================================\n",
      "64 256 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17373 | test ppl 3.23402|test cor -0.01003\n",
      "=========================================================================================\n",
      "64 256 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.43412 | test ppl 4.19593|test cor -0.07334\n",
      "=========================================================================================\n",
      "64 256 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17455 | test ppl 3.23668|test cor 0.14552\n",
      "=========================================================================================\n",
      "64 256 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16292 | test ppl 3.19926|test cor 0.03927\n",
      "=========================================================================================\n",
      "64 256 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16820 | test ppl 3.21621|test cor 0.00631\n",
      "=========================================================================================\n",
      "64 256 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17801 | test ppl 3.24791|test cor -0.10090\n",
      "=========================================================================================\n",
      "64 256 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18231 | test ppl 3.26189|test cor 0.08707\n",
      "=========================================================================================\n",
      "64 256 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16215 | test ppl 3.19678|test cor 0.06402\n",
      "=========================================================================================\n",
      "64 256 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17899 | test ppl 3.25110|test cor 0.12043\n",
      "=========================================================================================\n",
      "64 256 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.58825 | test ppl 4.89518|test cor 0.02384\n",
      "=========================================================================================\n",
      "64 256 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17225 | test ppl 3.22926|test cor -0.02492\n",
      "=========================================================================================\n",
      "64 256 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15839 | test ppl 3.18480|test cor 0.06961\n",
      "=========================================================================================\n",
      "64 256 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17805 | test ppl 3.24805|test cor 0.11614\n",
      "=========================================================================================\n",
      "64 256 6 2 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.19544 | test ppl 3.30500|test cor -0.02738\n",
      "=========================================================================================\n",
      "64 256 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16809 | test ppl 3.21585|test cor 0.22300\n",
      "=========================================================================================\n",
      "64 256 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16496 | test ppl 3.20578|test cor 0.15659\n",
      "=========================================================================================\n",
      "64 256 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16722 | test ppl 3.21306|test cor -0.15959\n",
      "=========================================================================================\n",
      "64 256 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17311 | test ppl 3.23203|test cor 0.22458\n",
      "=========================================================================================\n",
      "64 256 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16558 | test ppl 3.20779|test cor 0.10670\n",
      "=========================================================================================\n",
      "64 256 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16833 | test ppl 3.21663|test cor 0.22687\n",
      "=========================================================================================\n",
      "64 256 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15592 | test ppl 3.17695|test cor -0.10714\n",
      "=========================================================================================\n",
      "64 256 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19450 | test ppl 3.30190|test cor 0.20729\n",
      "=========================================================================================\n",
      "64 256 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17366 | test ppl 3.23382|test cor 0.10166\n",
      "=========================================================================================\n",
      "64 256 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15767 | test ppl 3.18251|test cor -0.02263\n",
      "=========================================================================================\n",
      "64 256 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16433 | test ppl 3.20377|test cor 0.17067\n",
      "=========================================================================================\n",
      "64 256 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19183 | test ppl 3.29311|test cor 0.11770\n",
      "=========================================================================================\n",
      "64 256 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18728 | test ppl 3.27815|test cor 0.13448\n",
      "=========================================================================================\n",
      "64 256 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16433 | test ppl 3.20377|test cor 0.06955\n",
      "=========================================================================================\n",
      "64 256 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16464 | test ppl 3.20477|test cor 0.19120\n",
      "=========================================================================================\n",
      "64 256 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18579 | test ppl 3.27328|test cor 0.01018\n",
      "=========================================================================================\n",
      "64 256 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20508 | test ppl 3.33703|test cor -0.03473\n",
      "=========================================================================================\n",
      "64 256 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16259 | test ppl 3.19820|test cor 0.10495\n",
      "=========================================================================================\n",
      "64 256 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17117 | test ppl 3.22577|test cor 0.09026\n",
      "=========================================================================================\n",
      "64 256 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16362 | test ppl 3.20150|test cor 0.06534\n",
      "=========================================================================================\n",
      "64 256 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17074 | test ppl 3.22437|test cor -0.02089\n",
      "=========================================================================================\n",
      "64 256 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16876 | test ppl 3.21799|test cor -0.01365\n",
      "=========================================================================================\n",
      "64 256 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16007 | test ppl 3.19016|test cor 0.07352\n",
      "=========================================================================================\n",
      "64 256 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16058 | test ppl 3.19178|test cor 0.01247\n",
      "=========================================================================================\n",
      "64 256 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16702 | test ppl 3.21240|test cor 0.24112\n",
      "=========================================================================================\n",
      "64 256 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16024 | test ppl 3.19069|test cor 0.08314\n",
      "=========================================================================================\n",
      "64 256 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16243 | test ppl 3.19769|test cor -0.07742\n",
      "=========================================================================================\n",
      "64 256 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17965 | test ppl 3.25324|test cor -0.16438\n",
      "=========================================================================================\n",
      "64 256 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17918 | test ppl 3.25170|test cor -0.20540\n",
      "=========================================================================================\n",
      "64 256 8 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16098 | test ppl 3.19306|test cor 0.20971\n",
      "=========================================================================================\n",
      "64 256 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16483 | test ppl 3.20537|test cor -0.14315\n",
      "=========================================================================================\n",
      "64 256 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18783 | test ppl 3.27995|test cor -0.00100\n",
      "=========================================================================================\n",
      "64 256 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17489 | test ppl 3.23779|test cor 0.15486\n",
      "=========================================================================================\n",
      "64 256 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16278 | test ppl 3.19881|test cor -0.13246\n",
      "=========================================================================================\n",
      "64 256 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16372 | test ppl 3.20182|test cor -0.22406\n",
      "=========================================================================================\n",
      "64 256 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.30438 | test ppl 3.68541|test cor -0.12948\n",
      "=========================================================================================\n",
      "64 256 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19064 | test ppl 3.28918|test cor 0.03542\n",
      "=========================================================================================\n",
      "64 256 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16259 | test ppl 3.19822|test cor -0.14658\n",
      "=========================================================================================\n",
      "64 256 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16610 | test ppl 3.20947|test cor -0.06283\n",
      "=========================================================================================\n",
      "64 256 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18609 | test ppl 3.27424|test cor -0.15722\n",
      "=========================================================================================\n",
      "64 256 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17262 | test ppl 3.23044|test cor 0.13089\n",
      "=========================================================================================\n",
      "64 256 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17009 | test ppl 3.22227|test cor 0.21615\n",
      "=========================================================================================\n",
      "64 256 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19312 | test ppl 3.29734|test cor 0.05529\n",
      "=========================================================================================\n",
      "64 256 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17343 | test ppl 3.23308|test cor -0.14578\n",
      "=========================================================================================\n",
      "128 8 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20373 | test ppl 3.33251|test cor 0.14165\n",
      "=========================================================================================\n",
      "128 8 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15871 | test ppl 3.18583|test cor 0.12917\n",
      "=========================================================================================\n",
      "128 8 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15438 | test ppl 3.17207|test cor 0.05400\n",
      "=========================================================================================\n",
      "128 8 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19679 | test ppl 3.30949|test cor 0.00511\n",
      "=========================================================================================\n",
      "128 8 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18037 | test ppl 3.25559|test cor 0.04193\n",
      "=========================================================================================\n",
      "128 8 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16402 | test ppl 3.20279|test cor 0.11114\n",
      "=========================================================================================\n",
      "128 8 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16119 | test ppl 3.19372|test cor -0.08842\n",
      "=========================================================================================\n",
      "128 8 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20597 | test ppl 3.33998|test cor -0.18335\n",
      "=========================================================================================\n",
      "128 8 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18931 | test ppl 3.28482|test cor 0.07888\n",
      "=========================================================================================\n",
      "128 8 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15992 | test ppl 3.18968|test cor 0.05404\n",
      "=========================================================================================\n",
      "128 8 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16220 | test ppl 3.19695|test cor 0.20543\n",
      "=========================================================================================\n",
      "128 8 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18141 | test ppl 3.25897|test cor 0.05931\n",
      "=========================================================================================\n",
      "128 8 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16936 | test ppl 3.21993|test cor 0.02453\n",
      "=========================================================================================\n",
      "128 8 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17307 | test ppl 3.23189|test cor 0.11044\n",
      "=========================================================================================\n",
      "128 8 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15871 | test ppl 3.18581|test cor -0.11723\n",
      "=========================================================================================\n",
      "128 8 2 4 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.29053 | test ppl 3.63470|test cor 0.03687\n",
      "=========================================================================================\n",
      "128 8 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21026 | test ppl 3.35435|test cor 0.14795\n",
      "=========================================================================================\n",
      "128 8 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15708 | test ppl 3.18063|test cor 0.11236\n",
      "=========================================================================================\n",
      "128 8 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16825 | test ppl 3.21635|test cor 0.06946\n",
      "=========================================================================================\n",
      "128 8 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22410 | test ppl 3.40112|test cor 0.08401\n",
      "=========================================================================================\n",
      "128 8 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17151 | test ppl 3.22686|test cor 0.04953\n",
      "=========================================================================================\n",
      "128 8 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16367 | test ppl 3.20167|test cor 0.15212\n",
      "=========================================================================================\n",
      "128 8 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16084 | test ppl 3.19261|test cor 0.05442\n",
      "=========================================================================================\n",
      "128 8 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.29664 | test ppl 3.65700|test cor 0.01634\n",
      "=========================================================================================\n",
      "128 8 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21299 | test ppl 3.36352|test cor 0.12681\n",
      "=========================================================================================\n",
      "128 8 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16097 | test ppl 3.19304|test cor -0.11310\n",
      "=========================================================================================\n",
      "128 8 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16434 | test ppl 3.20382|test cor 0.11211\n",
      "=========================================================================================\n",
      "128 8 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18941 | test ppl 3.28514|test cor 0.15064\n",
      "=========================================================================================\n",
      "128 8 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23182 | test ppl 3.42745|test cor 0.13414\n",
      "=========================================================================================\n",
      "128 8 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16410 | test ppl 3.20304|test cor 0.06890\n",
      "=========================================================================================\n",
      "128 8 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16166 | test ppl 3.19523|test cor 0.10673\n",
      "=========================================================================================\n",
      "128 8 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17340 | test ppl 3.23297|test cor 0.22143\n",
      "=========================================================================================\n",
      "128 8 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17823 | test ppl 3.24861|test cor 0.11080\n",
      "=========================================================================================\n",
      "128 8 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16113 | test ppl 3.19355|test cor 0.14703\n",
      "=========================================================================================\n",
      "128 8 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16286 | test ppl 3.19908|test cor -0.22028\n",
      "=========================================================================================\n",
      "128 8 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22136 | test ppl 3.39180|test cor -0.00207\n",
      "=========================================================================================\n",
      "128 8 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17410 | test ppl 3.23524|test cor 0.12575\n",
      "=========================================================================================\n",
      "128 8 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16451 | test ppl 3.20434|test cor 0.07880\n",
      "=========================================================================================\n",
      "128 8 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16303 | test ppl 3.19960|test cor 0.13588\n",
      "=========================================================================================\n",
      "128 8 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17352 | test ppl 3.23335|test cor -0.18402\n",
      "=========================================================================================\n",
      "128 8 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17311 | test ppl 3.23204|test cor 0.05239\n",
      "=========================================================================================\n",
      "128 8 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16809 | test ppl 3.21585|test cor -0.15784\n",
      "=========================================================================================\n",
      "128 8 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16022 | test ppl 3.19063|test cor 0.01018\n",
      "=========================================================================================\n",
      "128 8 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17223 | test ppl 3.22918|test cor -0.04747\n",
      "=========================================================================================\n",
      "128 8 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16406 | test ppl 3.20289|test cor 0.09515\n",
      "=========================================================================================\n",
      "128 8 4 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16955 | test ppl 3.22055|test cor 0.20131\n",
      "=========================================================================================\n",
      "128 8 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16536 | test ppl 3.20709|test cor 0.05384\n",
      "=========================================================================================\n",
      "128 8 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18137 | test ppl 3.25883|test cor 0.17571\n",
      "=========================================================================================\n",
      "128 8 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16545 | test ppl 3.20737|test cor 0.10759\n",
      "=========================================================================================\n",
      "128 8 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16444 | test ppl 3.20413|test cor -0.02087\n",
      "=========================================================================================\n",
      "128 8 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16332 | test ppl 3.20053|test cor -0.11685\n",
      "=========================================================================================\n",
      "128 8 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18008 | test ppl 3.25463|test cor -0.11168\n",
      "=========================================================================================\n",
      "128 8 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26170 | test ppl 3.53143|test cor 0.18158\n",
      "=========================================================================================\n",
      "128 8 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16506 | test ppl 3.20611|test cor 0.13130\n",
      "=========================================================================================\n",
      "128 8 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15558 | test ppl 3.17585|test cor 0.07731\n",
      "=========================================================================================\n",
      "128 8 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19128 | test ppl 3.29130|test cor -0.11088\n",
      "=========================================================================================\n",
      "128 8 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17392 | test ppl 3.23463|test cor 0.08951\n",
      "=========================================================================================\n",
      "128 8 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16052 | test ppl 3.19159|test cor 0.10226\n",
      "=========================================================================================\n",
      "128 8 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16383 | test ppl 3.20216|test cor 0.15220\n",
      "=========================================================================================\n",
      "128 8 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18100 | test ppl 3.25764|test cor 0.05499\n",
      "=========================================================================================\n",
      "128 8 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16827 | test ppl 3.21643|test cor 0.19515\n",
      "=========================================================================================\n",
      "128 8 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16288 | test ppl 3.19914|test cor -0.07718\n",
      "=========================================================================================\n",
      "128 8 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16545 | test ppl 3.20736|test cor 0.12073\n",
      "=========================================================================================\n",
      "128 8 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18531 | test ppl 3.27171|test cor 0.12563\n",
      "=========================================================================================\n",
      "128 8 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18392 | test ppl 3.26716|test cor 0.01802\n",
      "=========================================================================================\n",
      "128 8 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16351 | test ppl 3.20115|test cor -0.11338\n",
      "=========================================================================================\n",
      "128 8 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16487 | test ppl 3.20549|test cor -0.12689\n",
      "=========================================================================================\n",
      "128 8 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19239 | test ppl 3.29494|test cor 0.10146\n",
      "=========================================================================================\n",
      "128 8 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17713 | test ppl 3.24506|test cor 0.22454\n",
      "=========================================================================================\n",
      "128 8 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17875 | test ppl 3.25030|test cor -0.05338\n",
      "=========================================================================================\n",
      "128 8 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16294 | test ppl 3.19933|test cor 0.18218\n",
      "=========================================================================================\n",
      "128 8 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21217 | test ppl 3.36077|test cor 0.08075\n",
      "=========================================================================================\n",
      "128 8 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16954 | test ppl 3.22052|test cor 0.26737\n",
      "=========================================================================================\n",
      "128 8 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15917 | test ppl 3.18728|test cor 0.13615\n",
      "=========================================================================================\n",
      "128 8 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16225 | test ppl 3.19713|test cor 0.03141\n",
      "=========================================================================================\n",
      "128 8 8 2 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16889 | test ppl 3.21840|test cor 0.05848\n",
      "=========================================================================================\n",
      "128 8 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20402 | test ppl 3.33348|test cor 0.16643\n",
      "=========================================================================================\n",
      "128 8 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16240 | test ppl 3.19761|test cor 0.20460\n",
      "=========================================================================================\n",
      "128 8 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16938 | test ppl 3.22001|test cor 0.19306\n",
      "=========================================================================================\n",
      "128 8 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18207 | test ppl 3.26111|test cor -0.09171\n",
      "=========================================================================================\n",
      "128 8 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16553 | test ppl 3.20763|test cor 0.15508\n",
      "=========================================================================================\n",
      "128 8 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16653 | test ppl 3.21085|test cor -0.11931\n",
      "=========================================================================================\n",
      "128 8 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17002 | test ppl 3.22205|test cor -0.11702\n",
      "=========================================================================================\n",
      "128 8 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19827 | test ppl 3.31436|test cor -0.20095\n",
      "=========================================================================================\n",
      "128 8 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20471 | test ppl 3.33579|test cor 0.04669\n",
      "=========================================================================================\n",
      "128 8 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17523 | test ppl 3.23889|test cor -0.05634\n",
      "=========================================================================================\n",
      "128 8 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16948 | test ppl 3.22030|test cor -0.07056\n",
      "=========================================================================================\n",
      "128 8 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18652 | test ppl 3.27565|test cor 0.20613\n",
      "=========================================================================================\n",
      "128 8 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18118 | test ppl 3.25822|test cor 0.17642\n",
      "=========================================================================================\n",
      "128 8 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16370 | test ppl 3.20174|test cor 0.01064\n",
      "=========================================================================================\n",
      "128 8 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16448 | test ppl 3.20425|test cor 0.17743\n",
      "=========================================================================================\n",
      "128 8 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19328 | test ppl 3.29787|test cor -0.13045\n",
      "=========================================================================================\n",
      "128 8 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17495 | test ppl 3.23800|test cor 0.13372\n",
      "=========================================================================================\n",
      "128 8 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16405 | test ppl 3.20289|test cor 0.12316\n",
      "=========================================================================================\n",
      "128 8 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16694 | test ppl 3.21215|test cor -0.09440\n",
      "=========================================================================================\n",
      "128 8 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17141 | test ppl 3.22655|test cor -0.12064\n",
      "=========================================================================================\n",
      "128 32 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17435 | test ppl 3.23605|test cor 0.03093\n",
      "=========================================================================================\n",
      "128 32 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16231 | test ppl 3.19732|test cor 0.12459\n",
      "=========================================================================================\n",
      "128 32 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15964 | test ppl 3.18877|test cor 0.04918\n",
      "=========================================================================================\n",
      "128 32 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17248 | test ppl 3.23000|test cor -0.03269\n",
      "=========================================================================================\n",
      "128 32 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20898 | test ppl 3.35006|test cor -0.02250\n",
      "=========================================================================================\n",
      "128 32 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15566 | test ppl 3.17613|test cor 0.05413\n",
      "=========================================================================================\n",
      "128 32 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17543 | test ppl 3.23955|test cor -0.00321\n",
      "=========================================================================================\n",
      "128 32 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22835 | test ppl 3.41559|test cor -0.14472\n",
      "=========================================================================================\n",
      "128 32 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17271 | test ppl 3.23074|test cor 0.07386\n",
      "=========================================================================================\n",
      "128 32 2 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.15842 | test ppl 3.18489|test cor 0.00327\n",
      "=========================================================================================\n",
      "128 32 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16175 | test ppl 3.19553|test cor 0.03127\n",
      "=========================================================================================\n",
      "128 32 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25621 | test ppl 3.51209|test cor 0.04671\n",
      "=========================================================================================\n",
      "128 32 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21564 | test ppl 3.37245|test cor 0.00675\n",
      "=========================================================================================\n",
      "128 32 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15897 | test ppl 3.18666|test cor 0.05745\n",
      "=========================================================================================\n",
      "128 32 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16264 | test ppl 3.19837|test cor -0.04430\n",
      "=========================================================================================\n",
      "128 32 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17631 | test ppl 3.24237|test cor 0.01449\n",
      "=========================================================================================\n",
      "128 32 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17623 | test ppl 3.24214|test cor 0.05097\n",
      "=========================================================================================\n",
      "128 32 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16259 | test ppl 3.19821|test cor 0.14669\n",
      "=========================================================================================\n",
      "128 32 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16484 | test ppl 3.20540|test cor 0.09573\n",
      "=========================================================================================\n",
      "128 32 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17143 | test ppl 3.22660|test cor -0.17102\n",
      "=========================================================================================\n",
      "128 32 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20019 | test ppl 3.32074|test cor 0.00647\n",
      "=========================================================================================\n",
      "128 32 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16551 | test ppl 3.20757|test cor 0.09773\n",
      "=========================================================================================\n",
      "128 32 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16171 | test ppl 3.19538|test cor 0.00719\n",
      "=========================================================================================\n",
      "128 32 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16786 | test ppl 3.21511|test cor 0.02301\n",
      "=========================================================================================\n",
      "128 32 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16953 | test ppl 3.22048|test cor 0.07863\n",
      "=========================================================================================\n",
      "128 32 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16168 | test ppl 3.19528|test cor 0.16276\n",
      "=========================================================================================\n",
      "128 32 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16454 | test ppl 3.20444|test cor -0.00200\n",
      "=========================================================================================\n",
      "128 32 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.29078 | test ppl 3.63562|test cor -0.09393\n",
      "=========================================================================================\n",
      "128 32 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16935 | test ppl 3.21989|test cor 0.13991\n",
      "=========================================================================================\n",
      "128 32 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16344 | test ppl 3.20094|test cor 0.18305\n",
      "=========================================================================================\n",
      "128 32 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16532 | test ppl 3.20695|test cor 0.21309\n",
      "=========================================================================================\n",
      "128 32 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23314 | test ppl 3.43200|test cor 0.10900\n",
      "=========================================================================================\n",
      "128 32 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18035 | test ppl 3.25551|test cor 0.12438\n",
      "=========================================================================================\n",
      "128 32 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16444 | test ppl 3.20414|test cor 0.04639\n",
      "=========================================================================================\n",
      "128 32 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15823 | test ppl 3.18430|test cor 0.06996\n",
      "=========================================================================================\n",
      "128 32 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19317 | test ppl 3.29751|test cor -0.20206\n",
      "=========================================================================================\n",
      "128 32 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17936 | test ppl 3.25229|test cor 0.16222\n",
      "=========================================================================================\n",
      "128 32 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17013 | test ppl 3.22241|test cor 0.21890\n",
      "=========================================================================================\n",
      "128 32 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17125 | test ppl 3.22602|test cor 0.06892\n",
      "=========================================================================================\n",
      "128 32 4 4 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.25315 | test ppl 3.50134|test cor -0.02461\n",
      "=========================================================================================\n",
      "128 32 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19980 | test ppl 3.31945|test cor 0.14496\n",
      "=========================================================================================\n",
      "128 32 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15658 | test ppl 3.17904|test cor 0.18977\n",
      "=========================================================================================\n",
      "128 32 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16119 | test ppl 3.19372|test cor -0.09737\n",
      "=========================================================================================\n",
      "128 32 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21469 | test ppl 3.36925|test cor 0.06100\n",
      "=========================================================================================\n",
      "128 32 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18089 | test ppl 3.25728|test cor 0.15137\n",
      "=========================================================================================\n",
      "128 32 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16285 | test ppl 3.19903|test cor 0.02256\n",
      "=========================================================================================\n",
      "128 32 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15799 | test ppl 3.18353|test cor 0.16491\n",
      "=========================================================================================\n",
      "128 32 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21226 | test ppl 3.36107|test cor 0.17822\n",
      "=========================================================================================\n",
      "128 32 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21449 | test ppl 3.36857|test cor 0.19182\n",
      "=========================================================================================\n",
      "128 32 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16324 | test ppl 3.20028|test cor -0.08532\n",
      "=========================================================================================\n",
      "128 32 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16613 | test ppl 3.20955|test cor 0.02780\n",
      "=========================================================================================\n",
      "128 32 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21317 | test ppl 3.36414|test cor 0.08487\n",
      "=========================================================================================\n",
      "128 32 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18634 | test ppl 3.27507|test cor 0.07518\n",
      "=========================================================================================\n",
      "128 32 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16701 | test ppl 3.21237|test cor 0.15095\n",
      "=========================================================================================\n",
      "128 32 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17722 | test ppl 3.24535|test cor -0.11759\n",
      "=========================================================================================\n",
      "128 32 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23534 | test ppl 3.43954|test cor -0.14147\n",
      "=========================================================================================\n",
      "128 32 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17728 | test ppl 3.24552|test cor 0.00010\n",
      "=========================================================================================\n",
      "128 32 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16111 | test ppl 3.19347|test cor 0.03774\n",
      "=========================================================================================\n",
      "128 32 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16858 | test ppl 3.21741|test cor -0.11562\n",
      "=========================================================================================\n",
      "128 32 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22149 | test ppl 3.39223|test cor 0.15574\n",
      "=========================================================================================\n",
      "128 32 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16427 | test ppl 3.20357|test cor 0.12929\n",
      "=========================================================================================\n",
      "128 32 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16326 | test ppl 3.20036|test cor -0.10627\n",
      "=========================================================================================\n",
      "128 32 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21878 | test ppl 3.38307|test cor 0.18275\n",
      "=========================================================================================\n",
      "128 32 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16917 | test ppl 3.21931|test cor -0.13616\n",
      "=========================================================================================\n",
      "128 32 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.27232 | test ppl 3.56911|test cor 0.13617\n",
      "=========================================================================================\n",
      "128 32 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16036 | test ppl 3.19108|test cor 0.09852\n",
      "=========================================================================================\n",
      "128 32 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16590 | test ppl 3.20882|test cor 0.07990\n",
      "=========================================================================================\n",
      "128 32 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18884 | test ppl 3.28328|test cor -0.08427\n",
      "=========================================================================================\n",
      "128 32 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16851 | test ppl 3.21720|test cor 0.19721\n",
      "=========================================================================================\n",
      "128 32 6 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.15872 | test ppl 3.18586|test cor 0.11606\n",
      "=========================================================================================\n",
      "128 32 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18977 | test ppl 3.28634|test cor 0.08217\n",
      "=========================================================================================\n",
      "128 32 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17225 | test ppl 3.22926|test cor 0.09352\n",
      "=========================================================================================\n",
      "128 32 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17034 | test ppl 3.22308|test cor 0.15432\n",
      "=========================================================================================\n",
      "128 32 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16562 | test ppl 3.20792|test cor 0.05721\n",
      "=========================================================================================\n",
      "128 32 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17635 | test ppl 3.24253|test cor -0.22365\n",
      "=========================================================================================\n",
      "128 32 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17523 | test ppl 3.23890|test cor -0.28112\n",
      "=========================================================================================\n",
      "128 32 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17012 | test ppl 3.22238|test cor 0.18680\n",
      "=========================================================================================\n",
      "128 32 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16525 | test ppl 3.20673|test cor 0.13295\n",
      "=========================================================================================\n",
      "128 32 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19094 | test ppl 3.29019|test cor 0.19064\n",
      "=========================================================================================\n",
      "128 32 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16560 | test ppl 3.20784|test cor 0.06863\n",
      "=========================================================================================\n",
      "128 32 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26384 | test ppl 3.53897|test cor 0.22304\n",
      "=========================================================================================\n",
      "128 32 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16172 | test ppl 3.19542|test cor 0.03529\n",
      "=========================================================================================\n",
      "128 32 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16638 | test ppl 3.21034|test cor 0.19516\n",
      "=========================================================================================\n",
      "128 32 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18078 | test ppl 3.25693|test cor -0.03173\n",
      "=========================================================================================\n",
      "128 32 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16434 | test ppl 3.20381|test cor 0.11018\n",
      "=========================================================================================\n",
      "128 32 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16753 | test ppl 3.21403|test cor -0.02986\n",
      "=========================================================================================\n",
      "128 32 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17155 | test ppl 3.22698|test cor 0.22063\n",
      "=========================================================================================\n",
      "128 32 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22779 | test ppl 3.41367|test cor 0.14778\n",
      "=========================================================================================\n",
      "128 32 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16688 | test ppl 3.21196|test cor 0.11935\n",
      "=========================================================================================\n",
      "128 32 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16649 | test ppl 3.21071|test cor -0.13262\n",
      "=========================================================================================\n",
      "128 32 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16731 | test ppl 3.21335|test cor 0.04111\n",
      "=========================================================================================\n",
      "128 32 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17183 | test ppl 3.22789|test cor 0.11587\n",
      "=========================================================================================\n",
      "128 32 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17790 | test ppl 3.24755|test cor 0.18746\n",
      "=========================================================================================\n",
      "128 32 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16236 | test ppl 3.19749|test cor 0.12894\n",
      "=========================================================================================\n",
      "128 32 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16997 | test ppl 3.22189|test cor 0.03706\n",
      "=========================================================================================\n",
      "128 32 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18447 | test ppl 3.26896|test cor 0.15081\n",
      "=========================================================================================\n",
      "128 64 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17416 | test ppl 3.23542|test cor 0.16644\n",
      "=========================================================================================\n",
      "128 64 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15923 | test ppl 3.18748|test cor 0.03492\n",
      "=========================================================================================\n",
      "128 64 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17058 | test ppl 3.22386|test cor 0.00363\n",
      "=========================================================================================\n",
      "128 64 2 2 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.18080 | test ppl 3.25699|test cor 0.02269\n",
      "=========================================================================================\n",
      "128 64 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18949 | test ppl 3.28542|test cor -0.00870\n",
      "=========================================================================================\n",
      "128 64 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16091 | test ppl 3.19285|test cor 0.05521\n",
      "=========================================================================================\n",
      "128 64 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16433 | test ppl 3.20378|test cor 0.06793\n",
      "=========================================================================================\n",
      "128 64 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24152 | test ppl 3.46088|test cor -0.02381\n",
      "=========================================================================================\n",
      "128 64 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18368 | test ppl 3.26637|test cor 0.07075\n",
      "=========================================================================================\n",
      "128 64 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16833 | test ppl 3.21661|test cor 0.13622\n",
      "=========================================================================================\n",
      "128 64 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15779 | test ppl 3.18289|test cor -0.01466\n",
      "=========================================================================================\n",
      "128 64 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16658 | test ppl 3.21098|test cor -0.02675\n",
      "=========================================================================================\n",
      "128 64 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20656 | test ppl 3.34198|test cor 0.02610\n",
      "=========================================================================================\n",
      "128 64 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16301 | test ppl 3.19955|test cor 0.14673\n",
      "=========================================================================================\n",
      "128 64 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18035 | test ppl 3.25552|test cor 0.06434\n",
      "=========================================================================================\n",
      "128 64 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16520 | test ppl 3.20656|test cor 0.08756\n",
      "=========================================================================================\n",
      "128 64 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16741 | test ppl 3.21365|test cor 0.16965\n",
      "=========================================================================================\n",
      "128 64 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16475 | test ppl 3.20511|test cor 0.14958\n",
      "=========================================================================================\n",
      "128 64 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16886 | test ppl 3.21832|test cor 0.05799\n",
      "=========================================================================================\n",
      "128 64 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18505 | test ppl 3.27084|test cor 0.03509\n",
      "=========================================================================================\n",
      "128 64 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18841 | test ppl 3.28187|test cor 0.04351\n",
      "=========================================================================================\n",
      "128 64 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16068 | test ppl 3.19211|test cor 0.16898\n",
      "=========================================================================================\n",
      "128 64 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15713 | test ppl 3.18079|test cor -0.04085\n",
      "=========================================================================================\n",
      "128 64 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22343 | test ppl 3.39883|test cor 0.06956\n",
      "=========================================================================================\n",
      "128 64 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21766 | test ppl 3.37927|test cor 0.05987\n",
      "=========================================================================================\n",
      "128 64 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16026 | test ppl 3.19075|test cor 0.06422\n",
      "=========================================================================================\n",
      "128 64 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16553 | test ppl 3.20763|test cor 0.20732\n",
      "=========================================================================================\n",
      "128 64 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17947 | test ppl 3.25266|test cor -0.09469\n",
      "=========================================================================================\n",
      "128 64 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17398 | test ppl 3.23484|test cor 0.14350\n",
      "=========================================================================================\n",
      "128 64 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16539 | test ppl 3.20718|test cor 0.19651\n",
      "=========================================================================================\n",
      "128 64 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16163 | test ppl 3.19514|test cor 0.08949\n",
      "=========================================================================================\n",
      "128 64 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16117 | test ppl 3.19367|test cor -0.14074\n",
      "=========================================================================================\n",
      "128 64 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18334 | test ppl 3.26526|test cor -0.09587\n",
      "=========================================================================================\n",
      "128 64 4 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17254 | test ppl 3.23020|test cor -0.04354\n",
      "=========================================================================================\n",
      "128 64 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17345 | test ppl 3.23313|test cor 0.08905\n",
      "=========================================================================================\n",
      "128 64 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16913 | test ppl 3.21918|test cor -0.10837\n",
      "=========================================================================================\n",
      "128 64 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21472 | test ppl 3.36936|test cor 0.09260\n",
      "=========================================================================================\n",
      "128 64 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17245 | test ppl 3.22991|test cor 0.20227\n",
      "=========================================================================================\n",
      "128 64 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16920 | test ppl 3.21942|test cor 0.18018\n",
      "=========================================================================================\n",
      "128 64 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28518 | test ppl 3.61533|test cor -0.03896\n",
      "=========================================================================================\n",
      "128 64 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19404 | test ppl 3.30039|test cor 0.15831\n",
      "=========================================================================================\n",
      "128 64 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16331 | test ppl 3.20051|test cor 0.08111\n",
      "=========================================================================================\n",
      "128 64 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17043 | test ppl 3.22338|test cor -0.00008\n",
      "=========================================================================================\n",
      "128 64 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19623 | test ppl 3.30761|test cor 0.22342\n",
      "=========================================================================================\n",
      "128 64 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18635 | test ppl 3.27509|test cor 0.09750\n",
      "=========================================================================================\n",
      "128 64 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17041 | test ppl 3.22332|test cor 0.14849\n",
      "=========================================================================================\n",
      "128 64 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17701 | test ppl 3.24466|test cor 0.00529\n",
      "=========================================================================================\n",
      "128 64 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.29807 | test ppl 3.66224|test cor 0.01720\n",
      "=========================================================================================\n",
      "128 64 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20869 | test ppl 3.34909|test cor 0.08996\n",
      "=========================================================================================\n",
      "128 64 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16155 | test ppl 3.19490|test cor -0.02631\n",
      "=========================================================================================\n",
      "128 64 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16185 | test ppl 3.19584|test cor 0.06471\n",
      "=========================================================================================\n",
      "128 64 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19063 | test ppl 3.28916|test cor 0.04315\n",
      "=========================================================================================\n",
      "128 64 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16144 | test ppl 3.19453|test cor 0.18367\n",
      "=========================================================================================\n",
      "128 64 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17215 | test ppl 3.22894|test cor 0.15923\n",
      "=========================================================================================\n",
      "128 64 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16562 | test ppl 3.20793|test cor 0.20257\n",
      "=========================================================================================\n",
      "128 64 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19122 | test ppl 3.29109|test cor 0.06434\n",
      "=========================================================================================\n",
      "128 64 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21109 | test ppl 3.35715|test cor 0.13979\n",
      "=========================================================================================\n",
      "128 64 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17023 | test ppl 3.22273|test cor -0.01979\n",
      "=========================================================================================\n",
      "128 64 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17744 | test ppl 3.24604|test cor 0.13802\n",
      "=========================================================================================\n",
      "128 64 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15834 | test ppl 3.18465|test cor 0.05251\n",
      "=========================================================================================\n",
      "128 64 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17312 | test ppl 3.23206|test cor 0.09522\n",
      "=========================================================================================\n",
      "128 64 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16855 | test ppl 3.21734|test cor 0.03958\n",
      "=========================================================================================\n",
      "128 64 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19303 | test ppl 3.29705|test cor 0.13666\n",
      "=========================================================================================\n",
      "128 64 6 4 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.28462 | test ppl 3.61328|test cor 0.16507\n",
      "=========================================================================================\n",
      "128 64 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19202 | test ppl 3.29373|test cor 0.10831\n",
      "=========================================================================================\n",
      "128 64 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15698 | test ppl 3.18032|test cor 0.18918\n",
      "=========================================================================================\n",
      "128 64 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16493 | test ppl 3.20570|test cor 0.15082\n",
      "=========================================================================================\n",
      "128 64 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17246 | test ppl 3.22992|test cor -0.20072\n",
      "=========================================================================================\n",
      "128 64 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18653 | test ppl 3.27570|test cor 0.20351\n",
      "=========================================================================================\n",
      "128 64 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16437 | test ppl 3.20392|test cor -0.05696\n",
      "=========================================================================================\n",
      "128 64 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16388 | test ppl 3.20232|test cor 0.11636\n",
      "=========================================================================================\n",
      "128 64 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19627 | test ppl 3.30774|test cor -0.00455\n",
      "=========================================================================================\n",
      "128 64 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16497 | test ppl 3.20584|test cor 0.25837\n",
      "=========================================================================================\n",
      "128 64 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17019 | test ppl 3.22260|test cor 0.04279\n",
      "=========================================================================================\n",
      "128 64 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17136 | test ppl 3.22638|test cor 0.22085\n",
      "=========================================================================================\n",
      "128 64 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16243 | test ppl 3.19769|test cor -0.07929\n",
      "=========================================================================================\n",
      "128 64 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21183 | test ppl 3.35962|test cor 0.19310\n",
      "=========================================================================================\n",
      "128 64 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16075 | test ppl 3.19233|test cor 0.10992\n",
      "=========================================================================================\n",
      "128 64 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19739 | test ppl 3.31147|test cor 0.20977\n",
      "=========================================================================================\n",
      "128 64 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.27530 | test ppl 3.57976|test cor -0.14275\n",
      "=========================================================================================\n",
      "128 64 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19097 | test ppl 3.29029|test cor -0.11253\n",
      "=========================================================================================\n",
      "128 64 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16776 | test ppl 3.21479|test cor 0.19355\n",
      "=========================================================================================\n",
      "128 64 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16326 | test ppl 3.20033|test cor 0.12274\n",
      "=========================================================================================\n",
      "128 64 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16004 | test ppl 3.19007|test cor -0.08925\n",
      "=========================================================================================\n",
      "128 64 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19591 | test ppl 3.30656|test cor 0.11783\n",
      "=========================================================================================\n",
      "128 64 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16214 | test ppl 3.19676|test cor 0.01586\n",
      "=========================================================================================\n",
      "128 64 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16286 | test ppl 3.19906|test cor -0.12798\n",
      "=========================================================================================\n",
      "128 64 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.27517 | test ppl 3.57930|test cor 0.08825\n",
      "=========================================================================================\n",
      "128 64 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18049 | test ppl 3.25597|test cor 0.23694\n",
      "=========================================================================================\n",
      "128 64 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16724 | test ppl 3.21312|test cor 0.19775\n",
      "=========================================================================================\n",
      "128 64 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16032 | test ppl 3.19094|test cor 0.12249\n",
      "=========================================================================================\n",
      "128 64 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18217 | test ppl 3.26144|test cor 0.10731\n",
      "=========================================================================================\n",
      "128 64 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17095 | test ppl 3.22504|test cor 0.19340\n",
      "=========================================================================================\n",
      "128 64 8 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16762 | test ppl 3.21434|test cor 0.08747\n",
      "=========================================================================================\n",
      "128 64 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16803 | test ppl 3.21564|test cor -0.16419\n",
      "=========================================================================================\n",
      "128 64 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26144 | test ppl 3.53051|test cor -0.02373\n",
      "=========================================================================================\n",
      "128 128 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17782 | test ppl 3.24730|test cor 0.05596\n",
      "=========================================================================================\n",
      "128 128 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16053 | test ppl 3.19162|test cor 0.06324\n",
      "=========================================================================================\n",
      "128 128 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15815 | test ppl 3.18403|test cor 0.05832\n",
      "=========================================================================================\n",
      "128 128 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17748 | test ppl 3.24618|test cor 0.15878\n",
      "=========================================================================================\n",
      "128 128 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18725 | test ppl 3.27806|test cor 0.02573\n",
      "=========================================================================================\n",
      "128 128 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16065 | test ppl 3.19199|test cor -0.00791\n",
      "=========================================================================================\n",
      "128 128 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16077 | test ppl 3.19240|test cor 0.00508\n",
      "=========================================================================================\n",
      "128 128 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20744 | test ppl 3.34492|test cor 0.09723\n",
      "=========================================================================================\n",
      "128 128 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17945 | test ppl 3.25259|test cor 0.06798\n",
      "=========================================================================================\n",
      "128 128 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16200 | test ppl 3.19633|test cor 0.15240\n",
      "=========================================================================================\n",
      "128 128 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17939 | test ppl 3.25237|test cor 0.01360\n",
      "=========================================================================================\n",
      "128 128 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17994 | test ppl 3.25418|test cor 0.07691\n",
      "=========================================================================================\n",
      "128 128 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18426 | test ppl 3.26825|test cor 0.00553\n",
      "=========================================================================================\n",
      "128 128 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16428 | test ppl 3.20363|test cor 0.05238\n",
      "=========================================================================================\n",
      "128 128 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16343 | test ppl 3.20090|test cor -0.07807\n",
      "=========================================================================================\n",
      "128 128 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25922 | test ppl 3.52268|test cor 0.00043\n",
      "=========================================================================================\n",
      "128 128 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18813 | test ppl 3.28093|test cor 0.08025\n",
      "=========================================================================================\n",
      "128 128 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16751 | test ppl 3.21398|test cor 0.09775\n",
      "=========================================================================================\n",
      "128 128 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16234 | test ppl 3.19740|test cor -0.00927\n",
      "=========================================================================================\n",
      "128 128 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18369 | test ppl 3.26640|test cor 0.13387\n",
      "=========================================================================================\n",
      "128 128 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21043 | test ppl 3.35494|test cor 0.00563\n",
      "=========================================================================================\n",
      "128 128 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17163 | test ppl 3.22724|test cor 0.04962\n",
      "=========================================================================================\n",
      "128 128 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16551 | test ppl 3.20757|test cor 0.01940\n",
      "=========================================================================================\n",
      "128 128 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17021 | test ppl 3.22268|test cor -0.07257\n",
      "=========================================================================================\n",
      "128 128 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20190 | test ppl 3.32642|test cor 0.13133\n",
      "=========================================================================================\n",
      "128 128 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15484 | test ppl 3.17352|test cor 0.12285\n",
      "=========================================================================================\n",
      "128 128 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15906 | test ppl 3.18695|test cor -0.00957\n",
      "=========================================================================================\n",
      "128 128 4 2 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.20494 | test ppl 3.33655|test cor -0.11924\n",
      "=========================================================================================\n",
      "128 128 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20680 | test ppl 3.34278|test cor 0.07478\n",
      "=========================================================================================\n",
      "128 128 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16707 | test ppl 3.21257|test cor 0.18746\n",
      "=========================================================================================\n",
      "128 128 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18154 | test ppl 3.25938|test cor -0.08845\n",
      "=========================================================================================\n",
      "128 128 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26679 | test ppl 3.54943|test cor 0.12755\n",
      "=========================================================================================\n",
      "128 128 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20579 | test ppl 3.33941|test cor 0.15432\n",
      "=========================================================================================\n",
      "128 128 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15906 | test ppl 3.18694|test cor -0.09066\n",
      "=========================================================================================\n",
      "128 128 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16273 | test ppl 3.19865|test cor -0.15215\n",
      "=========================================================================================\n",
      "128 128 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17922 | test ppl 3.25183|test cor -0.03477\n",
      "=========================================================================================\n",
      "128 128 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17383 | test ppl 3.23437|test cor 0.14434\n",
      "=========================================================================================\n",
      "128 128 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16261 | test ppl 3.19827|test cor -0.05422\n",
      "=========================================================================================\n",
      "128 128 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17353 | test ppl 3.23337|test cor 0.13918\n",
      "=========================================================================================\n",
      "128 128 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23860 | test ppl 3.45078|test cor -0.04578\n",
      "=========================================================================================\n",
      "128 128 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20798 | test ppl 3.34673|test cor 0.21323\n",
      "=========================================================================================\n",
      "128 128 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16103 | test ppl 3.19323|test cor 0.15879\n",
      "=========================================================================================\n",
      "128 128 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17968 | test ppl 3.25333|test cor 0.11402\n",
      "=========================================================================================\n",
      "128 128 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17412 | test ppl 3.23529|test cor -0.00832\n",
      "=========================================================================================\n",
      "128 128 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17899 | test ppl 3.25108|test cor 0.10537\n",
      "=========================================================================================\n",
      "128 128 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20356 | test ppl 3.33194|test cor 0.20136\n",
      "=========================================================================================\n",
      "128 128 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16796 | test ppl 3.21543|test cor 0.06904\n",
      "=========================================================================================\n",
      "128 128 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.27290 | test ppl 3.57121|test cor -0.11447\n",
      "=========================================================================================\n",
      "128 128 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17509 | test ppl 3.23842|test cor 0.03686\n",
      "=========================================================================================\n",
      "128 128 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16432 | test ppl 3.20373|test cor 0.22971\n",
      "=========================================================================================\n",
      "128 128 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16966 | test ppl 3.22088|test cor -0.23205\n",
      "=========================================================================================\n",
      "128 128 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17357 | test ppl 3.23353|test cor 0.12804\n",
      "=========================================================================================\n",
      "128 128 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18694 | test ppl 3.27702|test cor 0.10134\n",
      "=========================================================================================\n",
      "128 128 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15924 | test ppl 3.18750|test cor 0.14029\n",
      "=========================================================================================\n",
      "128 128 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16794 | test ppl 3.21538|test cor 0.14468\n",
      "=========================================================================================\n",
      "128 128 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24089 | test ppl 3.45867|test cor -0.12032\n",
      "=========================================================================================\n",
      "128 128 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22247 | test ppl 3.39556|test cor 0.11689\n",
      "=========================================================================================\n",
      "128 128 6 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16649 | test ppl 3.21070|test cor 0.07006\n",
      "=========================================================================================\n",
      "128 128 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16738 | test ppl 3.21358|test cor 0.15573\n",
      "=========================================================================================\n",
      "128 128 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17680 | test ppl 3.24399|test cor -0.14288\n",
      "=========================================================================================\n",
      "128 128 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18173 | test ppl 3.25999|test cor 0.11950\n",
      "=========================================================================================\n",
      "128 128 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16932 | test ppl 3.21980|test cor 0.16327\n",
      "=========================================================================================\n",
      "128 128 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17219 | test ppl 3.22907|test cor -0.09690\n",
      "=========================================================================================\n",
      "128 128 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16696 | test ppl 3.21220|test cor 0.17218\n",
      "=========================================================================================\n",
      "128 128 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18639 | test ppl 3.27525|test cor 0.10143\n",
      "=========================================================================================\n",
      "128 128 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17066 | test ppl 3.22411|test cor 0.15995\n",
      "=========================================================================================\n",
      "128 128 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16334 | test ppl 3.20060|test cor 0.06454\n",
      "=========================================================================================\n",
      "128 128 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23489 | test ppl 3.43800|test cor -0.10258\n",
      "=========================================================================================\n",
      "128 128 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19277 | test ppl 3.29618|test cor 0.12579\n",
      "=========================================================================================\n",
      "128 128 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16277 | test ppl 3.19879|test cor 0.22739\n",
      "=========================================================================================\n",
      "128 128 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16372 | test ppl 3.20184|test cor 0.06471\n",
      "=========================================================================================\n",
      "128 128 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16997 | test ppl 3.22189|test cor 0.09168\n",
      "=========================================================================================\n",
      "128 128 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17517 | test ppl 3.23869|test cor 0.19416\n",
      "=========================================================================================\n",
      "128 128 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16663 | test ppl 3.21116|test cor -0.01285\n",
      "=========================================================================================\n",
      "128 128 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16233 | test ppl 3.19739|test cor -0.06663\n",
      "=========================================================================================\n",
      "128 128 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15973 | test ppl 3.18907|test cor 0.03919\n",
      "=========================================================================================\n",
      "128 128 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16322 | test ppl 3.20022|test cor 0.19006\n",
      "=========================================================================================\n",
      "128 128 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16586 | test ppl 3.20870|test cor 0.03973\n",
      "=========================================================================================\n",
      "128 128 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16259 | test ppl 3.19822|test cor -0.00054\n",
      "=========================================================================================\n",
      "128 128 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16372 | test ppl 3.20182|test cor 0.06331\n",
      "=========================================================================================\n",
      "128 128 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17153 | test ppl 3.22694|test cor 0.09505\n",
      "=========================================================================================\n",
      "128 128 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16819 | test ppl 3.21617|test cor -0.09711\n",
      "=========================================================================================\n",
      "128 128 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17651 | test ppl 3.24304|test cor 0.08379\n",
      "=========================================================================================\n",
      "128 128 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18787 | test ppl 3.28008|test cor 0.12310\n",
      "=========================================================================================\n",
      "128 128 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18909 | test ppl 3.28409|test cor 0.21641\n",
      "=========================================================================================\n",
      "128 128 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16565 | test ppl 3.20800|test cor -0.11389\n",
      "=========================================================================================\n",
      "128 128 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16484 | test ppl 3.20542|test cor 0.06673\n",
      "=========================================================================================\n",
      "128 128 8 4 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.20535 | test ppl 3.33793|test cor -0.14850\n",
      "=========================================================================================\n",
      "128 128 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23161 | test ppl 3.42676|test cor 0.21391\n",
      "=========================================================================================\n",
      "128 128 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16664 | test ppl 3.21118|test cor 0.19052\n",
      "=========================================================================================\n",
      "128 128 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15728 | test ppl 3.18127|test cor -0.20249\n",
      "=========================================================================================\n",
      "128 128 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21455 | test ppl 3.36876|test cor 0.11735\n",
      "=========================================================================================\n",
      "128 128 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19059 | test ppl 3.28903|test cor 0.18917\n",
      "=========================================================================================\n",
      "128 128 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16012 | test ppl 3.19031|test cor 0.11569\n",
      "=========================================================================================\n",
      "128 128 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16873 | test ppl 3.21791|test cor 0.07011\n",
      "=========================================================================================\n",
      "128 128 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18404 | test ppl 3.26754|test cor -0.01359\n",
      "=========================================================================================\n",
      "128 256 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18526 | test ppl 3.27155|test cor 0.04972\n",
      "=========================================================================================\n",
      "128 256 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16046 | test ppl 3.19139|test cor 0.15620\n",
      "=========================================================================================\n",
      "128 256 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15894 | test ppl 3.18657|test cor -0.01550\n",
      "=========================================================================================\n",
      "128 256 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17394 | test ppl 3.23473|test cor 0.13808\n",
      "=========================================================================================\n",
      "128 256 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22400 | test ppl 3.40075|test cor 0.02217\n",
      "=========================================================================================\n",
      "128 256 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16599 | test ppl 3.20910|test cor 0.05390\n",
      "=========================================================================================\n",
      "128 256 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17255 | test ppl 3.23022|test cor -0.01269\n",
      "=========================================================================================\n",
      "128 256 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19845 | test ppl 3.31497|test cor 0.11001\n",
      "=========================================================================================\n",
      "128 256 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18180 | test ppl 3.26025|test cor 0.05534\n",
      "=========================================================================================\n",
      "128 256 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15669 | test ppl 3.17940|test cor 0.14982\n",
      "=========================================================================================\n",
      "128 256 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15769 | test ppl 3.18258|test cor 0.05711\n",
      "=========================================================================================\n",
      "128 256 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16460 | test ppl 3.20465|test cor 0.02454\n",
      "=========================================================================================\n",
      "128 256 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20936 | test ppl 3.35133|test cor 0.00427\n",
      "=========================================================================================\n",
      "128 256 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16878 | test ppl 3.21808|test cor -0.04895\n",
      "=========================================================================================\n",
      "128 256 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16302 | test ppl 3.19958|test cor 0.09639\n",
      "=========================================================================================\n",
      "128 256 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20243 | test ppl 3.32820|test cor -0.01994\n",
      "=========================================================================================\n",
      "128 256 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18444 | test ppl 3.26885|test cor 0.08677\n",
      "=========================================================================================\n",
      "128 256 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16291 | test ppl 3.19922|test cor 0.13332\n",
      "=========================================================================================\n",
      "128 256 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15890 | test ppl 3.18641|test cor 0.04129\n",
      "=========================================================================================\n",
      "128 256 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19345 | test ppl 3.29846|test cor 0.11651\n",
      "=========================================================================================\n",
      "128 256 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21261 | test ppl 3.36226|test cor 0.00423\n",
      "=========================================================================================\n",
      "128 256 2 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16261 | test ppl 3.19826|test cor -0.04771\n",
      "=========================================================================================\n",
      "128 256 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18225 | test ppl 3.26169|test cor 0.13795\n",
      "=========================================================================================\n",
      "128 256 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17305 | test ppl 3.23183|test cor 0.05019\n",
      "=========================================================================================\n",
      "128 256 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18890 | test ppl 3.28347|test cor 0.12821\n",
      "=========================================================================================\n",
      "128 256 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16139 | test ppl 3.19436|test cor 0.07610\n",
      "=========================================================================================\n",
      "128 256 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17029 | test ppl 3.22293|test cor 0.05654\n",
      "=========================================================================================\n",
      "128 256 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17367 | test ppl 3.23384|test cor -0.12203\n",
      "=========================================================================================\n",
      "128 256 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17843 | test ppl 3.24927|test cor 0.08476\n",
      "=========================================================================================\n",
      "128 256 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16137 | test ppl 3.19431|test cor 0.10737\n",
      "=========================================================================================\n",
      "128 256 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17708 | test ppl 3.24489|test cor -0.01579\n",
      "=========================================================================================\n",
      "128 256 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23323 | test ppl 3.43231|test cor 0.08053\n",
      "=========================================================================================\n",
      "128 256 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18641 | test ppl 3.27531|test cor 0.16198\n",
      "=========================================================================================\n",
      "128 256 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16114 | test ppl 3.19356|test cor 0.13322\n",
      "=========================================================================================\n",
      "128 256 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16803 | test ppl 3.21565|test cor 0.22806\n",
      "=========================================================================================\n",
      "128 256 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17090 | test ppl 3.22488|test cor 0.05667\n",
      "=========================================================================================\n",
      "128 256 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20572 | test ppl 3.33916|test cor 0.12119\n",
      "=========================================================================================\n",
      "128 256 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16105 | test ppl 3.19329|test cor 0.13087\n",
      "=========================================================================================\n",
      "128 256 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16122 | test ppl 3.19384|test cor 0.12578\n",
      "=========================================================================================\n",
      "128 256 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17151 | test ppl 3.22685|test cor 0.12905\n",
      "=========================================================================================\n",
      "128 256 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17758 | test ppl 3.24652|test cor 0.20884\n",
      "=========================================================================================\n",
      "128 256 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16298 | test ppl 3.19944|test cor -0.00219\n",
      "=========================================================================================\n",
      "128 256 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16742 | test ppl 3.21369|test cor 0.00997\n",
      "=========================================================================================\n",
      "128 256 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17940 | test ppl 3.25244|test cor -0.11373\n",
      "=========================================================================================\n",
      "128 256 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19363 | test ppl 3.29903|test cor 0.11310\n",
      "=========================================================================================\n",
      "128 256 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16075 | test ppl 3.19232|test cor 0.07862\n",
      "=========================================================================================\n",
      "128 256 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15400 | test ppl 3.17086|test cor 0.08614\n",
      "=========================================================================================\n",
      "128 256 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18367 | test ppl 3.26635|test cor 0.10025\n",
      "=========================================================================================\n",
      "128 256 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19100 | test ppl 3.29036|test cor 0.00052\n",
      "=========================================================================================\n",
      "128 256 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16161 | test ppl 3.19507|test cor 0.21941\n",
      "=========================================================================================\n",
      "128 256 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16136 | test ppl 3.19428|test cor 0.00533\n",
      "=========================================================================================\n",
      "128 256 6 2 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.18342 | test ppl 3.26553|test cor 0.05041\n",
      "=========================================================================================\n",
      "128 256 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20717 | test ppl 3.34401|test cor 0.14919\n",
      "=========================================================================================\n",
      "128 256 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16542 | test ppl 3.20727|test cor 0.14383\n",
      "=========================================================================================\n",
      "128 256 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17853 | test ppl 3.24958|test cor 0.21313\n",
      "=========================================================================================\n",
      "128 256 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17967 | test ppl 3.25329|test cor -0.12213\n",
      "=========================================================================================\n",
      "128 256 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19664 | test ppl 3.30899|test cor 0.14995\n",
      "=========================================================================================\n",
      "128 256 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16554 | test ppl 3.20766|test cor 0.05847\n",
      "=========================================================================================\n",
      "128 256 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17826 | test ppl 3.24873|test cor 0.18431\n",
      "=========================================================================================\n",
      "128 256 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18290 | test ppl 3.26384|test cor 0.20028\n",
      "=========================================================================================\n",
      "128 256 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16147 | test ppl 3.19462|test cor 0.16653\n",
      "=========================================================================================\n",
      "128 256 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16251 | test ppl 3.19796|test cor 0.27070\n",
      "=========================================================================================\n",
      "128 256 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16319 | test ppl 3.20013|test cor 0.16069\n",
      "=========================================================================================\n",
      "128 256 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21779 | test ppl 3.37971|test cor -0.00058\n",
      "=========================================================================================\n",
      "128 256 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17712 | test ppl 3.24500|test cor 0.04718\n",
      "=========================================================================================\n",
      "128 256 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16411 | test ppl 3.20307|test cor 0.07027\n",
      "=========================================================================================\n",
      "128 256 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16642 | test ppl 3.21049|test cor 0.14590\n",
      "=========================================================================================\n",
      "128 256 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16029 | test ppl 3.19085|test cor -0.02779\n",
      "=========================================================================================\n",
      "128 256 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16033 | test ppl 3.19097|test cor 0.15726\n",
      "=========================================================================================\n",
      "128 256 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16379 | test ppl 3.20204|test cor -0.16998\n",
      "=========================================================================================\n",
      "128 256 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18151 | test ppl 3.25929|test cor -0.09077\n",
      "=========================================================================================\n",
      "128 256 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22028 | test ppl 3.38813|test cor 0.11018\n",
      "=========================================================================================\n",
      "128 256 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19282 | test ppl 3.29637|test cor 0.12354\n",
      "=========================================================================================\n",
      "128 256 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16536 | test ppl 3.20709|test cor 0.17641\n",
      "=========================================================================================\n",
      "128 256 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15889 | test ppl 3.18639|test cor -0.00529\n",
      "=========================================================================================\n",
      "128 256 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17724 | test ppl 3.24540|test cor -0.08811\n",
      "=========================================================================================\n",
      "128 256 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16268 | test ppl 3.19851|test cor 0.16673\n",
      "=========================================================================================\n",
      "128 256 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16387 | test ppl 3.20230|test cor 0.13283\n",
      "=========================================================================================\n",
      "128 256 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16766 | test ppl 3.21446|test cor -0.05665\n",
      "=========================================================================================\n",
      "128 256 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23205 | test ppl 3.42825|test cor 0.06250\n",
      "=========================================================================================\n",
      "128 256 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18991 | test ppl 3.28678|test cor 0.22477\n",
      "=========================================================================================\n",
      "128 256 8 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16362 | test ppl 3.20151|test cor 0.08360\n",
      "=========================================================================================\n",
      "128 256 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16069 | test ppl 3.19212|test cor 0.04846\n",
      "=========================================================================================\n",
      "128 256 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16187 | test ppl 3.19589|test cor -0.11481\n",
      "=========================================================================================\n",
      "128 256 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18855 | test ppl 3.28233|test cor 0.18264\n",
      "=========================================================================================\n",
      "128 256 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16779 | test ppl 3.21488|test cor 0.15308\n",
      "=========================================================================================\n",
      "128 256 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17308 | test ppl 3.23194|test cor 0.17748\n",
      "=========================================================================================\n",
      "128 256 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17914 | test ppl 3.25159|test cor -0.24857\n",
      "=========================================================================================\n",
      "128 256 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18402 | test ppl 3.26749|test cor 0.14200\n",
      "=========================================================================================\n",
      "128 256 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17101 | test ppl 3.22524|test cor -0.06628\n",
      "=========================================================================================\n",
      "128 256 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15685 | test ppl 3.17989|test cor -0.03194\n",
      "=========================================================================================\n",
      "128 256 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16926 | test ppl 3.21962|test cor -0.26173\n",
      "=========================================================================================\n",
      "128 256 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19178 | test ppl 3.29294|test cor 0.13487\n",
      "=========================================================================================\n",
      "128 256 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16066 | test ppl 3.19205|test cor 0.03142\n",
      "=========================================================================================\n",
      "128 256 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15795 | test ppl 3.18342|test cor 0.01604\n",
      "=========================================================================================\n",
      "128 256 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18087 | test ppl 3.25721|test cor 0.15664\n",
      "=========================================================================================\n",
      "256 8 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17151 | test ppl 3.22686|test cor 0.05736\n",
      "=========================================================================================\n",
      "256 8 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15764 | test ppl 3.18242|test cor 0.11545\n",
      "=========================================================================================\n",
      "256 8 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16337 | test ppl 3.20072|test cor 0.01257\n",
      "=========================================================================================\n",
      "256 8 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17462 | test ppl 3.23692|test cor -0.05595\n",
      "=========================================================================================\n",
      "256 8 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17737 | test ppl 3.24583|test cor 0.15051\n",
      "=========================================================================================\n",
      "256 8 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16152 | test ppl 3.19478|test cor 0.03560\n",
      "=========================================================================================\n",
      "256 8 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16831 | test ppl 3.21654|test cor -0.08267\n",
      "=========================================================================================\n",
      "256 8 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18208 | test ppl 3.26116|test cor 0.08625\n",
      "=========================================================================================\n",
      "256 8 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28278 | test ppl 3.60664|test cor 0.00202\n",
      "=========================================================================================\n",
      "256 8 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16048 | test ppl 3.19147|test cor 0.01756\n",
      "=========================================================================================\n",
      "256 8 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16302 | test ppl 3.19958|test cor 0.12750\n",
      "=========================================================================================\n",
      "256 8 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18649 | test ppl 3.27558|test cor -0.07152\n",
      "=========================================================================================\n",
      "256 8 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16917 | test ppl 3.21933|test cor 0.14317\n",
      "=========================================================================================\n",
      "256 8 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16669 | test ppl 3.21133|test cor 0.08738\n",
      "=========================================================================================\n",
      "256 8 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17685 | test ppl 3.24413|test cor 0.17906\n",
      "=========================================================================================\n",
      "256 8 2 4 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.20060 | test ppl 3.32211|test cor 0.11053\n",
      "=========================================================================================\n",
      "256 8 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23334 | test ppl 3.43266|test cor 0.05468\n",
      "=========================================================================================\n",
      "256 8 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16320 | test ppl 3.20016|test cor 0.10427\n",
      "=========================================================================================\n",
      "256 8 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17449 | test ppl 3.23651|test cor 0.06561\n",
      "=========================================================================================\n",
      "256 8 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17797 | test ppl 3.24777|test cor 0.04415\n",
      "=========================================================================================\n",
      "256 8 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20967 | test ppl 3.35238|test cor 0.15607\n",
      "=========================================================================================\n",
      "256 8 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17012 | test ppl 3.22239|test cor 0.05171\n",
      "=========================================================================================\n",
      "256 8 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17983 | test ppl 3.25381|test cor 0.07555\n",
      "=========================================================================================\n",
      "256 8 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16962 | test ppl 3.22078|test cor 0.01943\n",
      "=========================================================================================\n",
      "256 8 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.36806 | test ppl 3.92773|test cor 0.10702\n",
      "=========================================================================================\n",
      "256 8 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17014 | test ppl 3.22243|test cor 0.12201\n",
      "=========================================================================================\n",
      "256 8 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16394 | test ppl 3.20253|test cor 0.04468\n",
      "=========================================================================================\n",
      "256 8 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16969 | test ppl 3.22099|test cor 0.21070\n",
      "=========================================================================================\n",
      "256 8 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17139 | test ppl 3.22646|test cor 0.14837\n",
      "=========================================================================================\n",
      "256 8 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17379 | test ppl 3.23423|test cor 0.12629\n",
      "=========================================================================================\n",
      "256 8 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18632 | test ppl 3.27501|test cor 0.23559\n",
      "=========================================================================================\n",
      "256 8 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21088 | test ppl 3.35645|test cor 0.11831\n",
      "=========================================================================================\n",
      "256 8 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19186 | test ppl 3.29319|test cor 0.16614\n",
      "=========================================================================================\n",
      "256 8 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16343 | test ppl 3.20091|test cor 0.06337\n",
      "=========================================================================================\n",
      "256 8 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15986 | test ppl 3.18950|test cor 0.07359\n",
      "=========================================================================================\n",
      "256 8 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18151 | test ppl 3.25929|test cor 0.00503\n",
      "=========================================================================================\n",
      "256 8 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16034 | test ppl 3.19101|test cor 0.09690\n",
      "=========================================================================================\n",
      "256 8 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18002 | test ppl 3.25444|test cor 0.19567\n",
      "=========================================================================================\n",
      "256 8 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16789 | test ppl 3.21522|test cor 0.11814\n",
      "=========================================================================================\n",
      "256 8 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19502 | test ppl 3.30363|test cor 0.09788\n",
      "=========================================================================================\n",
      "256 8 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19670 | test ppl 3.30917|test cor 0.07574\n",
      "=========================================================================================\n",
      "256 8 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17138 | test ppl 3.22645|test cor -0.00718\n",
      "=========================================================================================\n",
      "256 8 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16332 | test ppl 3.20054|test cor 0.26946\n",
      "=========================================================================================\n",
      "256 8 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18499 | test ppl 3.27067|test cor 0.10147\n",
      "=========================================================================================\n",
      "256 8 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17757 | test ppl 3.24649|test cor 0.21641\n",
      "=========================================================================================\n",
      "256 8 4 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.15776 | test ppl 3.18280|test cor -0.04972\n",
      "=========================================================================================\n",
      "256 8 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15914 | test ppl 3.18718|test cor -0.09681\n",
      "=========================================================================================\n",
      "256 8 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28436 | test ppl 3.61237|test cor 0.11172\n",
      "=========================================================================================\n",
      "256 8 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18361 | test ppl 3.26614|test cor 0.20131\n",
      "=========================================================================================\n",
      "256 8 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16087 | test ppl 3.19272|test cor -0.05571\n",
      "=========================================================================================\n",
      "256 8 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16484 | test ppl 3.20542|test cor -0.01377\n",
      "=========================================================================================\n",
      "256 8 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19011 | test ppl 3.28744|test cor -0.18309\n",
      "=========================================================================================\n",
      "256 8 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15762 | test ppl 3.18234|test cor 0.20146\n",
      "=========================================================================================\n",
      "256 8 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17048 | test ppl 3.22354|test cor 0.15866\n",
      "=========================================================================================\n",
      "256 8 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16479 | test ppl 3.20526|test cor 0.04400\n",
      "=========================================================================================\n",
      "256 8 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18576 | test ppl 3.27316|test cor -0.11797\n",
      "=========================================================================================\n",
      "256 8 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17354 | test ppl 3.23342|test cor 0.16067\n",
      "=========================================================================================\n",
      "256 8 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16223 | test ppl 3.19706|test cor 0.03149\n",
      "=========================================================================================\n",
      "256 8 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16877 | test ppl 3.21804|test cor 0.17652\n",
      "=========================================================================================\n",
      "256 8 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16306 | test ppl 3.19971|test cor 0.11131\n",
      "=========================================================================================\n",
      "256 8 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17395 | test ppl 3.23475|test cor 0.15007\n",
      "=========================================================================================\n",
      "256 8 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16040 | test ppl 3.19121|test cor 0.01485\n",
      "=========================================================================================\n",
      "256 8 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19131 | test ppl 3.29140|test cor 0.00876\n",
      "=========================================================================================\n",
      "256 8 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16686 | test ppl 3.21190|test cor 0.19924\n",
      "=========================================================================================\n",
      "256 8 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20035 | test ppl 3.32126|test cor 0.22982\n",
      "=========================================================================================\n",
      "256 8 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16240 | test ppl 3.19760|test cor 0.18149\n",
      "=========================================================================================\n",
      "256 8 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16266 | test ppl 3.19843|test cor 0.26459\n",
      "=========================================================================================\n",
      "256 8 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17028 | test ppl 3.22289|test cor -0.18251\n",
      "=========================================================================================\n",
      "256 8 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17011 | test ppl 3.22233|test cor 0.20393\n",
      "=========================================================================================\n",
      "256 8 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16639 | test ppl 3.21037|test cor 0.12376\n",
      "=========================================================================================\n",
      "256 8 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16176 | test ppl 3.19554|test cor -0.04468\n",
      "=========================================================================================\n",
      "256 8 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16905 | test ppl 3.21892|test cor -0.08783\n",
      "=========================================================================================\n",
      "256 8 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17881 | test ppl 3.25050|test cor 0.29779\n",
      "=========================================================================================\n",
      "256 8 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16596 | test ppl 3.20900|test cor -0.03461\n",
      "=========================================================================================\n",
      "256 8 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16942 | test ppl 3.22011|test cor 0.01639\n",
      "=========================================================================================\n",
      "256 8 8 2 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17475 | test ppl 3.23734|test cor 0.07221\n",
      "=========================================================================================\n",
      "256 8 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20480 | test ppl 3.33608|test cor 0.18147\n",
      "=========================================================================================\n",
      "256 8 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16157 | test ppl 3.19494|test cor 0.19066\n",
      "=========================================================================================\n",
      "256 8 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16051 | test ppl 3.19155|test cor 0.07945\n",
      "=========================================================================================\n",
      "256 8 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23026 | test ppl 3.42212|test cor 0.18819\n",
      "=========================================================================================\n",
      "256 8 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18896 | test ppl 3.28366|test cor 0.21760\n",
      "=========================================================================================\n",
      "256 8 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16664 | test ppl 3.21119|test cor -0.03733\n",
      "=========================================================================================\n",
      "256 8 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17101 | test ppl 3.22526|test cor 0.19196\n",
      "=========================================================================================\n",
      "256 8 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17675 | test ppl 3.24382|test cor -0.07038\n",
      "=========================================================================================\n",
      "256 8 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20924 | test ppl 3.35093|test cor 0.15118\n",
      "=========================================================================================\n",
      "256 8 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16588 | test ppl 3.20874|test cor 0.14948\n",
      "=========================================================================================\n",
      "256 8 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16000 | test ppl 3.18993|test cor 0.11783\n",
      "=========================================================================================\n",
      "256 8 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18202 | test ppl 3.26096|test cor 0.12167\n",
      "=========================================================================================\n",
      "256 8 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23550 | test ppl 3.44010|test cor 0.28731\n",
      "=========================================================================================\n",
      "256 8 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16307 | test ppl 3.19976|test cor 0.20643\n",
      "=========================================================================================\n",
      "256 8 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17032 | test ppl 3.22303|test cor -0.07316\n",
      "=========================================================================================\n",
      "256 8 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19328 | test ppl 3.29788|test cor -0.09884\n",
      "=========================================================================================\n",
      "256 8 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18430 | test ppl 3.26841|test cor 0.20267\n",
      "=========================================================================================\n",
      "256 8 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17266 | test ppl 3.23059|test cor -0.17597\n",
      "=========================================================================================\n",
      "256 8 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17086 | test ppl 3.22477|test cor 0.17645\n",
      "=========================================================================================\n",
      "256 8 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20245 | test ppl 3.32825|test cor 0.11423\n",
      "=========================================================================================\n",
      "256 32 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25913 | test ppl 3.52237|test cor -0.00301\n",
      "=========================================================================================\n",
      "256 32 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16326 | test ppl 3.20034|test cor 0.00957\n",
      "=========================================================================================\n",
      "256 32 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17120 | test ppl 3.22585|test cor -0.04114\n",
      "=========================================================================================\n",
      "256 32 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17661 | test ppl 3.24337|test cor -0.01513\n",
      "=========================================================================================\n",
      "256 32 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23749 | test ppl 3.44694|test cor 0.00900\n",
      "=========================================================================================\n",
      "256 32 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15760 | test ppl 3.18229|test cor 0.06397\n",
      "=========================================================================================\n",
      "256 32 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16081 | test ppl 3.19251|test cor 0.01939\n",
      "=========================================================================================\n",
      "256 32 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21604 | test ppl 3.37381|test cor -0.12447\n",
      "=========================================================================================\n",
      "256 32 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22368 | test ppl 3.39968|test cor 0.02762\n",
      "=========================================================================================\n",
      "256 32 2 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.15780 | test ppl 3.18293|test cor 0.05031\n",
      "=========================================================================================\n",
      "256 32 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15995 | test ppl 3.18978|test cor 0.05395\n",
      "=========================================================================================\n",
      "256 32 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16993 | test ppl 3.22178|test cor -0.07890\n",
      "=========================================================================================\n",
      "256 32 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25186 | test ppl 3.49683|test cor 0.01511\n",
      "=========================================================================================\n",
      "256 32 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16038 | test ppl 3.19115|test cor 0.08089\n",
      "=========================================================================================\n",
      "256 32 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16547 | test ppl 3.20744|test cor 0.11452\n",
      "=========================================================================================\n",
      "256 32 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17654 | test ppl 3.24312|test cor -0.05591\n",
      "=========================================================================================\n",
      "256 32 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21412 | test ppl 3.36733|test cor 0.03341\n",
      "=========================================================================================\n",
      "256 32 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16181 | test ppl 3.19570|test cor 0.11096\n",
      "=========================================================================================\n",
      "256 32 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15894 | test ppl 3.18655|test cor 0.09495\n",
      "=========================================================================================\n",
      "256 32 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17252 | test ppl 3.23011|test cor -0.03076\n",
      "=========================================================================================\n",
      "256 32 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23499 | test ppl 3.43834|test cor 0.08533\n",
      "=========================================================================================\n",
      "256 32 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15992 | test ppl 3.18969|test cor -0.01843\n",
      "=========================================================================================\n",
      "256 32 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17581 | test ppl 3.24076|test cor 0.03070\n",
      "=========================================================================================\n",
      "256 32 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17406 | test ppl 3.23509|test cor 0.02982\n",
      "=========================================================================================\n",
      "256 32 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25040 | test ppl 3.49176|test cor 0.12622\n",
      "=========================================================================================\n",
      "256 32 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16470 | test ppl 3.20497|test cor 0.13527\n",
      "=========================================================================================\n",
      "256 32 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16870 | test ppl 3.21779|test cor -0.02504\n",
      "=========================================================================================\n",
      "256 32 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18033 | test ppl 3.25544|test cor -0.10594\n",
      "=========================================================================================\n",
      "256 32 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18905 | test ppl 3.28396|test cor 0.14807\n",
      "=========================================================================================\n",
      "256 32 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16327 | test ppl 3.20037|test cor -0.00036\n",
      "=========================================================================================\n",
      "256 32 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16900 | test ppl 3.21877|test cor 0.18664\n",
      "=========================================================================================\n",
      "256 32 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26492 | test ppl 3.54282|test cor 0.00322\n",
      "=========================================================================================\n",
      "256 32 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25491 | test ppl 3.50751|test cor 0.16427\n",
      "=========================================================================================\n",
      "256 32 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16490 | test ppl 3.20560|test cor 0.14657\n",
      "=========================================================================================\n",
      "256 32 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16699 | test ppl 3.21232|test cor 0.09220\n",
      "=========================================================================================\n",
      "256 32 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19282 | test ppl 3.29636|test cor -0.00871\n",
      "=========================================================================================\n",
      "256 32 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28802 | test ppl 3.62561|test cor 0.17696\n",
      "=========================================================================================\n",
      "256 32 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16077 | test ppl 3.19240|test cor 0.00275\n",
      "=========================================================================================\n",
      "256 32 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16385 | test ppl 3.20223|test cor 0.08700\n",
      "=========================================================================================\n",
      "256 32 4 4 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.25837 | test ppl 3.51967|test cor 0.16845\n",
      "=========================================================================================\n",
      "256 32 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26723 | test ppl 3.55102|test cor 0.15630\n",
      "=========================================================================================\n",
      "256 32 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16303 | test ppl 3.19960|test cor 0.06941\n",
      "=========================================================================================\n",
      "256 32 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16805 | test ppl 3.21573|test cor -0.01302\n",
      "=========================================================================================\n",
      "256 32 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16724 | test ppl 3.21312|test cor 0.13084\n",
      "=========================================================================================\n",
      "256 32 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26427 | test ppl 3.54051|test cor 0.19252\n",
      "=========================================================================================\n",
      "256 32 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16258 | test ppl 3.19817|test cor 0.02801\n",
      "=========================================================================================\n",
      "256 32 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18436 | test ppl 3.26861|test cor 0.16604\n",
      "=========================================================================================\n",
      "256 32 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21512 | test ppl 3.37071|test cor -0.18279\n",
      "=========================================================================================\n",
      "256 32 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26228 | test ppl 3.53346|test cor 0.07710\n",
      "=========================================================================================\n",
      "256 32 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17413 | test ppl 3.23532|test cor 0.02584\n",
      "=========================================================================================\n",
      "256 32 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16483 | test ppl 3.20538|test cor -0.02735\n",
      "=========================================================================================\n",
      "256 32 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16112 | test ppl 3.19352|test cor 0.16739\n",
      "=========================================================================================\n",
      "256 32 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21057 | test ppl 3.35539|test cor 0.15554\n",
      "=========================================================================================\n",
      "256 32 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17406 | test ppl 3.23512|test cor 0.18409\n",
      "=========================================================================================\n",
      "256 32 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16261 | test ppl 3.19827|test cor 0.12281\n",
      "=========================================================================================\n",
      "256 32 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17520 | test ppl 3.23880|test cor 0.14191\n",
      "=========================================================================================\n",
      "256 32 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17709 | test ppl 3.24493|test cor 0.18385\n",
      "=========================================================================================\n",
      "256 32 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16570 | test ppl 3.20816|test cor 0.22696\n",
      "=========================================================================================\n",
      "256 32 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16078 | test ppl 3.19243|test cor 0.18142\n",
      "=========================================================================================\n",
      "256 32 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16709 | test ppl 3.21262|test cor 0.18064\n",
      "=========================================================================================\n",
      "256 32 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19100 | test ppl 3.29039|test cor 0.17778\n",
      "=========================================================================================\n",
      "256 32 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16050 | test ppl 3.19152|test cor 0.04369\n",
      "=========================================================================================\n",
      "256 32 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16962 | test ppl 3.22077|test cor 0.21880\n",
      "=========================================================================================\n",
      "256 32 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17933 | test ppl 3.25219|test cor -0.06566\n",
      "=========================================================================================\n",
      "256 32 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24130 | test ppl 3.46012|test cor 0.01081\n",
      "=========================================================================================\n",
      "256 32 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16585 | test ppl 3.20865|test cor 0.06722\n",
      "=========================================================================================\n",
      "256 32 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16517 | test ppl 3.20647|test cor 0.05599\n",
      "=========================================================================================\n",
      "256 32 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16459 | test ppl 3.20461|test cor -0.09868\n",
      "=========================================================================================\n",
      "256 32 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22088 | test ppl 3.39016|test cor 0.16577\n",
      "=========================================================================================\n",
      "256 32 6 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17309 | test ppl 3.23195|test cor 0.13843\n",
      "=========================================================================================\n",
      "256 32 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17655 | test ppl 3.24315|test cor -0.07958\n",
      "=========================================================================================\n",
      "256 32 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24454 | test ppl 3.47134|test cor 0.07627\n",
      "=========================================================================================\n",
      "256 32 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18208 | test ppl 3.26114|test cor 0.25894\n",
      "=========================================================================================\n",
      "256 32 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16301 | test ppl 3.19954|test cor 0.23981\n",
      "=========================================================================================\n",
      "256 32 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16392 | test ppl 3.20248|test cor 0.16444\n",
      "=========================================================================================\n",
      "256 32 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17506 | test ppl 3.23833|test cor 0.21681\n",
      "=========================================================================================\n",
      "256 32 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21602 | test ppl 3.37372|test cor 0.12243\n",
      "=========================================================================================\n",
      "256 32 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16428 | test ppl 3.20361|test cor 0.13507\n",
      "=========================================================================================\n",
      "256 32 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18402 | test ppl 3.26748|test cor -0.05844\n",
      "=========================================================================================\n",
      "256 32 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17443 | test ppl 3.23629|test cor -0.01318\n",
      "=========================================================================================\n",
      "256 32 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19744 | test ppl 3.31162|test cor 0.23224\n",
      "=========================================================================================\n",
      "256 32 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16077 | test ppl 3.19239|test cor -0.02195\n",
      "=========================================================================================\n",
      "256 32 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16547 | test ppl 3.20743|test cor 0.05747\n",
      "=========================================================================================\n",
      "256 32 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17177 | test ppl 3.22771|test cor 0.04600\n",
      "=========================================================================================\n",
      "256 32 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22435 | test ppl 3.40197|test cor 0.13437\n",
      "=========================================================================================\n",
      "256 32 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16219 | test ppl 3.19691|test cor -0.03496\n",
      "=========================================================================================\n",
      "256 32 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16964 | test ppl 3.22083|test cor 0.21304\n",
      "=========================================================================================\n",
      "256 32 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17786 | test ppl 3.24741|test cor -0.17134\n",
      "=========================================================================================\n",
      "256 32 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17365 | test ppl 3.23376|test cor 0.25807\n",
      "=========================================================================================\n",
      "256 32 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16596 | test ppl 3.20899|test cor -0.29566\n",
      "=========================================================================================\n",
      "256 32 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16351 | test ppl 3.20115|test cor 0.22149\n",
      "=========================================================================================\n",
      "256 32 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22331 | test ppl 3.39840|test cor 0.18485\n",
      "=========================================================================================\n",
      "256 32 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18911 | test ppl 3.28415|test cor 0.20254\n",
      "=========================================================================================\n",
      "256 32 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16707 | test ppl 3.21255|test cor -0.05256\n",
      "=========================================================================================\n",
      "256 32 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17637 | test ppl 3.24259|test cor 0.07644\n",
      "=========================================================================================\n",
      "256 32 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.32996 | test ppl 3.78089|test cor 0.01040\n",
      "=========================================================================================\n",
      "256 64 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22272 | test ppl 3.39642|test cor 0.01736\n",
      "=========================================================================================\n",
      "256 64 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15917 | test ppl 3.18729|test cor 0.00402\n",
      "=========================================================================================\n",
      "256 64 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16349 | test ppl 3.20108|test cor -0.08445\n",
      "=========================================================================================\n",
      "256 64 2 2 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16726 | test ppl 3.21317|test cor -0.01276\n",
      "=========================================================================================\n",
      "256 64 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23930 | test ppl 3.45320|test cor 0.04282\n",
      "=========================================================================================\n",
      "256 64 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16088 | test ppl 3.19275|test cor 0.04539\n",
      "=========================================================================================\n",
      "256 64 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15911 | test ppl 3.18710|test cor 0.04983\n",
      "=========================================================================================\n",
      "256 64 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16096 | test ppl 3.19300|test cor 0.13708\n",
      "=========================================================================================\n",
      "256 64 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23267 | test ppl 3.43037|test cor 0.04618\n",
      "=========================================================================================\n",
      "256 64 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16340 | test ppl 3.20080|test cor 0.13074\n",
      "=========================================================================================\n",
      "256 64 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16735 | test ppl 3.21347|test cor 0.08570\n",
      "=========================================================================================\n",
      "256 64 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20479 | test ppl 3.33605|test cor -0.00636\n",
      "=========================================================================================\n",
      "256 64 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21824 | test ppl 3.38123|test cor -0.02645\n",
      "=========================================================================================\n",
      "256 64 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16068 | test ppl 3.19209|test cor 0.05374\n",
      "=========================================================================================\n",
      "256 64 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16931 | test ppl 3.21977|test cor -0.12165\n",
      "=========================================================================================\n",
      "256 64 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18472 | test ppl 3.26978|test cor -0.03782\n",
      "=========================================================================================\n",
      "256 64 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24874 | test ppl 3.48593|test cor 0.03600\n",
      "=========================================================================================\n",
      "256 64 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16288 | test ppl 3.19914|test cor 0.10415\n",
      "=========================================================================================\n",
      "256 64 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16394 | test ppl 3.20254|test cor 0.01962\n",
      "=========================================================================================\n",
      "256 64 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18237 | test ppl 3.26209|test cor -0.16973\n",
      "=========================================================================================\n",
      "256 64 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19404 | test ppl 3.30038|test cor 0.05950\n",
      "=========================================================================================\n",
      "256 64 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16116 | test ppl 3.19365|test cor 0.06122\n",
      "=========================================================================================\n",
      "256 64 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17838 | test ppl 3.24909|test cor -0.09460\n",
      "=========================================================================================\n",
      "256 64 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18578 | test ppl 3.27323|test cor 0.07523\n",
      "=========================================================================================\n",
      "256 64 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21098 | test ppl 3.35676|test cor 0.01566\n",
      "=========================================================================================\n",
      "256 64 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16376 | test ppl 3.20196|test cor 0.05001\n",
      "=========================================================================================\n",
      "256 64 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16342 | test ppl 3.20085|test cor 0.15712\n",
      "=========================================================================================\n",
      "256 64 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17838 | test ppl 3.24912|test cor -0.02209\n",
      "=========================================================================================\n",
      "256 64 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23207 | test ppl 3.42832|test cor 0.16913\n",
      "=========================================================================================\n",
      "256 64 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18303 | test ppl 3.26425|test cor 0.24278\n",
      "=========================================================================================\n",
      "256 64 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17221 | test ppl 3.22911|test cor -0.14737\n",
      "=========================================================================================\n",
      "256 64 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21627 | test ppl 3.37458|test cor 0.08187\n",
      "=========================================================================================\n",
      "256 64 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21731 | test ppl 3.37809|test cor 0.15343\n",
      "=========================================================================================\n",
      "256 64 4 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16378 | test ppl 3.20201|test cor 0.10455\n",
      "=========================================================================================\n",
      "256 64 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16421 | test ppl 3.20338|test cor 0.09933\n",
      "=========================================================================================\n",
      "256 64 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17422 | test ppl 3.23563|test cor 0.07184\n",
      "=========================================================================================\n",
      "256 64 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24704 | test ppl 3.48001|test cor 0.20861\n",
      "=========================================================================================\n",
      "256 64 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16015 | test ppl 3.19042|test cor 0.11892\n",
      "=========================================================================================\n",
      "256 64 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16784 | test ppl 3.21503|test cor 0.17872\n",
      "=========================================================================================\n",
      "256 64 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22936 | test ppl 3.41904|test cor 0.11140\n",
      "=========================================================================================\n",
      "256 64 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.31621 | test ppl 3.72928|test cor 0.12339\n",
      "=========================================================================================\n",
      "256 64 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16068 | test ppl 3.19211|test cor -0.10197\n",
      "=========================================================================================\n",
      "256 64 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16369 | test ppl 3.20173|test cor 0.13109\n",
      "=========================================================================================\n",
      "256 64 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18068 | test ppl 3.25659|test cor 0.03181\n",
      "=========================================================================================\n",
      "256 64 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18117 | test ppl 3.25817|test cor 0.12321\n",
      "=========================================================================================\n",
      "256 64 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18210 | test ppl 3.26121|test cor 0.14429\n",
      "=========================================================================================\n",
      "256 64 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16674 | test ppl 3.21149|test cor 0.13202\n",
      "=========================================================================================\n",
      "256 64 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.29199 | test ppl 3.64003|test cor -0.08888\n",
      "=========================================================================================\n",
      "256 64 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18136 | test ppl 3.25880|test cor 0.15707\n",
      "=========================================================================================\n",
      "256 64 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16369 | test ppl 3.20171|test cor 0.00679\n",
      "=========================================================================================\n",
      "256 64 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17124 | test ppl 3.22599|test cor -0.09553\n",
      "=========================================================================================\n",
      "256 64 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16773 | test ppl 3.21469|test cor 0.10165\n",
      "=========================================================================================\n",
      "256 64 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17820 | test ppl 3.24852|test cor 0.15751\n",
      "=========================================================================================\n",
      "256 64 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16606 | test ppl 3.20931|test cor 0.21799\n",
      "=========================================================================================\n",
      "256 64 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15952 | test ppl 3.18841|test cor 0.17260\n",
      "=========================================================================================\n",
      "256 64 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18800 | test ppl 3.28053|test cor 0.06583\n",
      "=========================================================================================\n",
      "256 64 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19017 | test ppl 3.28763|test cor 0.15319\n",
      "=========================================================================================\n",
      "256 64 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17091 | test ppl 3.22494|test cor 0.12389\n",
      "=========================================================================================\n",
      "256 64 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16545 | test ppl 3.20735|test cor 0.20185\n",
      "=========================================================================================\n",
      "256 64 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16781 | test ppl 3.21495|test cor 0.02734\n",
      "=========================================================================================\n",
      "256 64 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28273 | test ppl 3.60648|test cor 0.21543\n",
      "=========================================================================================\n",
      "256 64 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17197 | test ppl 3.22833|test cor -0.01020\n",
      "=========================================================================================\n",
      "256 64 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16430 | test ppl 3.20369|test cor -0.22266\n",
      "=========================================================================================\n",
      "256 64 6 4 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.27833 | test ppl 3.59065|test cor 0.05984\n",
      "=========================================================================================\n",
      "256 64 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19111 | test ppl 3.29074|test cor 0.04606\n",
      "=========================================================================================\n",
      "256 64 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16539 | test ppl 3.20718|test cor 0.14145\n",
      "=========================================================================================\n",
      "256 64 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17306 | test ppl 3.23186|test cor -0.08697\n",
      "=========================================================================================\n",
      "256 64 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18990 | test ppl 3.28675|test cor 0.18281\n",
      "=========================================================================================\n",
      "256 64 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17908 | test ppl 3.25139|test cor 0.16236\n",
      "=========================================================================================\n",
      "256 64 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16708 | test ppl 3.21260|test cor 0.08730\n",
      "=========================================================================================\n",
      "256 64 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18556 | test ppl 3.27251|test cor 0.01838\n",
      "=========================================================================================\n",
      "256 64 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20256 | test ppl 3.32864|test cor -0.11181\n",
      "=========================================================================================\n",
      "256 64 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26451 | test ppl 3.54136|test cor 0.21544\n",
      "=========================================================================================\n",
      "256 64 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16599 | test ppl 3.20909|test cor 0.21783\n",
      "=========================================================================================\n",
      "256 64 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16776 | test ppl 3.21477|test cor 0.05630\n",
      "=========================================================================================\n",
      "256 64 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16519 | test ppl 3.20652|test cor 0.05788\n",
      "=========================================================================================\n",
      "256 64 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16444 | test ppl 3.20414|test cor 0.00679\n",
      "=========================================================================================\n",
      "256 64 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16847 | test ppl 3.21706|test cor 0.13743\n",
      "=========================================================================================\n",
      "256 64 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17447 | test ppl 3.23642|test cor 0.09644\n",
      "=========================================================================================\n",
      "256 64 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17389 | test ppl 3.23455|test cor -0.07143\n",
      "=========================================================================================\n",
      "256 64 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16858 | test ppl 3.21740|test cor 0.10541\n",
      "=========================================================================================\n",
      "256 64 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16489 | test ppl 3.20556|test cor 0.22348\n",
      "=========================================================================================\n",
      "256 64 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17638 | test ppl 3.24263|test cor -0.20159\n",
      "=========================================================================================\n",
      "256 64 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19203 | test ppl 3.29375|test cor -0.07649\n",
      "=========================================================================================\n",
      "256 64 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20207 | test ppl 3.32700|test cor 0.20651\n",
      "=========================================================================================\n",
      "256 64 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15903 | test ppl 3.18684|test cor -0.04908\n",
      "=========================================================================================\n",
      "256 64 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17032 | test ppl 3.22302|test cor 0.21821\n",
      "=========================================================================================\n",
      "256 64 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17560 | test ppl 3.24009|test cor -0.10797\n",
      "=========================================================================================\n",
      "256 64 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17491 | test ppl 3.23785|test cor 0.17316\n",
      "=========================================================================================\n",
      "256 64 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16667 | test ppl 3.21127|test cor -0.10828\n",
      "=========================================================================================\n",
      "256 64 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16388 | test ppl 3.20233|test cor 0.00758\n",
      "=========================================================================================\n",
      "256 64 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16663 | test ppl 3.21116|test cor -0.16164\n",
      "=========================================================================================\n",
      "256 64 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17703 | test ppl 3.24472|test cor 0.15360\n",
      "=========================================================================================\n",
      "256 64 8 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.16449 | test ppl 3.20428|test cor 0.21661\n",
      "=========================================================================================\n",
      "256 64 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17410 | test ppl 3.23523|test cor -0.19782\n",
      "=========================================================================================\n",
      "256 64 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17613 | test ppl 3.24179|test cor 0.08456\n",
      "=========================================================================================\n",
      "256 128 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28754 | test ppl 3.62385|test cor 0.04791\n",
      "=========================================================================================\n",
      "256 128 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15908 | test ppl 3.18699|test cor -0.12489\n",
      "=========================================================================================\n",
      "256 128 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15841 | test ppl 3.18485|test cor -0.09090\n",
      "=========================================================================================\n",
      "256 128 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16356 | test ppl 3.20130|test cor -0.07205\n",
      "=========================================================================================\n",
      "256 128 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21962 | test ppl 3.38591|test cor 0.02010\n",
      "=========================================================================================\n",
      "256 128 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16133 | test ppl 3.19418|test cor 0.03377\n",
      "=========================================================================================\n",
      "256 128 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18151 | test ppl 3.25931|test cor -0.17651\n",
      "=========================================================================================\n",
      "256 128 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16090 | test ppl 3.19281|test cor 0.01157\n",
      "=========================================================================================\n",
      "256 128 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20382 | test ppl 3.33281|test cor 0.06673\n",
      "=========================================================================================\n",
      "256 128 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15968 | test ppl 3.18890|test cor 0.04713\n",
      "=========================================================================================\n",
      "256 128 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16147 | test ppl 3.19462|test cor 0.00090\n",
      "=========================================================================================\n",
      "256 128 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17198 | test ppl 3.22838|test cor 0.15662\n",
      "=========================================================================================\n",
      "256 128 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20133 | test ppl 3.32454|test cor 0.09294\n",
      "=========================================================================================\n",
      "256 128 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16403 | test ppl 3.20281|test cor 0.04274\n",
      "=========================================================================================\n",
      "256 128 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16443 | test ppl 3.20411|test cor 0.02147\n",
      "=========================================================================================\n",
      "256 128 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19497 | test ppl 3.30346|test cor -0.00107\n",
      "=========================================================================================\n",
      "256 128 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22729 | test ppl 3.41196|test cor 0.04159\n",
      "=========================================================================================\n",
      "256 128 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16128 | test ppl 3.19401|test cor 0.12352\n",
      "=========================================================================================\n",
      "256 128 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16832 | test ppl 3.21658|test cor -0.00217\n",
      "=========================================================================================\n",
      "256 128 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17110 | test ppl 3.22555|test cor -0.09761\n",
      "=========================================================================================\n",
      "256 128 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22079 | test ppl 3.38986|test cor 0.08148\n",
      "=========================================================================================\n",
      "256 128 2 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16227 | test ppl 3.19718|test cor 0.06704\n",
      "=========================================================================================\n",
      "256 128 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16589 | test ppl 3.20879|test cor 0.02102\n",
      "=========================================================================================\n",
      "256 128 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16848 | test ppl 3.21709|test cor -0.11044\n",
      "=========================================================================================\n",
      "256 128 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19497 | test ppl 3.30345|test cor -0.02739\n",
      "=========================================================================================\n",
      "256 128 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16180 | test ppl 3.19567|test cor 0.19935\n",
      "=========================================================================================\n",
      "256 128 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15975 | test ppl 3.18915|test cor 0.15221\n",
      "=========================================================================================\n",
      "256 128 4 2 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17080 | test ppl 3.22457|test cor 0.17332\n",
      "=========================================================================================\n",
      "256 128 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22139 | test ppl 3.39190|test cor 0.13621\n",
      "=========================================================================================\n",
      "256 128 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16921 | test ppl 3.21944|test cor 0.17942\n",
      "=========================================================================================\n",
      "256 128 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16467 | test ppl 3.20486|test cor 0.18819\n",
      "=========================================================================================\n",
      "256 128 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16961 | test ppl 3.22075|test cor -0.08258\n",
      "=========================================================================================\n",
      "256 128 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19450 | test ppl 3.30191|test cor 0.09866\n",
      "=========================================================================================\n",
      "256 128 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16520 | test ppl 3.20658|test cor -0.08962\n",
      "=========================================================================================\n",
      "256 128 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15949 | test ppl 3.18829|test cor -0.06518\n",
      "=========================================================================================\n",
      "256 128 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22306 | test ppl 3.39757|test cor 0.04009\n",
      "=========================================================================================\n",
      "256 128 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26664 | test ppl 3.54890|test cor 0.18681\n",
      "=========================================================================================\n",
      "256 128 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16980 | test ppl 3.22133|test cor 0.06290\n",
      "=========================================================================================\n",
      "256 128 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16615 | test ppl 3.20962|test cor 0.21465\n",
      "=========================================================================================\n",
      "256 128 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21195 | test ppl 3.36002|test cor -0.21803\n",
      "=========================================================================================\n",
      "256 128 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26158 | test ppl 3.53100|test cor 0.10623\n",
      "=========================================================================================\n",
      "256 128 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16416 | test ppl 3.20324|test cor 0.21872\n",
      "=========================================================================================\n",
      "256 128 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16316 | test ppl 3.20002|test cor 0.03341\n",
      "=========================================================================================\n",
      "256 128 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16901 | test ppl 3.21880|test cor -0.00964\n",
      "=========================================================================================\n",
      "256 128 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17967 | test ppl 3.25328|test cor 0.14060\n",
      "=========================================================================================\n",
      "256 128 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16882 | test ppl 3.21820|test cor 0.07138\n",
      "=========================================================================================\n",
      "256 128 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19588 | test ppl 3.30648|test cor 0.07016\n",
      "=========================================================================================\n",
      "256 128 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17107 | test ppl 3.22544|test cor 0.04841\n",
      "=========================================================================================\n",
      "256 128 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17807 | test ppl 3.24811|test cor 0.22987\n",
      "=========================================================================================\n",
      "256 128 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16318 | test ppl 3.20009|test cor 0.17574\n",
      "=========================================================================================\n",
      "256 128 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16550 | test ppl 3.20752|test cor 0.13629\n",
      "=========================================================================================\n",
      "256 128 6 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19228 | test ppl 3.29458|test cor -0.01612\n",
      "=========================================================================================\n",
      "256 128 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18251 | test ppl 3.26255|test cor 0.18173\n",
      "=========================================================================================\n",
      "256 128 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16182 | test ppl 3.19574|test cor -0.20429\n",
      "=========================================================================================\n",
      "256 128 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16919 | test ppl 3.21939|test cor 0.00770\n",
      "=========================================================================================\n",
      "256 128 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.29309 | test ppl 3.64403|test cor 0.10390\n",
      "=========================================================================================\n",
      "256 128 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.28742 | test ppl 3.62342|test cor 0.23411\n",
      "=========================================================================================\n",
      "256 128 6 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17162 | test ppl 3.22722|test cor 0.10977\n",
      "=========================================================================================\n",
      "256 128 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16650 | test ppl 3.21074|test cor 0.17979\n",
      "=========================================================================================\n",
      "256 128 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16818 | test ppl 3.21613|test cor 0.15045\n",
      "=========================================================================================\n",
      "256 128 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16686 | test ppl 3.21189|test cor 0.12392\n",
      "=========================================================================================\n",
      "256 128 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16478 | test ppl 3.20522|test cor 0.19398\n",
      "=========================================================================================\n",
      "256 128 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18059 | test ppl 3.25629|test cor 0.01952\n",
      "=========================================================================================\n",
      "256 128 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.27654 | test ppl 3.58421|test cor 0.14867\n",
      "=========================================================================================\n",
      "256 128 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18483 | test ppl 3.27014|test cor 0.12968\n",
      "=========================================================================================\n",
      "256 128 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16321 | test ppl 3.20019|test cor 0.15288\n",
      "=========================================================================================\n",
      "256 128 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17656 | test ppl 3.24320|test cor 0.14831\n",
      "=========================================================================================\n",
      "256 128 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21350 | test ppl 3.36523|test cor 0.03027\n",
      "=========================================================================================\n",
      "256 128 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16432 | test ppl 3.20373|test cor 0.19907\n",
      "=========================================================================================\n",
      "256 128 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17022 | test ppl 3.22269|test cor -0.09045\n",
      "=========================================================================================\n",
      "256 128 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17855 | test ppl 3.24967|test cor 0.14511\n",
      "=========================================================================================\n",
      "256 128 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18529 | test ppl 3.27163|test cor 0.01597\n",
      "=========================================================================================\n",
      "256 128 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18127 | test ppl 3.25851|test cor 0.27714\n",
      "=========================================================================================\n",
      "256 128 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16908 | test ppl 3.21902|test cor -0.03638\n",
      "=========================================================================================\n",
      "256 128 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16313 | test ppl 3.19994|test cor 0.17734\n",
      "=========================================================================================\n",
      "256 128 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17534 | test ppl 3.23925|test cor 0.04715\n",
      "=========================================================================================\n",
      "256 128 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.30064 | test ppl 3.67165|test cor 0.19848\n",
      "=========================================================================================\n",
      "256 128 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16280 | test ppl 3.19887|test cor 0.23331\n",
      "=========================================================================================\n",
      "256 128 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16516 | test ppl 3.20643|test cor -0.17035\n",
      "=========================================================================================\n",
      "256 128 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22923 | test ppl 3.41859|test cor 0.14851\n",
      "=========================================================================================\n",
      "256 128 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17030 | test ppl 3.22298|test cor 0.25269\n",
      "=========================================================================================\n",
      "256 128 8 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16659 | test ppl 3.21103|test cor 0.28386\n",
      "=========================================================================================\n",
      "256 128 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16282 | test ppl 3.19895|test cor 0.14884\n",
      "=========================================================================================\n",
      "256 128 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18635 | test ppl 3.27512|test cor -0.17402\n",
      "=========================================================================================\n",
      "256 128 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20264 | test ppl 3.32889|test cor 0.07606\n",
      "=========================================================================================\n",
      "256 128 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16635 | test ppl 3.21026|test cor 0.02621\n",
      "=========================================================================================\n",
      "256 128 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16734 | test ppl 3.21344|test cor 0.16355\n",
      "=========================================================================================\n",
      "256 128 8 4 0.5 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.20907 | test ppl 3.35038|test cor -0.21757\n",
      "=========================================================================================\n",
      "256 128 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19467 | test ppl 3.30245|test cor 0.23917\n",
      "=========================================================================================\n",
      "256 128 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16550 | test ppl 3.20752|test cor 0.12852\n",
      "=========================================================================================\n",
      "256 128 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17353 | test ppl 3.23338|test cor -0.15784\n",
      "=========================================================================================\n",
      "256 128 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19914 | test ppl 3.31728|test cor 0.14034\n",
      "=========================================================================================\n",
      "256 128 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19557 | test ppl 3.30545|test cor 0.03622\n",
      "=========================================================================================\n",
      "256 128 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17794 | test ppl 3.24769|test cor 0.21891\n",
      "=========================================================================================\n",
      "256 128 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16320 | test ppl 3.20015|test cor 0.03484\n",
      "=========================================================================================\n",
      "256 128 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19634 | test ppl 3.30800|test cor -0.18154\n",
      "=========================================================================================\n",
      "256 256 2 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21799 | test ppl 3.38040|test cor 0.04966\n",
      "=========================================================================================\n",
      "256 256 2 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15814 | test ppl 3.18401|test cor 0.09584\n",
      "=========================================================================================\n",
      "256 256 2 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16698 | test ppl 3.21229|test cor 0.10740\n",
      "=========================================================================================\n",
      "256 256 2 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17651 | test ppl 3.24303|test cor 0.04609\n",
      "=========================================================================================\n",
      "256 256 2 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25842 | test ppl 3.51985|test cor 0.01860\n",
      "=========================================================================================\n",
      "256 256 2 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16425 | test ppl 3.20353|test cor -0.11720\n",
      "=========================================================================================\n",
      "256 256 2 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16111 | test ppl 3.19349|test cor -0.06268\n",
      "=========================================================================================\n",
      "256 256 2 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20652 | test ppl 3.34185|test cor 0.10799\n",
      "=========================================================================================\n",
      "256 256 2 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19141 | test ppl 3.29171|test cor 0.16599\n",
      "=========================================================================================\n",
      "256 256 2 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15991 | test ppl 3.18964|test cor 0.01522\n",
      "=========================================================================================\n",
      "256 256 2 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16585 | test ppl 3.20865|test cor 0.05936\n",
      "=========================================================================================\n",
      "256 256 2 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16871 | test ppl 3.21783|test cor 0.04782\n",
      "=========================================================================================\n",
      "256 256 2 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21462 | test ppl 3.36902|test cor 0.13721\n",
      "=========================================================================================\n",
      "256 256 2 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16057 | test ppl 3.19174|test cor 0.15724\n",
      "=========================================================================================\n",
      "256 256 2 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16094 | test ppl 3.19292|test cor 0.06891\n",
      "=========================================================================================\n",
      "256 256 2 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24605 | test ppl 3.47659|test cor -0.01597\n",
      "=========================================================================================\n",
      "256 256 2 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18151 | test ppl 3.25929|test cor 0.12667\n",
      "=========================================================================================\n",
      "256 256 2 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16747 | test ppl 3.21386|test cor 0.09317\n",
      "=========================================================================================\n",
      "256 256 2 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15806 | test ppl 3.18375|test cor 0.02250\n",
      "=========================================================================================\n",
      "256 256 2 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18026 | test ppl 3.25522|test cor -0.18839\n",
      "=========================================================================================\n",
      "256 256 2 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25126 | test ppl 3.49474|test cor 0.02609\n",
      "=========================================================================================\n",
      "256 256 2 8 0.5 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.15823 | test ppl 3.18428|test cor 0.09576\n",
      "=========================================================================================\n",
      "256 256 2 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16466 | test ppl 3.20482|test cor 0.01677\n",
      "=========================================================================================\n",
      "256 256 2 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23103 | test ppl 3.42474|test cor 0.17782\n",
      "=========================================================================================\n",
      "256 256 4 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16771 | test ppl 3.21462|test cor 0.19044\n",
      "=========================================================================================\n",
      "256 256 4 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16793 | test ppl 3.21532|test cor 0.10018\n",
      "=========================================================================================\n",
      "256 256 4 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16200 | test ppl 3.19633|test cor 0.09731\n",
      "=========================================================================================\n",
      "256 256 4 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17691 | test ppl 3.24435|test cor 0.08745\n",
      "=========================================================================================\n",
      "256 256 4 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.26456 | test ppl 3.54155|test cor 0.14482\n",
      "=========================================================================================\n",
      "256 256 4 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15928 | test ppl 3.18762|test cor 0.01236\n",
      "=========================================================================================\n",
      "256 256 4 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16183 | test ppl 3.19577|test cor -0.07693\n",
      "=========================================================================================\n",
      "256 256 4 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24807 | test ppl 3.48362|test cor 0.13368\n",
      "=========================================================================================\n",
      "256 256 4 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.29313 | test ppl 3.64417|test cor 0.07704\n",
      "=========================================================================================\n",
      "256 256 4 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16810 | test ppl 3.21586|test cor 0.14614\n",
      "=========================================================================================\n",
      "256 256 4 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16323 | test ppl 3.20025|test cor 0.23376\n",
      "=========================================================================================\n",
      "256 256 4 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18696 | test ppl 3.27709|test cor 0.03467\n",
      "=========================================================================================\n",
      "256 256 4 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20174 | test ppl 3.32591|test cor 0.20052\n",
      "=========================================================================================\n",
      "256 256 4 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15725 | test ppl 3.18117|test cor 0.00314\n",
      "=========================================================================================\n",
      "256 256 4 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15974 | test ppl 3.18910|test cor 0.08462\n",
      "=========================================================================================\n",
      "256 256 4 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15894 | test ppl 3.18654|test cor -0.14777\n",
      "=========================================================================================\n",
      "256 256 4 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.24846 | test ppl 3.48496|test cor 0.07709\n",
      "=========================================================================================\n",
      "256 256 4 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16133 | test ppl 3.19417|test cor 0.16996\n",
      "=========================================================================================\n",
      "256 256 4 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17009 | test ppl 3.22228|test cor 0.05947\n",
      "=========================================================================================\n",
      "256 256 4 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17780 | test ppl 3.24722|test cor -0.10782\n",
      "=========================================================================================\n",
      "256 256 4 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17840 | test ppl 3.24919|test cor 0.08873\n",
      "=========================================================================================\n",
      "256 256 4 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17416 | test ppl 3.23544|test cor 0.17647\n",
      "=========================================================================================\n",
      "256 256 4 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18969 | test ppl 3.28607|test cor 0.20271\n",
      "=========================================================================================\n",
      "256 256 4 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.21009 | test ppl 3.35380|test cor -0.12493\n",
      "=========================================================================================\n",
      "256 256 6 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17435 | test ppl 3.23604|test cor 0.22467\n",
      "=========================================================================================\n",
      "256 256 6 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16099 | test ppl 3.19308|test cor 0.16753\n",
      "=========================================================================================\n",
      "256 256 6 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16188 | test ppl 3.19594|test cor -0.06120\n",
      "=========================================================================================\n",
      "256 256 6 2 0.2 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17728 | test ppl 3.24554|test cor -0.08474\n",
      "=========================================================================================\n",
      "256 256 6 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17758 | test ppl 3.24652|test cor 0.16027\n",
      "=========================================================================================\n",
      "256 256 6 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16800 | test ppl 3.21555|test cor -0.06253\n",
      "=========================================================================================\n",
      "256 256 6 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16897 | test ppl 3.21867|test cor 0.04285\n",
      "=========================================================================================\n",
      "256 256 6 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.25175 | test ppl 3.49646|test cor -0.12423\n",
      "=========================================================================================\n",
      "256 256 6 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17689 | test ppl 3.24426|test cor 0.16589\n",
      "=========================================================================================\n",
      "256 256 6 4 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16129 | test ppl 3.19406|test cor 0.22591\n",
      "=========================================================================================\n",
      "256 256 6 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16752 | test ppl 3.21401|test cor 0.16029\n",
      "=========================================================================================\n",
      "256 256 6 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.22042 | test ppl 3.38860|test cor 0.03404\n",
      "=========================================================================================\n",
      "256 256 6 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.29851 | test ppl 3.66382|test cor 0.20779\n",
      "=========================================================================================\n",
      "256 256 6 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16636 | test ppl 3.21030|test cor 0.15047\n",
      "=========================================================================================\n",
      "256 256 6 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17369 | test ppl 3.23390|test cor -0.16570\n",
      "=========================================================================================\n",
      "256 256 6 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16880 | test ppl 3.21814|test cor 0.23211\n",
      "=========================================================================================\n",
      "256 256 6 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.30554 | test ppl 3.68969|test cor 0.21658\n",
      "=========================================================================================\n",
      "256 256 6 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16783 | test ppl 3.21502|test cor 0.08016\n",
      "=========================================================================================\n",
      "256 256 6 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16210 | test ppl 3.19665|test cor -0.20363\n",
      "=========================================================================================\n",
      "256 256 6 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19335 | test ppl 3.29810|test cor 0.18503\n",
      "=========================================================================================\n",
      "256 256 6 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16869 | test ppl 3.21779|test cor 0.15900\n",
      "=========================================================================================\n",
      "256 256 6 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17049 | test ppl 3.22357|test cor 0.10490\n",
      "=========================================================================================\n",
      "256 256 6 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16199 | test ppl 3.19627|test cor 0.07209\n",
      "=========================================================================================\n",
      "256 256 6 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.23127 | test ppl 3.42559|test cor -0.00224\n",
      "=========================================================================================\n",
      "256 256 8 2 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17032 | test ppl 3.22303|test cor 0.26650\n",
      "=========================================================================================\n",
      "256 256 8 2 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16296 | test ppl 3.19939|test cor -0.19840\n",
      "=========================================================================================\n",
      "256 256 8 2 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16358 | test ppl 3.20138|test cor 0.07202\n",
      "=========================================================================================\n",
      "256 256 8 2 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17416 | test ppl 3.23542|test cor 0.18701\n",
      "=========================================================================================\n",
      "256 256 8 2 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19930 | test ppl 3.31780|test cor 0.19422\n",
      "=========================================================================================\n",
      "256 256 8 2 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16655 | test ppl 3.21090|test cor 0.02274\n",
      "=========================================================================================\n",
      "256 256 8 2 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16709 | test ppl 3.21263|test cor 0.00321\n",
      "=========================================================================================\n",
      "256 256 8 2 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17812 | test ppl 3.24827|test cor -0.23543\n",
      "=========================================================================================\n",
      "256 256 8 4 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18537 | test ppl 3.27191|test cor 0.08525\n",
      "=========================================================================================\n",
      "256 256 8 4 0.2 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss 1.17775 | test ppl 3.24706|test cor -0.01188\n",
      "=========================================================================================\n",
      "256 256 8 4 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17302 | test ppl 3.23172|test cor 0.15213\n",
      "=========================================================================================\n",
      "256 256 8 4 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16862 | test ppl 3.21755|test cor -0.17611\n",
      "=========================================================================================\n",
      "256 256 8 4 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17124 | test ppl 3.22598|test cor 0.12071\n",
      "=========================================================================================\n",
      "256 256 8 4 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16350 | test ppl 3.20113|test cor 0.09215\n",
      "=========================================================================================\n",
      "256 256 8 4 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19392 | test ppl 3.30000|test cor 0.15594\n",
      "=========================================================================================\n",
      "256 256 8 4 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.20934 | test ppl 3.35129|test cor 0.13047\n",
      "=========================================================================================\n",
      "256 256 8 8 0.2 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.17873 | test ppl 3.25024|test cor 0.21407\n",
      "=========================================================================================\n",
      "256 256 8 8 0.2 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.15656 | test ppl 3.17898|test cor 0.12842\n",
      "=========================================================================================\n",
      "256 256 8 8 0.2 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16066 | test ppl 3.19205|test cor 0.04053\n",
      "=========================================================================================\n",
      "256 256 8 8 0.2 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.18184 | test ppl 3.26036|test cor -0.02763\n",
      "=========================================================================================\n",
      "256 256 8 8 0.5 0.1\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19413 | test ppl 3.30067|test cor 0.06423\n",
      "=========================================================================================\n",
      "256 256 8 8 0.5 0.01\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16025 | test ppl 3.19074|test cor -0.12348\n",
      "=========================================================================================\n",
      "256 256 8 8 0.5 0.005\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.16867 | test ppl 3.21770|test cor -0.06753\n",
      "=========================================================================================\n",
      "256 256 8 8 0.5 0.001\n",
      "=========================================================================================\n",
      "| End of training | test loss 1.19272 | test ppl 3.29605|test cor -0.15277\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_mse=[]\n",
    "for emsize, d_hid,nlayers, nhead, dropout,lr in param:\n",
    "    print(emsize, d_hid,nlayers, nhead, dropout,lr)\n",
    "    model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss,v_cor = evaluate(model, val_data)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "       # print('-' * 89)\n",
    "       # print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "         #     f'valid loss {val_loss:.5f} | valid ppl {val_ppl:8.2f}| 'f'V_cor {v_cor:.5f}')\n",
    "        #print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "    test_loss,t_cor= evaluate(best_model, test_data)\n",
    "    test_mse.append([emsize, d_hid,nlayers, nhead, dropout,lr,test_loss])\n",
    "    test_ppl = math.exp(test_loss)\n",
    "    print('=' * 89)\n",
    "    print(f'| End of training | test loss {test_loss:.5f} | '\n",
    "          f'test ppl {test_ppl:.5f}|'f'test cor {t_cor:.5f}')\n",
    "    print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 8, 4, 2, 0.2, 0.001, 1.9330300315518245]\n"
     ]
    }
   ],
   "source": [
    "print(test_mse[np.argmax(np.array(test_mse)[:,-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 32, 2, 8, 0.2, 0.01, 1.1523562502638203]\n"
     ]
    }
   ],
   "source": [
    "print(test_mse[np.argmin(np.array(test_mse)[:,-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}