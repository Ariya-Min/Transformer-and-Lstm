{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, Tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def standardization(data):\n",
    "    mu = np.mean(data, axis=0)\n",
    "    sigma = np.std(data, axis=0)\n",
    "    return (data - mu) / sigma\n",
    "\n",
    "def normalization(data):\n",
    "    _range = np.max(data) - np.min(data)\n",
    "    return (data - np.min(data)) / _range\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "learning_rate=0.005\n",
    "input_size=20\n",
    "num_epochs=1000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1753951\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_csv=pd.read_csv(\"industry_ret_data_1500.csv\")\n",
    "dataset = data_csv.values\n",
    "dataset=np.delete(dataset,0,axis=1)\n",
    "dataset = dataset.astype('float32')\n",
    "dataset=standardization(dataset)\n",
    "def create_dataset(dataset, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i + look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "data_X, data_Y = create_dataset(dataset,input_size )\n",
    "train_X = data_X[:1000]\n",
    "train_Y = data_Y[:1000]\n",
    "val_X=data_X[1000:1200]\n",
    "val_Y=data_Y[1000:1200]\n",
    "test_X = data_X[1200:]\n",
    "test_Y = data_Y[1200:]\n",
    "print(np.var(test_Y))\n",
    "train_X = train_X.reshape(-1, 433, input_size )\n",
    "train_Y = train_Y.reshape(-1,433,1)\n",
    "test_X = test_X.reshape(-1,433, input_size )\n",
    "test_Y=test_Y.reshape(-1,433,1)\n",
    "val_X = val_X.reshape(-1, 433, input_size )\n",
    "val_Y = val_Y.reshape(-1, 433,1)\n",
    "train_x = torch.from_numpy(train_X)\n",
    "train_y = torch.from_numpy(train_Y)\n",
    "test_x = torch.from_numpy(test_X)\n",
    "test_y=torch.from_numpy(test_Y)\n",
    "val_x=torch.from_numpy(val_X)\n",
    "val_y = torch.from_numpy(val_Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(standardization())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FFN, self).__init__()\n",
    "        self.ffn=nn.Linear(20,1)\n",
    "    def forward(self, x):  #\n",
    "        out = self.ffn(x)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.34900,val_Loss: 1.62079\n",
      "Epoch: 2, Loss: 1.24452,val_Loss: 1.51119\n",
      "Epoch: 3, Loss: 1.15535,val_Loss: 1.42058\n",
      "Epoch: 4, Loss: 1.08158,val_Loss: 1.34879\n",
      "Epoch: 5, Loss: 1.02309,val_Loss: 1.29522\n",
      "Epoch: 6, Loss: 0.97939,val_Loss: 1.25876\n",
      "Epoch: 7, Loss: 0.94959,val_Loss: 1.23764\n",
      "Epoch: 8, Loss: 0.93226,val_Loss: 1.22943\n",
      "Epoch: 9, Loss: 0.92546,val_Loss: 1.23111\n",
      "Epoch: 10, Loss: 0.92674,val_Loss: 1.23924\n",
      "Epoch: 11, Loss: 0.93333,val_Loss: 1.25040\n",
      "Epoch: 12, Loss: 0.94246,val_Loss: 1.26154\n",
      "Epoch: 13, Loss: 0.95165,val_Loss: 1.27032\n",
      "Epoch: 14, Loss: 0.95902,val_Loss: 1.27534\n",
      "Epoch: 15, Loss: 0.96341,val_Loss: 1.27605\n",
      "Epoch: 16, Loss: 0.96437,val_Loss: 1.27267\n",
      "Epoch: 17, Loss: 0.96205,val_Loss: 1.26593\n",
      "Epoch: 18, Loss: 0.95704,val_Loss: 1.25686\n",
      "Epoch: 19, Loss: 0.95016,val_Loss: 1.24662\n",
      "Epoch: 20, Loss: 0.94233,val_Loss: 1.23629\n",
      "Epoch: 21, Loss: 0.93443,val_Loss: 1.22681\n",
      "Epoch: 22, Loss: 0.92721,val_Loss: 1.21888\n",
      "Epoch: 23, Loss: 0.92122,val_Loss: 1.21292\n",
      "Epoch: 24, Loss: 0.91681,val_Loss: 1.20903\n",
      "Epoch: 25, Loss: 0.91406,val_Loss: 1.20710\n",
      "Epoch: 26, Loss: 0.91287,val_Loss: 1.20676\n",
      "Epoch: 27, Loss: 0.91297,val_Loss: 1.20753\n",
      "Epoch: 28, Loss: 0.91393,val_Loss: 1.20885\n",
      "Epoch: 29, Loss: 0.91534,val_Loss: 1.21019\n",
      "Epoch: 30, Loss: 0.91675,val_Loss: 1.21112\n",
      "Epoch: 31, Loss: 0.91783,val_Loss: 1.21135\n",
      "Epoch: 32, Loss: 0.91833,val_Loss: 1.21075\n",
      "Epoch: 33, Loss: 0.91816,val_Loss: 1.20933\n",
      "Epoch: 34, Loss: 0.91732,val_Loss: 1.20725\n",
      "Epoch: 35, Loss: 0.91594,val_Loss: 1.20473\n",
      "Epoch: 36, Loss: 0.91420,val_Loss: 1.20202\n",
      "Epoch: 37, Loss: 0.91231,val_Loss: 1.19940\n",
      "Epoch: 38, Loss: 0.91048,val_Loss: 1.19706\n",
      "Epoch: 39, Loss: 0.90888,val_Loss: 1.19514\n",
      "Epoch: 40, Loss: 0.90760,val_Loss: 1.19370\n",
      "Epoch: 41, Loss: 0.90671,val_Loss: 1.19271\n",
      "Epoch: 42, Loss: 0.90617,val_Loss: 1.19209\n",
      "Epoch: 43, Loss: 0.90593,val_Loss: 1.19171\n",
      "Epoch: 44, Loss: 0.90586,val_Loss: 1.19142\n",
      "Epoch: 45, Loss: 0.90587,val_Loss: 1.19110\n",
      "Epoch: 46, Loss: 0.90584,val_Loss: 1.19065\n",
      "Epoch: 47, Loss: 0.90570,val_Loss: 1.19000\n",
      "Epoch: 48, Loss: 0.90539,val_Loss: 1.18914\n",
      "Epoch: 49, Loss: 0.90490,val_Loss: 1.18811\n",
      "Epoch: 50, Loss: 0.90427,val_Loss: 1.18695\n",
      "Epoch: 51, Loss: 0.90353,val_Loss: 1.18575\n",
      "Epoch: 52, Loss: 0.90275,val_Loss: 1.18456\n",
      "Epoch: 53, Loss: 0.90198,val_Loss: 1.18344\n",
      "Epoch: 54, Loss: 0.90126,val_Loss: 1.18244\n",
      "Epoch: 55, Loss: 0.90064,val_Loss: 1.18156\n",
      "Epoch: 56, Loss: 0.90012,val_Loss: 1.18080\n",
      "Epoch: 57, Loss: 0.89968,val_Loss: 1.18012\n",
      "Epoch: 58, Loss: 0.89932,val_Loss: 1.17948\n",
      "Epoch: 59, Loss: 0.89899,val_Loss: 1.17885\n",
      "Epoch: 60, Loss: 0.89867,val_Loss: 1.17820\n",
      "Epoch: 61, Loss: 0.89833,val_Loss: 1.17749\n",
      "Epoch: 62, Loss: 0.89795,val_Loss: 1.17673\n",
      "Epoch: 63, Loss: 0.89753,val_Loss: 1.17592\n",
      "Epoch: 64, Loss: 0.89707,val_Loss: 1.17507\n",
      "Epoch: 65, Loss: 0.89658,val_Loss: 1.17421\n",
      "Epoch: 66, Loss: 0.89608,val_Loss: 1.17335\n",
      "Epoch: 67, Loss: 0.89558,val_Loss: 1.17252\n",
      "Epoch: 68, Loss: 0.89510,val_Loss: 1.17171\n",
      "Epoch: 69, Loss: 0.89465,val_Loss: 1.17094\n",
      "Epoch: 70, Loss: 0.89423,val_Loss: 1.17020\n",
      "Epoch: 71, Loss: 0.89383,val_Loss: 1.16949\n",
      "Epoch: 72, Loss: 0.89345,val_Loss: 1.16878\n",
      "Epoch: 73, Loss: 0.89308,val_Loss: 1.16807\n",
      "Epoch: 74, Loss: 0.89272,val_Loss: 1.16735\n",
      "Epoch: 75, Loss: 0.89234,val_Loss: 1.16662\n",
      "Epoch: 76, Loss: 0.89195,val_Loss: 1.16587\n",
      "Epoch: 77, Loss: 0.89156,val_Loss: 1.16512\n",
      "Epoch: 78, Loss: 0.89115,val_Loss: 1.16436\n",
      "Epoch: 79, Loss: 0.89075,val_Loss: 1.16360\n",
      "Epoch: 80, Loss: 0.89034,val_Loss: 1.16285\n",
      "Epoch: 81, Loss: 0.88994,val_Loss: 1.16211\n",
      "Epoch: 82, Loss: 0.88956,val_Loss: 1.16138\n",
      "Epoch: 83, Loss: 0.88918,val_Loss: 1.16067\n",
      "Epoch: 84, Loss: 0.88881,val_Loss: 1.15997\n",
      "Epoch: 85, Loss: 0.88845,val_Loss: 1.15927\n",
      "Epoch: 86, Loss: 0.88809,val_Loss: 1.15858\n",
      "Epoch: 87, Loss: 0.88774,val_Loss: 1.15789\n",
      "Epoch: 88, Loss: 0.88738,val_Loss: 1.15719\n",
      "Epoch: 89, Loss: 0.88703,val_Loss: 1.15650\n",
      "Epoch: 90, Loss: 0.88667,val_Loss: 1.15581\n",
      "Epoch: 91, Loss: 0.88631,val_Loss: 1.15513\n",
      "Epoch: 92, Loss: 0.88596,val_Loss: 1.15445\n",
      "Epoch: 93, Loss: 0.88561,val_Loss: 1.15378\n",
      "Epoch: 94, Loss: 0.88526,val_Loss: 1.15312\n",
      "Epoch: 95, Loss: 0.88492,val_Loss: 1.15246\n",
      "Epoch: 96, Loss: 0.88459,val_Loss: 1.15182\n",
      "Epoch: 97, Loss: 0.88426,val_Loss: 1.15118\n",
      "Epoch: 98, Loss: 0.88393,val_Loss: 1.15055\n",
      "Epoch: 99, Loss: 0.88361,val_Loss: 1.14993\n",
      "Epoch: 100, Loss: 0.88329,val_Loss: 1.14931\n",
      "Epoch: 101, Loss: 0.88297,val_Loss: 1.14869\n",
      "Epoch: 102, Loss: 0.88265,val_Loss: 1.14808\n",
      "Epoch: 103, Loss: 0.88234,val_Loss: 1.14748\n",
      "Epoch: 104, Loss: 0.88203,val_Loss: 1.14688\n",
      "Epoch: 105, Loss: 0.88172,val_Loss: 1.14629\n",
      "Epoch: 106, Loss: 0.88142,val_Loss: 1.14571\n",
      "Epoch: 107, Loss: 0.88111,val_Loss: 1.14513\n",
      "Epoch: 108, Loss: 0.88082,val_Loss: 1.14456\n",
      "Epoch: 109, Loss: 0.88052,val_Loss: 1.14400\n",
      "Epoch: 110, Loss: 0.88023,val_Loss: 1.14344\n",
      "Epoch: 111, Loss: 0.87995,val_Loss: 1.14289\n",
      "Epoch: 112, Loss: 0.87966,val_Loss: 1.14235\n",
      "Epoch: 113, Loss: 0.87938,val_Loss: 1.14181\n",
      "Epoch: 114, Loss: 0.87911,val_Loss: 1.14128\n",
      "Epoch: 115, Loss: 0.87883,val_Loss: 1.14075\n",
      "Epoch: 116, Loss: 0.87856,val_Loss: 1.14023\n",
      "Epoch: 117, Loss: 0.87829,val_Loss: 1.13972\n",
      "Epoch: 118, Loss: 0.87802,val_Loss: 1.13921\n",
      "Epoch: 119, Loss: 0.87776,val_Loss: 1.13871\n",
      "Epoch: 120, Loss: 0.87750,val_Loss: 1.13821\n",
      "Epoch: 121, Loss: 0.87725,val_Loss: 1.13772\n",
      "Epoch: 122, Loss: 0.87699,val_Loss: 1.13724\n",
      "Epoch: 123, Loss: 0.87674,val_Loss: 1.13676\n",
      "Epoch: 124, Loss: 0.87650,val_Loss: 1.13629\n",
      "Epoch: 125, Loss: 0.87625,val_Loss: 1.13582\n",
      "Epoch: 126, Loss: 0.87601,val_Loss: 1.13536\n",
      "Epoch: 127, Loss: 0.87578,val_Loss: 1.13490\n",
      "Epoch: 128, Loss: 0.87554,val_Loss: 1.13445\n",
      "Epoch: 129, Loss: 0.87531,val_Loss: 1.13400\n",
      "Epoch: 130, Loss: 0.87508,val_Loss: 1.13356\n",
      "Epoch: 131, Loss: 0.87485,val_Loss: 1.13313\n",
      "Epoch: 132, Loss: 0.87463,val_Loss: 1.13270\n",
      "Epoch: 133, Loss: 0.87441,val_Loss: 1.13227\n",
      "Epoch: 134, Loss: 0.87419,val_Loss: 1.13185\n",
      "Epoch: 135, Loss: 0.87398,val_Loss: 1.13144\n",
      "Epoch: 136, Loss: 0.87377,val_Loss: 1.13103\n",
      "Epoch: 137, Loss: 0.87356,val_Loss: 1.13063\n",
      "Epoch: 138, Loss: 0.87335,val_Loss: 1.13023\n",
      "Epoch: 139, Loss: 0.87315,val_Loss: 1.12983\n",
      "Epoch: 140, Loss: 0.87295,val_Loss: 1.12945\n",
      "Epoch: 141, Loss: 0.87275,val_Loss: 1.12906\n",
      "Epoch: 142, Loss: 0.87256,val_Loss: 1.12868\n",
      "Epoch: 143, Loss: 0.87237,val_Loss: 1.12831\n",
      "Epoch: 144, Loss: 0.87218,val_Loss: 1.12794\n",
      "Epoch: 145, Loss: 0.87199,val_Loss: 1.12758\n",
      "Epoch: 146, Loss: 0.87181,val_Loss: 1.12722\n",
      "Epoch: 147, Loss: 0.87162,val_Loss: 1.12687\n",
      "Epoch: 148, Loss: 0.87145,val_Loss: 1.12652\n",
      "Epoch: 149, Loss: 0.87127,val_Loss: 1.12618\n",
      "Epoch: 150, Loss: 0.87110,val_Loss: 1.12584\n",
      "Epoch: 151, Loss: 0.87092,val_Loss: 1.12551\n",
      "Epoch: 152, Loss: 0.87076,val_Loss: 1.12518\n",
      "Epoch: 153, Loss: 0.87059,val_Loss: 1.12485\n",
      "Epoch: 154, Loss: 0.87043,val_Loss: 1.12453\n",
      "Epoch: 155, Loss: 0.87026,val_Loss: 1.12422\n",
      "Epoch: 156, Loss: 0.87011,val_Loss: 1.12391\n",
      "Epoch: 157, Loss: 0.86995,val_Loss: 1.12360\n",
      "Epoch: 158, Loss: 0.86979,val_Loss: 1.12330\n",
      "Epoch: 159, Loss: 0.86964,val_Loss: 1.12300\n",
      "Epoch: 160, Loss: 0.86949,val_Loss: 1.12271\n",
      "Epoch: 161, Loss: 0.86935,val_Loss: 1.12242\n",
      "Epoch: 162, Loss: 0.86920,val_Loss: 1.12214\n",
      "Epoch: 163, Loss: 0.86906,val_Loss: 1.12186\n",
      "Epoch: 164, Loss: 0.86892,val_Loss: 1.12158\n",
      "Epoch: 165, Loss: 0.86878,val_Loss: 1.12131\n",
      "Epoch: 166, Loss: 0.86864,val_Loss: 1.12105\n",
      "Epoch: 167, Loss: 0.86851,val_Loss: 1.12078\n",
      "Epoch: 168, Loss: 0.86838,val_Loss: 1.12052\n",
      "Epoch: 169, Loss: 0.86825,val_Loss: 1.12027\n",
      "Epoch: 170, Loss: 0.86812,val_Loss: 1.12002\n",
      "Epoch: 171, Loss: 0.86799,val_Loss: 1.11977\n",
      "Epoch: 172, Loss: 0.86787,val_Loss: 1.11953\n",
      "Epoch: 173, Loss: 0.86775,val_Loss: 1.11929\n",
      "Epoch: 174, Loss: 0.86763,val_Loss: 1.11905\n",
      "Epoch: 175, Loss: 0.86751,val_Loss: 1.11882\n",
      "Epoch: 176, Loss: 0.86739,val_Loss: 1.11859\n",
      "Epoch: 177, Loss: 0.86728,val_Loss: 1.11837\n",
      "Epoch: 178, Loss: 0.86717,val_Loss: 1.11815\n",
      "Epoch: 179, Loss: 0.86706,val_Loss: 1.11793\n",
      "Epoch: 180, Loss: 0.86695,val_Loss: 1.11772\n",
      "Epoch: 181, Loss: 0.86684,val_Loss: 1.11751\n",
      "Epoch: 182, Loss: 0.86674,val_Loss: 1.11730\n",
      "Epoch: 183, Loss: 0.86663,val_Loss: 1.11710\n",
      "Epoch: 184, Loss: 0.86653,val_Loss: 1.11690\n",
      "Epoch: 185, Loss: 0.86643,val_Loss: 1.11670\n",
      "Epoch: 186, Loss: 0.86633,val_Loss: 1.11650\n",
      "Epoch: 187, Loss: 0.86624,val_Loss: 1.11631\n",
      "Epoch: 188, Loss: 0.86614,val_Loss: 1.11613\n",
      "Epoch: 189, Loss: 0.86605,val_Loss: 1.11594\n",
      "Epoch: 190, Loss: 0.86596,val_Loss: 1.11576\n",
      "Epoch: 191, Loss: 0.86587,val_Loss: 1.11558\n",
      "Epoch: 192, Loss: 0.86578,val_Loss: 1.11541\n",
      "Epoch: 193, Loss: 0.86569,val_Loss: 1.11523\n",
      "Epoch: 194, Loss: 0.86561,val_Loss: 1.11506\n",
      "Epoch: 195, Loss: 0.86552,val_Loss: 1.11490\n",
      "Epoch: 196, Loss: 0.86544,val_Loss: 1.11473\n",
      "Epoch: 197, Loss: 0.86536,val_Loss: 1.11457\n",
      "Epoch: 198, Loss: 0.86528,val_Loss: 1.11441\n",
      "Epoch: 199, Loss: 0.86520,val_Loss: 1.11426\n",
      "Epoch: 200, Loss: 0.86513,val_Loss: 1.11411\n",
      "Epoch: 201, Loss: 0.86505,val_Loss: 1.11396\n",
      "Epoch: 202, Loss: 0.86498,val_Loss: 1.11381\n",
      "Epoch: 203, Loss: 0.86490,val_Loss: 1.11366\n",
      "Epoch: 204, Loss: 0.86483,val_Loss: 1.11352\n",
      "Epoch: 205, Loss: 0.86476,val_Loss: 1.11338\n",
      "Epoch: 206, Loss: 0.86469,val_Loss: 1.11324\n",
      "Epoch: 207, Loss: 0.86463,val_Loss: 1.11311\n",
      "Epoch: 208, Loss: 0.86456,val_Loss: 1.11297\n",
      "Epoch: 209, Loss: 0.86450,val_Loss: 1.11284\n",
      "Epoch: 210, Loss: 0.86443,val_Loss: 1.11272\n",
      "Epoch: 211, Loss: 0.86437,val_Loss: 1.11259\n",
      "Epoch: 212, Loss: 0.86431,val_Loss: 1.11247\n",
      "Epoch: 213, Loss: 0.86425,val_Loss: 1.11235\n",
      "Epoch: 214, Loss: 0.86419,val_Loss: 1.11223\n",
      "Epoch: 215, Loss: 0.86413,val_Loss: 1.11211\n",
      "Epoch: 216, Loss: 0.86407,val_Loss: 1.11199\n",
      "Epoch: 217, Loss: 0.86402,val_Loss: 1.11188\n",
      "Epoch: 218, Loss: 0.86396,val_Loss: 1.11177\n",
      "Epoch: 219, Loss: 0.86391,val_Loss: 1.11166\n",
      "Epoch: 220, Loss: 0.86386,val_Loss: 1.11156\n",
      "Epoch: 221, Loss: 0.86380,val_Loss: 1.11145\n",
      "Epoch: 222, Loss: 0.86375,val_Loss: 1.11135\n",
      "Epoch: 223, Loss: 0.86370,val_Loss: 1.11125\n",
      "Epoch: 224, Loss: 0.86365,val_Loss: 1.11115\n",
      "Epoch: 225, Loss: 0.86361,val_Loss: 1.11105\n",
      "Epoch: 226, Loss: 0.86356,val_Loss: 1.11096\n",
      "Epoch: 227, Loss: 0.86351,val_Loss: 1.11086\n",
      "Epoch: 228, Loss: 0.86347,val_Loss: 1.11077\n",
      "Epoch: 229, Loss: 0.86342,val_Loss: 1.11068\n",
      "Epoch: 230, Loss: 0.86338,val_Loss: 1.11059\n",
      "Epoch: 231, Loss: 0.86334,val_Loss: 1.11051\n",
      "Epoch: 232, Loss: 0.86330,val_Loss: 1.11042\n",
      "Epoch: 233, Loss: 0.86326,val_Loss: 1.11034\n",
      "Epoch: 234, Loss: 0.86322,val_Loss: 1.11025\n",
      "Epoch: 235, Loss: 0.86318,val_Loss: 1.11017\n",
      "Epoch: 236, Loss: 0.86314,val_Loss: 1.11010\n",
      "Epoch: 237, Loss: 0.86310,val_Loss: 1.11002\n",
      "Epoch: 238, Loss: 0.86306,val_Loss: 1.10994\n",
      "Epoch: 239, Loss: 0.86303,val_Loss: 1.10987\n",
      "Epoch: 240, Loss: 0.86299,val_Loss: 1.10979\n",
      "Epoch: 241, Loss: 0.86296,val_Loss: 1.10972\n",
      "Epoch: 242, Loss: 0.86292,val_Loss: 1.10965\n",
      "Epoch: 243, Loss: 0.86289,val_Loss: 1.10958\n",
      "Epoch: 244, Loss: 0.86286,val_Loss: 1.10952\n",
      "Epoch: 245, Loss: 0.86283,val_Loss: 1.10945\n",
      "Epoch: 246, Loss: 0.86279,val_Loss: 1.10939\n",
      "Epoch: 247, Loss: 0.86276,val_Loss: 1.10932\n",
      "Epoch: 248, Loss: 0.86273,val_Loss: 1.10926\n",
      "Epoch: 249, Loss: 0.86270,val_Loss: 1.10920\n",
      "Epoch: 250, Loss: 0.86267,val_Loss: 1.10914\n",
      "Epoch: 251, Loss: 0.86265,val_Loss: 1.10908\n",
      "Epoch: 252, Loss: 0.86262,val_Loss: 1.10902\n",
      "Epoch: 253, Loss: 0.86259,val_Loss: 1.10897\n",
      "Epoch: 254, Loss: 0.86257,val_Loss: 1.10891\n",
      "Epoch: 255, Loss: 0.86254,val_Loss: 1.10886\n",
      "Epoch: 256, Loss: 0.86251,val_Loss: 1.10880\n",
      "Epoch: 257, Loss: 0.86249,val_Loss: 1.10875\n",
      "Epoch: 258, Loss: 0.86246,val_Loss: 1.10870\n",
      "Epoch: 259, Loss: 0.86244,val_Loss: 1.10865\n",
      "Epoch: 260, Loss: 0.86242,val_Loss: 1.10860\n",
      "Epoch: 261, Loss: 0.86240,val_Loss: 1.10855\n",
      "Epoch: 262, Loss: 0.86237,val_Loss: 1.10851\n",
      "Epoch: 263, Loss: 0.86235,val_Loss: 1.10846\n",
      "Epoch: 264, Loss: 0.86233,val_Loss: 1.10842\n",
      "Epoch: 265, Loss: 0.86231,val_Loss: 1.10837\n",
      "Epoch: 266, Loss: 0.86229,val_Loss: 1.10833\n",
      "Epoch: 267, Loss: 0.86227,val_Loss: 1.10828\n",
      "Epoch: 268, Loss: 0.86225,val_Loss: 1.10824\n",
      "Epoch: 269, Loss: 0.86223,val_Loss: 1.10820\n",
      "Epoch: 270, Loss: 0.86221,val_Loss: 1.10816\n",
      "Epoch: 271, Loss: 0.86219,val_Loss: 1.10812\n",
      "Epoch: 272, Loss: 0.86217,val_Loss: 1.10809\n",
      "Epoch: 273, Loss: 0.86216,val_Loss: 1.10805\n",
      "Epoch: 274, Loss: 0.86214,val_Loss: 1.10801\n",
      "Epoch: 275, Loss: 0.86212,val_Loss: 1.10797\n",
      "Epoch: 276, Loss: 0.86211,val_Loss: 1.10794\n",
      "Epoch: 277, Loss: 0.86209,val_Loss: 1.10791\n",
      "Epoch: 278, Loss: 0.86207,val_Loss: 1.10787\n",
      "Epoch: 279, Loss: 0.86206,val_Loss: 1.10784\n",
      "Epoch: 280, Loss: 0.86204,val_Loss: 1.10781\n",
      "Epoch: 281, Loss: 0.86203,val_Loss: 1.10777\n",
      "Epoch: 282, Loss: 0.86202,val_Loss: 1.10774\n",
      "Epoch: 283, Loss: 0.86200,val_Loss: 1.10771\n",
      "Epoch: 284, Loss: 0.86199,val_Loss: 1.10768\n",
      "Epoch: 285, Loss: 0.86197,val_Loss: 1.10765\n",
      "Epoch: 286, Loss: 0.86196,val_Loss: 1.10763\n",
      "Epoch: 287, Loss: 0.86195,val_Loss: 1.10760\n",
      "Epoch: 288, Loss: 0.86194,val_Loss: 1.10757\n",
      "Epoch: 289, Loss: 0.86192,val_Loss: 1.10754\n",
      "Epoch: 290, Loss: 0.86191,val_Loss: 1.10752\n",
      "Epoch: 291, Loss: 0.86190,val_Loss: 1.10749\n",
      "Epoch: 292, Loss: 0.86189,val_Loss: 1.10747\n",
      "Epoch: 293, Loss: 0.86188,val_Loss: 1.10744\n",
      "Epoch: 294, Loss: 0.86187,val_Loss: 1.10742\n",
      "Epoch: 295, Loss: 0.86186,val_Loss: 1.10739\n",
      "Epoch: 296, Loss: 0.86185,val_Loss: 1.10737\n",
      "Epoch: 297, Loss: 0.86184,val_Loss: 1.10735\n",
      "Epoch: 298, Loss: 0.86183,val_Loss: 1.10733\n",
      "Epoch: 299, Loss: 0.86182,val_Loss: 1.10730\n",
      "Epoch: 300, Loss: 0.86181,val_Loss: 1.10728\n",
      "Epoch: 301, Loss: 0.86180,val_Loss: 1.10726\n",
      "Epoch: 302, Loss: 0.86179,val_Loss: 1.10724\n",
      "Epoch: 303, Loss: 0.86178,val_Loss: 1.10722\n",
      "Epoch: 304, Loss: 0.86177,val_Loss: 1.10720\n",
      "Epoch: 305, Loss: 0.86176,val_Loss: 1.10718\n",
      "Epoch: 306, Loss: 0.86175,val_Loss: 1.10716\n",
      "Epoch: 307, Loss: 0.86175,val_Loss: 1.10715\n",
      "Epoch: 308, Loss: 0.86174,val_Loss: 1.10713\n",
      "Epoch: 309, Loss: 0.86173,val_Loss: 1.10711\n",
      "Epoch: 310, Loss: 0.86172,val_Loss: 1.10709\n",
      "Epoch: 311, Loss: 0.86172,val_Loss: 1.10708\n",
      "Epoch: 312, Loss: 0.86171,val_Loss: 1.10706\n",
      "Epoch: 313, Loss: 0.86170,val_Loss: 1.10705\n",
      "Epoch: 314, Loss: 0.86170,val_Loss: 1.10703\n",
      "Epoch: 315, Loss: 0.86169,val_Loss: 1.10701\n",
      "Epoch: 316, Loss: 0.86168,val_Loss: 1.10700\n",
      "Epoch: 317, Loss: 0.86168,val_Loss: 1.10699\n",
      "Epoch: 318, Loss: 0.86167,val_Loss: 1.10697\n",
      "Epoch: 319, Loss: 0.86166,val_Loss: 1.10696\n",
      "Epoch: 320, Loss: 0.86166,val_Loss: 1.10694\n",
      "Epoch: 321, Loss: 0.86165,val_Loss: 1.10693\n",
      "Epoch: 322, Loss: 0.86165,val_Loss: 1.10692\n",
      "Epoch: 323, Loss: 0.86164,val_Loss: 1.10690\n",
      "Epoch: 324, Loss: 0.86164,val_Loss: 1.10689\n",
      "Epoch: 325, Loss: 0.86163,val_Loss: 1.10688\n",
      "Epoch: 326, Loss: 0.86163,val_Loss: 1.10687\n",
      "Epoch: 327, Loss: 0.86162,val_Loss: 1.10685\n",
      "Epoch: 328, Loss: 0.86162,val_Loss: 1.10684\n",
      "Epoch: 329, Loss: 0.86161,val_Loss: 1.10683\n",
      "Epoch: 330, Loss: 0.86161,val_Loss: 1.10682\n",
      "Epoch: 331, Loss: 0.86160,val_Loss: 1.10681\n",
      "Epoch: 332, Loss: 0.86160,val_Loss: 1.10680\n",
      "Epoch: 333, Loss: 0.86159,val_Loss: 1.10679\n",
      "Epoch: 334, Loss: 0.86159,val_Loss: 1.10678\n",
      "Epoch: 335, Loss: 0.86159,val_Loss: 1.10677\n",
      "Epoch: 336, Loss: 0.86158,val_Loss: 1.10676\n",
      "Epoch: 337, Loss: 0.86158,val_Loss: 1.10675\n",
      "Epoch: 338, Loss: 0.86158,val_Loss: 1.10674\n",
      "Epoch: 339, Loss: 0.86157,val_Loss: 1.10673\n",
      "Epoch: 340, Loss: 0.86157,val_Loss: 1.10672\n",
      "Epoch: 341, Loss: 0.86156,val_Loss: 1.10671\n",
      "Epoch: 342, Loss: 0.86156,val_Loss: 1.10671\n",
      "Epoch: 343, Loss: 0.86156,val_Loss: 1.10670\n",
      "Epoch: 344, Loss: 0.86155,val_Loss: 1.10669\n",
      "Epoch: 345, Loss: 0.86155,val_Loss: 1.10668\n",
      "Epoch: 346, Loss: 0.86155,val_Loss: 1.10667\n",
      "Epoch: 347, Loss: 0.86155,val_Loss: 1.10667\n",
      "Epoch: 348, Loss: 0.86154,val_Loss: 1.10666\n",
      "Epoch: 349, Loss: 0.86154,val_Loss: 1.10665\n",
      "Epoch: 350, Loss: 0.86154,val_Loss: 1.10665\n",
      "Epoch: 351, Loss: 0.86153,val_Loss: 1.10664\n",
      "Epoch: 352, Loss: 0.86153,val_Loss: 1.10663\n",
      "Epoch: 353, Loss: 0.86153,val_Loss: 1.10663\n",
      "Epoch: 354, Loss: 0.86153,val_Loss: 1.10662\n",
      "Epoch: 355, Loss: 0.86152,val_Loss: 1.10661\n",
      "Epoch: 356, Loss: 0.86152,val_Loss: 1.10661\n",
      "Epoch: 357, Loss: 0.86152,val_Loss: 1.10660\n",
      "Epoch: 358, Loss: 0.86152,val_Loss: 1.10659\n",
      "Epoch: 359, Loss: 0.86152,val_Loss: 1.10659\n",
      "Epoch: 360, Loss: 0.86151,val_Loss: 1.10658\n",
      "Epoch: 361, Loss: 0.86151,val_Loss: 1.10658\n",
      "Epoch: 362, Loss: 0.86151,val_Loss: 1.10657\n",
      "Epoch: 363, Loss: 0.86151,val_Loss: 1.10657\n",
      "Epoch: 364, Loss: 0.86151,val_Loss: 1.10656\n",
      "Epoch: 365, Loss: 0.86150,val_Loss: 1.10656\n",
      "Epoch: 366, Loss: 0.86150,val_Loss: 1.10655\n",
      "Epoch: 367, Loss: 0.86150,val_Loss: 1.10655\n",
      "Epoch: 368, Loss: 0.86150,val_Loss: 1.10654\n",
      "Epoch: 369, Loss: 0.86150,val_Loss: 1.10654\n",
      "Epoch: 370, Loss: 0.86150,val_Loss: 1.10653\n",
      "Epoch: 371, Loss: 0.86149,val_Loss: 1.10653\n",
      "Epoch: 372, Loss: 0.86149,val_Loss: 1.10652\n",
      "Epoch: 373, Loss: 0.86149,val_Loss: 1.10652\n",
      "Epoch: 374, Loss: 0.86149,val_Loss: 1.10652\n",
      "Epoch: 375, Loss: 0.86149,val_Loss: 1.10651\n",
      "Epoch: 376, Loss: 0.86149,val_Loss: 1.10651\n",
      "Epoch: 377, Loss: 0.86149,val_Loss: 1.10650\n",
      "Epoch: 378, Loss: 0.86148,val_Loss: 1.10650\n",
      "Epoch: 379, Loss: 0.86148,val_Loss: 1.10650\n",
      "Epoch: 380, Loss: 0.86148,val_Loss: 1.10649\n",
      "Epoch: 381, Loss: 0.86148,val_Loss: 1.10649\n",
      "Epoch: 382, Loss: 0.86148,val_Loss: 1.10649\n",
      "Epoch: 383, Loss: 0.86148,val_Loss: 1.10648\n",
      "Epoch: 384, Loss: 0.86148,val_Loss: 1.10648\n",
      "Epoch: 385, Loss: 0.86148,val_Loss: 1.10648\n",
      "Epoch: 386, Loss: 0.86148,val_Loss: 1.10647\n",
      "Epoch: 387, Loss: 0.86147,val_Loss: 1.10647\n",
      "Epoch: 388, Loss: 0.86147,val_Loss: 1.10647\n",
      "Epoch: 389, Loss: 0.86147,val_Loss: 1.10646\n",
      "Epoch: 390, Loss: 0.86147,val_Loss: 1.10646\n",
      "Epoch: 391, Loss: 0.86147,val_Loss: 1.10646\n",
      "Epoch: 392, Loss: 0.86147,val_Loss: 1.10645\n",
      "Epoch: 393, Loss: 0.86147,val_Loss: 1.10645\n",
      "Epoch: 394, Loss: 0.86147,val_Loss: 1.10645\n",
      "Epoch: 395, Loss: 0.86147,val_Loss: 1.10645\n",
      "Epoch: 396, Loss: 0.86147,val_Loss: 1.10644\n",
      "Epoch: 397, Loss: 0.86147,val_Loss: 1.10644\n",
      "Epoch: 398, Loss: 0.86146,val_Loss: 1.10644\n",
      "Epoch: 399, Loss: 0.86146,val_Loss: 1.10644\n",
      "Epoch: 400, Loss: 0.86146,val_Loss: 1.10643\n",
      "Epoch: 401, Loss: 0.86146,val_Loss: 1.10643\n",
      "Epoch: 402, Loss: 0.86146,val_Loss: 1.10643\n",
      "Epoch: 403, Loss: 0.86146,val_Loss: 1.10643\n",
      "Epoch: 404, Loss: 0.86146,val_Loss: 1.10643\n",
      "Epoch: 405, Loss: 0.86146,val_Loss: 1.10642\n",
      "Epoch: 406, Loss: 0.86146,val_Loss: 1.10642\n",
      "Epoch: 407, Loss: 0.86146,val_Loss: 1.10642\n",
      "Epoch: 408, Loss: 0.86146,val_Loss: 1.10642\n",
      "Epoch: 409, Loss: 0.86146,val_Loss: 1.10642\n",
      "Epoch: 410, Loss: 0.86146,val_Loss: 1.10641\n",
      "Epoch: 411, Loss: 0.86146,val_Loss: 1.10641\n",
      "Epoch: 412, Loss: 0.86146,val_Loss: 1.10641\n",
      "Epoch: 413, Loss: 0.86146,val_Loss: 1.10641\n",
      "Epoch: 414, Loss: 0.86146,val_Loss: 1.10641\n",
      "Epoch: 415, Loss: 0.86146,val_Loss: 1.10640\n",
      "Epoch: 416, Loss: 0.86145,val_Loss: 1.10640\n",
      "Epoch: 417, Loss: 0.86145,val_Loss: 1.10640\n",
      "Epoch: 418, Loss: 0.86145,val_Loss: 1.10640\n",
      "Epoch: 419, Loss: 0.86145,val_Loss: 1.10640\n",
      "Epoch: 420, Loss: 0.86145,val_Loss: 1.10640\n",
      "Epoch: 421, Loss: 0.86145,val_Loss: 1.10639\n",
      "Epoch: 422, Loss: 0.86145,val_Loss: 1.10639\n",
      "Epoch: 423, Loss: 0.86145,val_Loss: 1.10639\n",
      "Epoch: 424, Loss: 0.86145,val_Loss: 1.10639\n",
      "Epoch: 425, Loss: 0.86145,val_Loss: 1.10639\n",
      "Epoch: 426, Loss: 0.86145,val_Loss: 1.10639\n",
      "Epoch: 427, Loss: 0.86145,val_Loss: 1.10639\n",
      "Epoch: 428, Loss: 0.86145,val_Loss: 1.10639\n",
      "Epoch: 429, Loss: 0.86145,val_Loss: 1.10638\n",
      "Epoch: 430, Loss: 0.86145,val_Loss: 1.10638\n",
      "Epoch: 431, Loss: 0.86145,val_Loss: 1.10638\n",
      "Epoch: 432, Loss: 0.86145,val_Loss: 1.10638\n",
      "Epoch: 433, Loss: 0.86145,val_Loss: 1.10638\n",
      "Epoch: 434, Loss: 0.86145,val_Loss: 1.10638\n",
      "Epoch: 435, Loss: 0.86145,val_Loss: 1.10638\n",
      "Epoch: 436, Loss: 0.86145,val_Loss: 1.10638\n",
      "Epoch: 437, Loss: 0.86145,val_Loss: 1.10637\n",
      "Epoch: 438, Loss: 0.86145,val_Loss: 1.10637\n",
      "Epoch: 439, Loss: 0.86145,val_Loss: 1.10637\n",
      "Epoch: 440, Loss: 0.86145,val_Loss: 1.10637\n",
      "Epoch: 441, Loss: 0.86145,val_Loss: 1.10637\n",
      "Epoch: 442, Loss: 0.86145,val_Loss: 1.10637\n",
      "Epoch: 443, Loss: 0.86145,val_Loss: 1.10637\n",
      "Epoch: 444, Loss: 0.86145,val_Loss: 1.10637\n",
      "Epoch: 445, Loss: 0.86145,val_Loss: 1.10637\n",
      "Epoch: 446, Loss: 0.86145,val_Loss: 1.10637\n",
      "Epoch: 447, Loss: 0.86145,val_Loss: 1.10637\n",
      "Epoch: 448, Loss: 0.86145,val_Loss: 1.10636\n",
      "Epoch: 449, Loss: 0.86145,val_Loss: 1.10636\n",
      "Epoch: 450, Loss: 0.86145,val_Loss: 1.10636\n",
      "Epoch: 451, Loss: 0.86145,val_Loss: 1.10636\n",
      "Epoch: 452, Loss: 0.86145,val_Loss: 1.10636\n",
      "Epoch: 453, Loss: 0.86145,val_Loss: 1.10636\n",
      "Epoch: 454, Loss: 0.86144,val_Loss: 1.10636\n",
      "Epoch: 455, Loss: 0.86144,val_Loss: 1.10636\n",
      "Epoch: 456, Loss: 0.86144,val_Loss: 1.10636\n",
      "Epoch: 457, Loss: 0.86144,val_Loss: 1.10636\n",
      "Epoch: 458, Loss: 0.86144,val_Loss: 1.10636\n",
      "Epoch: 459, Loss: 0.86144,val_Loss: 1.10636\n",
      "Epoch: 460, Loss: 0.86144,val_Loss: 1.10636\n",
      "Epoch: 461, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 462, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 463, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 464, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 465, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 466, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 467, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 468, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 469, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 470, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 471, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 472, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 473, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 474, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 475, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 476, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 477, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 478, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 479, Loss: 0.86144,val_Loss: 1.10635\n",
      "Epoch: 480, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 481, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 482, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 483, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 484, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 485, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 486, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 487, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 488, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 489, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 490, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 491, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 492, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 493, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 494, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 495, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 496, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 497, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 498, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 499, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 500, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 501, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 502, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 503, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 504, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 505, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 506, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 507, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 508, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 509, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 510, Loss: 0.86144,val_Loss: 1.10634\n",
      "Epoch: 511, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 512, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 513, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 514, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 515, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 516, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 517, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 518, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 519, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 520, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 521, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 522, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 523, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 524, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 525, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 526, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 527, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 528, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 529, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 530, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 531, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 532, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 533, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 534, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 535, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 536, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 537, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 538, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 539, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 540, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 541, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 542, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 543, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 544, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 545, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 546, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 547, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 548, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 549, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 550, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 551, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 552, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 553, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 554, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 555, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 556, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 557, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 558, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 559, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 560, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 561, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 562, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 563, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 564, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 565, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 566, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 567, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 568, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 569, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 570, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 571, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 572, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 573, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 574, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 575, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 576, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 577, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 578, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 579, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 580, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 581, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 582, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 583, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 584, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 585, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 586, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 587, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 588, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 589, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 590, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 591, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 592, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 593, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 594, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 595, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 596, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 597, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 598, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 599, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 600, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 601, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 602, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 603, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 604, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 605, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 606, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 607, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 608, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 609, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 610, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 611, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 612, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 613, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 614, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 615, Loss: 0.86144,val_Loss: 1.10633\n",
      "Epoch: 616, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 617, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 618, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 619, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 620, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 621, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 622, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 623, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 624, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 625, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 626, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 627, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 628, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 629, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 630, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 631, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 632, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 633, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 634, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 635, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 636, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 637, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 638, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 639, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 640, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 641, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 642, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 643, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 644, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 645, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 646, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 647, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 648, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 649, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 650, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 651, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 652, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 653, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 654, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 655, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 656, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 657, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 658, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 659, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 660, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 661, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 662, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 663, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 664, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 665, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 666, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 667, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 668, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 669, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 670, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 671, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 672, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 673, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 674, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 675, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 676, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 677, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 678, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 679, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 680, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 681, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 682, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 683, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 684, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 685, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 686, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 687, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 688, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 689, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 690, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 691, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 692, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 693, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 694, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 695, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 696, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 697, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 698, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 699, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 700, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 701, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 702, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 703, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 704, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 705, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 706, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 707, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 708, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 709, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 710, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 711, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 712, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 713, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 714, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 715, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 716, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 717, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 718, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 719, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 720, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 721, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 722, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 723, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 724, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 725, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 726, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 727, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 728, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 729, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 730, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 731, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 732, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 733, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 734, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 735, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 736, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 737, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 738, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 739, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 740, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 741, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 742, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 743, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 744, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 745, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 746, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 747, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 748, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 749, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 750, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 751, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 752, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 753, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 754, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 755, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 756, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 757, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 758, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 759, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 760, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 761, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 762, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 763, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 764, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 765, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 766, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 767, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 768, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 769, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 770, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 771, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 772, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 773, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 774, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 775, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 776, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 777, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 778, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 779, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 780, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 781, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 782, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 783, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 784, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 785, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 786, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 787, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 788, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 789, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 790, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 791, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 792, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 793, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 794, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 795, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 796, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 797, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 798, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 799, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 800, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 801, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 802, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 803, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 804, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 805, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 806, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 807, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 808, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 809, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 810, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 811, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 812, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 813, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 814, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 815, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 816, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 817, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 818, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 819, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 820, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 821, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 822, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 823, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 824, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 825, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 826, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 827, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 828, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 829, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 830, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 831, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 832, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 833, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 834, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 835, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 836, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 837, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 838, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 839, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 840, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 841, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 842, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 843, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 844, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 845, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 846, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 847, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 848, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 849, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 850, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 851, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 852, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 853, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 854, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 855, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 856, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 857, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 858, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 859, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 860, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 861, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 862, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 863, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 864, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 865, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 866, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 867, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 868, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 869, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 870, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 871, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 872, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 873, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 874, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 875, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 876, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 877, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 878, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 879, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 880, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 881, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 882, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 883, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 884, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 885, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 886, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 887, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 888, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 889, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 890, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 891, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 892, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 893, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 894, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 895, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 896, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 897, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 898, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 899, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 900, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 901, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 902, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 903, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 904, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 905, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 906, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 907, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 908, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 909, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 910, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 911, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 912, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 913, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 914, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 915, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 916, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 917, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 918, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 919, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 920, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 921, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 922, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 923, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 924, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 925, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 926, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 927, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 928, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 929, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 930, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 931, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 932, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 933, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 934, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 935, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 936, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 937, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 938, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 939, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 940, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 941, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 942, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 943, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 944, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 945, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 946, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 947, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 948, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 949, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 950, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 951, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 952, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 953, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 954, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 955, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 956, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 957, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 958, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 959, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 960, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 961, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 962, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 963, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 964, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 965, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 966, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 967, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 968, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 969, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 970, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 971, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 972, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 973, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 974, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 975, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 976, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 977, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 978, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 979, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 980, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 981, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 982, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 983, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 984, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 985, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 986, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 987, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 988, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 989, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 990, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 991, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 992, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 993, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 994, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 995, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 996, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 997, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 998, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 999, Loss: 0.86144,val_Loss: 1.10632\n",
      "Epoch: 1000, Loss: 0.86144,val_Loss: 1.10632\n",
      "test_Loss: 1.17563\n"
     ]
    }
   ],
   "source": [
    "model=FFN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for i in range(num_epochs):\n",
    "    output=model(train_x.to(device))\n",
    "    loss=criterion(output,train_y.to(device))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    val_out=model(val_x.to(device))\n",
    "    val_loss=criterion(val_out,val_y.to(device))\n",
    "    print('Epoch: {}, Loss: {:.5f},val_Loss: {:.5f}'.format(i+1, loss,val_loss))\n",
    "\n",
    "test_out=model(test_x.to(device))\n",
    "test_loss=criterion(test_out,test_y.to(device))\n",
    "print('test_Loss: {:.5f}'.format(test_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}