{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "#data_csv = pd.read_csv('C:\\\\Users\\\\86134\\\\Desktop\\\\temp.csv', header=None,usecols=[1])\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class lstm_reg(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1, num_layers=2):\n",
    "        super(lstm_reg, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers)  # rnn\n",
    "        self.reg = nn.Linear(hidden_size, output_size)  # 回归\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)  # (seq, batch, hidden)\n",
    "        s, b, h = x.shape\n",
    "        x = x.view(s * b, h)  # 转换成线性层的输入格式\n",
    "        x = self.reg(x)\n",
    "        x = x.view(s, b, -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def standardization(data):\n",
    "    mu = np.mean(data, axis=0)\n",
    "    sigma = np.std(data, axis=0)\n",
    "    return (data - mu) / sigma\n",
    "\n",
    "def normalization(data):\n",
    "    _range = np.max(data) - np.min(data)\n",
    "    return (data - np.min(data)) / _range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1522, 433)\n"
     ]
    }
   ],
   "source": [
    "data_csv=pd.read_csv(\"industry_ret_data_1500.csv\").set_index(\"Date\")\n",
    "dataset = data_csv.values\n",
    "dataset = dataset.astype('float32')\n",
    "#dataset=normalization(dataset)\n",
    "dataset=standardization(dataset)\n",
    "print(dataset.shape)\n",
    "def create_dataset(dataset, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i + look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output_size=1\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 3, 2, 0.1), (3, 3, 2, 0.01), (3, 3, 2, 0.005), (3, 3, 2, 0.001), (3, 3, 3, 0.1), (3, 3, 3, 0.01), (3, 3, 3, 0.005), (3, 3, 3, 0.001), (3, 3, 4, 0.1), (3, 3, 4, 0.01), (3, 3, 4, 0.005), (3, 3, 4, 0.001), (3, 4, 2, 0.1), (3, 4, 2, 0.01), (3, 4, 2, 0.005), (3, 4, 2, 0.001), (3, 4, 3, 0.1), (3, 4, 3, 0.01), (3, 4, 3, 0.005), (3, 4, 3, 0.001), (3, 4, 4, 0.1), (3, 4, 4, 0.01), (3, 4, 4, 0.005), (3, 4, 4, 0.001), (3, 6, 2, 0.1), (3, 6, 2, 0.01), (3, 6, 2, 0.005), (3, 6, 2, 0.001), (3, 6, 3, 0.1), (3, 6, 3, 0.01), (3, 6, 3, 0.005), (3, 6, 3, 0.001), (3, 6, 4, 0.1), (3, 6, 4, 0.01), (3, 6, 4, 0.005), (3, 6, 4, 0.001), (4, 3, 2, 0.1), (4, 3, 2, 0.01), (4, 3, 2, 0.005), (4, 3, 2, 0.001), (4, 3, 3, 0.1), (4, 3, 3, 0.01), (4, 3, 3, 0.005), (4, 3, 3, 0.001), (4, 3, 4, 0.1), (4, 3, 4, 0.01), (4, 3, 4, 0.005), (4, 3, 4, 0.001), (4, 4, 2, 0.1), (4, 4, 2, 0.01), (4, 4, 2, 0.005), (4, 4, 2, 0.001), (4, 4, 3, 0.1), (4, 4, 3, 0.01), (4, 4, 3, 0.005), (4, 4, 3, 0.001), (4, 4, 4, 0.1), (4, 4, 4, 0.01), (4, 4, 4, 0.005), (4, 4, 4, 0.001), (4, 6, 2, 0.1), (4, 6, 2, 0.01), (4, 6, 2, 0.005), (4, 6, 2, 0.001), (4, 6, 3, 0.1), (4, 6, 3, 0.01), (4, 6, 3, 0.005), (4, 6, 3, 0.001), (4, 6, 4, 0.1), (4, 6, 4, 0.01), (4, 6, 4, 0.005), (4, 6, 4, 0.001), (6, 3, 2, 0.1), (6, 3, 2, 0.01), (6, 3, 2, 0.005), (6, 3, 2, 0.001), (6, 3, 3, 0.1), (6, 3, 3, 0.01), (6, 3, 3, 0.005), (6, 3, 3, 0.001), (6, 3, 4, 0.1), (6, 3, 4, 0.01), (6, 3, 4, 0.005), (6, 3, 4, 0.001), (6, 4, 2, 0.1), (6, 4, 2, 0.01), (6, 4, 2, 0.005), (6, 4, 2, 0.001), (6, 4, 3, 0.1), (6, 4, 3, 0.01), (6, 4, 3, 0.005), (6, 4, 3, 0.001), (6, 4, 4, 0.1), (6, 4, 4, 0.01), (6, 4, 4, 0.005), (6, 4, 4, 0.001), (6, 6, 2, 0.1), (6, 6, 2, 0.01), (6, 6, 2, 0.005), (6, 6, 2, 0.001), (6, 6, 3, 0.1), (6, 6, 3, 0.01), (6, 6, 3, 0.005), (6, 6, 3, 0.001), (6, 6, 4, 0.1), (6, 6, 4, 0.01), (6, 6, 4, 0.005), (6, 6, 4, 0.001)]\n"
     ]
    }
   ],
   "source": [
    "parameters=dict(\n",
    "    input_size=[3,4,6],\n",
    "    hidden_size=[3,4,6],\n",
    "    num_layers=[2,3,4],\n",
    "    l_rate=[0.1,0.01,0.005,0.001]\n",
    ")\n",
    "param_values=[v for v in parameters.values()]\n",
    "param=list(product(*param_values))\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(input_size,hidden_size,num_layers,l_rate,output_size=1,epochs=10):\n",
    "    net = lstm_reg(input_size,hidden_size,output_size,num_layers)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=l_rate)\n",
    "    data_X, data_Y = create_dataset(dataset,input_size)\n",
    "\n",
    "    train_X = data_X[:1000]\n",
    "    train_Y = data_Y[:1000]\n",
    "    val_X=data_X[1000:1200]\n",
    "    val_Y=data_Y[1000:1200]\n",
    "    test_X = data_X[1200:]\n",
    "    test_Y = data_Y[1200:]\n",
    "\n",
    "    train_X = train_X.reshape(-1, 433, input_size)\n",
    "    train_Y = train_Y.reshape(-1, 433, 1)\n",
    "    test_X = test_X.reshape(-1, 433, input_size)\n",
    "    test_Y=test_Y.reshape(-1,433,1)\n",
    "    val_X = val_X.reshape(-1, 433, input_size)\n",
    "    val_Y = val_Y.reshape(-1, 433, 1)\n",
    "\n",
    "    train_x = torch.from_numpy(train_X)\n",
    "    train_y = torch.from_numpy(train_Y)\n",
    "    test_x = torch.from_numpy(test_X)\n",
    "    test_y=torch.from_numpy(test_Y)\n",
    "    val_x=torch.from_numpy(val_X)\n",
    "    val_y = torch.from_numpy(val_Y)\n",
    "    #print((train_x.shape))\n",
    "    tr_loss=[]\n",
    "    val_loss=[]\n",
    "    for e in range(epochs):\n",
    "        var_x = Variable(train_x)\n",
    "        var_y = Variable(train_y)\n",
    "        valx=Variable(val_x)\n",
    "        valy=Variable(val_y)\n",
    "\n",
    "        # 前向传播\n",
    "        out = net(var_x)\n",
    "        val_out=net(valx)\n",
    "        loss = criterion(out, var_y)\n",
    "        v_loss=criterion(val_out, valy)\n",
    "        tr_loss.append(loss)\n",
    "        val_loss.append(v_loss)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        #cor.backward()\n",
    "        optimizer.step()\n",
    "        #print('Epoch: {}, Loss: {:.5f},val_Loss: {:.5f},cor:{},v_cor:{}'.format(e + 1, loss.data,v_loss,cor,V_cor))\n",
    "\n",
    "    net = net.eval() # 转换成测试模式\n",
    "\n",
    "    test_data = Variable(test_x)\n",
    "    test_tar = Variable(test_y)\n",
    "    pred_test = net(test_data) # 测试集的预测结果\n",
    "    test_loss=criterion(pred_test,test_tar)\n",
    "    print('ave_val_Loss: {:.5f},test_loss:{:.5f}'.format(sum(val_loss)/len(val_loss),test_loss) )\n",
    "    return sum(val_loss)/len(val_loss),test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_para=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size,hidden_size,num_layers,l_rate: 3 3 2 0.1\n",
      "ave_val_Loss: 1.23825,test_loss:1.16434\n",
      "input_size,hidden_size,num_layers,l_rate: 3 3 2 0.01\n",
      "ave_val_Loss: 1.36296,test_loss:1.19176\n",
      "input_size,hidden_size,num_layers,l_rate: 3 3 2 0.005\n",
      "ave_val_Loss: 1.23331,test_loss:1.16454\n",
      "input_size,hidden_size,num_layers,l_rate: 3 3 2 0.001\n",
      "ave_val_Loss: 1.39799,test_loss:1.34428\n",
      "input_size,hidden_size,num_layers,l_rate: 3 3 3 0.1\n",
      "ave_val_Loss: 1.26440,test_loss:1.16364\n",
      "input_size,hidden_size,num_layers,l_rate: 3 3 3 0.01\n",
      "ave_val_Loss: 1.27111,test_loss:1.16686\n",
      "input_size,hidden_size,num_layers,l_rate: 3 3 3 0.005\n",
      "ave_val_Loss: 1.47617,test_loss:1.32589\n",
      "input_size,hidden_size,num_layers,l_rate: 3 3 3 0.001\n",
      "ave_val_Loss: 1.59762,test_loss:1.54151\n",
      "input_size,hidden_size,num_layers,l_rate: 3 3 4 0.1\n",
      "ave_val_Loss: 1.28589,test_loss:1.17763\n",
      "input_size,hidden_size,num_layers,l_rate: 3 3 4 0.01\n",
      "ave_val_Loss: 1.24578,test_loss:1.16541\n",
      "input_size,hidden_size,num_layers,l_rate: 3 3 4 0.005\n",
      "ave_val_Loss: 1.25546,test_loss:1.17654\n",
      "input_size,hidden_size,num_layers,l_rate: 3 3 4 0.001\n",
      "ave_val_Loss: 1.35925,test_loss:1.30203\n",
      "input_size,hidden_size,num_layers,l_rate: 3 4 2 0.1\n",
      "ave_val_Loss: 1.24205,test_loss:1.16500\n",
      "input_size,hidden_size,num_layers,l_rate: 3 4 2 0.01\n",
      "ave_val_Loss: 1.33227,test_loss:1.17448\n",
      "input_size,hidden_size,num_layers,l_rate: 3 4 2 0.005\n",
      "ave_val_Loss: 1.30169,test_loss:1.21265\n",
      "input_size,hidden_size,num_layers,l_rate: 3 4 2 0.001\n",
      "ave_val_Loss: 1.26015,test_loss:1.17462\n",
      "input_size,hidden_size,num_layers,l_rate: 3 4 3 0.1\n",
      "ave_val_Loss: 1.23979,test_loss:1.16688\n",
      "input_size,hidden_size,num_layers,l_rate: 3 4 3 0.01\n",
      "ave_val_Loss: 1.23883,test_loss:1.16408\n",
      "input_size,hidden_size,num_layers,l_rate: 3 4 3 0.005\n",
      "ave_val_Loss: 1.28229,test_loss:1.16727\n",
      "input_size,hidden_size,num_layers,l_rate: 3 4 3 0.001\n",
      "ave_val_Loss: 1.47445,test_loss:1.41514\n",
      "input_size,hidden_size,num_layers,l_rate: 3 4 4 0.1\n",
      "ave_val_Loss: 1.26299,test_loss:1.18651\n",
      "input_size,hidden_size,num_layers,l_rate: 3 4 4 0.01\n",
      "ave_val_Loss: 1.46017,test_loss:1.23003\n",
      "input_size,hidden_size,num_layers,l_rate: 3 4 4 0.005\n",
      "ave_val_Loss: 1.26653,test_loss:1.16969\n",
      "input_size,hidden_size,num_layers,l_rate: 3 4 4 0.001\n",
      "ave_val_Loss: 1.59946,test_loss:1.47247\n",
      "input_size,hidden_size,num_layers,l_rate: 3 6 2 0.1\n",
      "ave_val_Loss: 1.25116,test_loss:1.16372\n",
      "input_size,hidden_size,num_layers,l_rate: 3 6 2 0.01\n",
      "ave_val_Loss: 1.24030,test_loss:1.16684\n",
      "input_size,hidden_size,num_layers,l_rate: 3 6 2 0.005\n",
      "ave_val_Loss: 1.24314,test_loss:1.16422\n",
      "input_size,hidden_size,num_layers,l_rate: 3 6 2 0.001\n",
      "ave_val_Loss: 1.27927,test_loss:1.21772\n",
      "input_size,hidden_size,num_layers,l_rate: 3 6 3 0.1\n",
      "ave_val_Loss: 1.27476,test_loss:1.16347\n",
      "input_size,hidden_size,num_layers,l_rate: 3 6 3 0.01\n",
      "ave_val_Loss: 1.23425,test_loss:1.16317\n",
      "input_size,hidden_size,num_layers,l_rate: 3 6 3 0.005\n",
      "ave_val_Loss: 1.23510,test_loss:1.16330\n",
      "input_size,hidden_size,num_layers,l_rate: 3 6 3 0.001\n",
      "ave_val_Loss: 1.23969,test_loss:1.16433\n"
     ]
    }
   ],
   "source": [
    "for input_size,hidden_size,num_layers,l_rate in param[0:32]:\n",
    "    if input_size<=hidden_size:\n",
    "        print(\"input_size,hidden_size,num_layers,l_rate:\",input_size,hidden_size,num_layers,l_rate)\n",
    "        varl,testl=train_model(input_size,hidden_size,num_layers,l_rate)\n",
    "        total_para.append((varl,testl,input_size,hidden_size,num_layers,l_rate))\n",
    "    else:\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size,hidden_size,num_layers,l_rate: 3 6 4 0.1\n",
      "ave_val_Loss: 1.26090,test_loss:1.16354\n",
      "input_size,hidden_size,num_layers,l_rate: 3 6 4 0.01\n",
      "ave_val_Loss: 1.23342,test_loss:1.16325\n",
      "input_size,hidden_size,num_layers,l_rate: 3 6 4 0.005\n",
      "ave_val_Loss: 1.23348,test_loss:1.16644\n",
      "input_size,hidden_size,num_layers,l_rate: 3 6 4 0.001\n",
      "ave_val_Loss: 1.23217,test_loss:1.16326\n",
      "input_size,hidden_size,num_layers,l_rate: 4 4 2 0.1\n",
      "ave_val_Loss: 1.23178,test_loss:1.16563\n",
      "input_size,hidden_size,num_layers,l_rate: 4 4 2 0.01\n",
      "ave_val_Loss: 1.23110,test_loss:1.16925\n",
      "input_size,hidden_size,num_layers,l_rate: 4 4 2 0.005\n",
      "ave_val_Loss: 1.52881,test_loss:1.39247\n",
      "input_size,hidden_size,num_layers,l_rate: 4 4 2 0.001\n",
      "ave_val_Loss: 1.35348,test_loss:1.30358\n",
      "input_size,hidden_size,num_layers,l_rate: 4 4 3 0.1\n",
      "ave_val_Loss: 1.23769,test_loss:1.16646\n",
      "input_size,hidden_size,num_layers,l_rate: 4 4 3 0.01\n",
      "ave_val_Loss: 1.31355,test_loss:1.17009\n",
      "input_size,hidden_size,num_layers,l_rate: 4 4 3 0.005\n",
      "ave_val_Loss: 1.25432,test_loss:1.16878\n",
      "input_size,hidden_size,num_layers,l_rate: 4 4 3 0.001\n",
      "ave_val_Loss: 1.24357,test_loss:1.18418\n",
      "input_size,hidden_size,num_layers,l_rate: 4 4 4 0.1\n",
      "ave_val_Loss: 1.27434,test_loss:1.16647\n",
      "input_size,hidden_size,num_layers,l_rate: 4 4 4 0.01\n",
      "ave_val_Loss: 1.25809,test_loss:1.16974\n",
      "input_size,hidden_size,num_layers,l_rate: 4 4 4 0.005\n",
      "ave_val_Loss: 1.22769,test_loss:1.16666\n",
      "input_size,hidden_size,num_layers,l_rate: 4 4 4 0.001\n",
      "ave_val_Loss: 1.22670,test_loss:1.16646\n",
      "input_size,hidden_size,num_layers,l_rate: 4 6 2 0.1\n",
      "ave_val_Loss: 1.25840,test_loss:1.16296\n",
      "input_size,hidden_size,num_layers,l_rate: 4 6 2 0.01\n",
      "ave_val_Loss: 1.23796,test_loss:1.16519\n",
      "input_size,hidden_size,num_layers,l_rate: 4 6 2 0.005\n",
      "ave_val_Loss: 1.22685,test_loss:1.16315\n",
      "input_size,hidden_size,num_layers,l_rate: 4 6 2 0.001\n",
      "ave_val_Loss: 1.27257,test_loss:1.18802\n"
     ]
    }
   ],
   "source": [
    "for input_size,hidden_size,num_layers,l_rate in param[32:64]:\n",
    "    if input_size<=hidden_size:\n",
    "        print(\"input_size,hidden_size,num_layers,l_rate:\",input_size,hidden_size,num_layers,l_rate)\n",
    "        varl,testl=train_model(input_size,hidden_size,num_layers,l_rate)\n",
    "        total_para.append((varl,testl,input_size,hidden_size,num_layers,l_rate))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size,hidden_size,num_layers,l_rate: 4 6 3 0.1\n",
      "ave_val_Loss: 1.24604,test_loss:1.16594\n",
      "input_size,hidden_size,num_layers,l_rate: 4 6 3 0.01\n",
      "ave_val_Loss: 1.23277,test_loss:1.16690\n",
      "input_size,hidden_size,num_layers,l_rate: 4 6 3 0.005\n",
      "ave_val_Loss: 1.22815,test_loss:1.16537\n",
      "input_size,hidden_size,num_layers,l_rate: 4 6 3 0.001\n",
      "ave_val_Loss: 1.23737,test_loss:1.16845\n",
      "input_size,hidden_size,num_layers,l_rate: 4 6 4 0.1\n",
      "ave_val_Loss: 1.23418,test_loss:1.16594\n",
      "input_size,hidden_size,num_layers,l_rate: 4 6 4 0.01\n",
      "ave_val_Loss: 1.23896,test_loss:1.17453\n",
      "input_size,hidden_size,num_layers,l_rate: 4 6 4 0.005\n",
      "ave_val_Loss: 1.22841,test_loss:1.16491\n",
      "input_size,hidden_size,num_layers,l_rate: 4 6 4 0.001\n",
      "ave_val_Loss: 1.27420,test_loss:1.18979\n"
     ]
    }
   ],
   "source": [
    "for input_size,hidden_size,num_layers,l_rate in param[64:96]:\n",
    "    if input_size<=hidden_size:\n",
    "        print(\"input_size,hidden_size,num_layers,l_rate:\",input_size,hidden_size,num_layers,l_rate)\n",
    "        varl,testl=train_model(input_size,hidden_size,num_layers,l_rate)\n",
    "        total_para.append((varl,testl,input_size,hidden_size,num_layers,l_rate))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size,hidden_size,num_layers,l_rate: 6 6 2 0.1\n",
      "ave_val_Loss: 1.23054,test_loss:1.16841\n",
      "input_size,hidden_size,num_layers,l_rate: 6 6 2 0.01\n",
      "ave_val_Loss: 1.23068,test_loss:1.17045\n",
      "input_size,hidden_size,num_layers,l_rate: 6 6 2 0.005\n",
      "ave_val_Loss: 1.22361,test_loss:1.16771\n",
      "input_size,hidden_size,num_layers,l_rate: 6 6 2 0.001\n",
      "ave_val_Loss: 1.23345,test_loss:1.17861\n",
      "input_size,hidden_size,num_layers,l_rate: 6 6 3 0.1\n",
      "ave_val_Loss: 1.23159,test_loss:1.16989\n",
      "input_size,hidden_size,num_layers,l_rate: 6 6 3 0.01\n",
      "ave_val_Loss: 1.22684,test_loss:1.16843\n",
      "input_size,hidden_size,num_layers,l_rate: 6 6 3 0.005\n",
      "ave_val_Loss: 1.22557,test_loss:1.16835\n",
      "input_size,hidden_size,num_layers,l_rate: 6 6 3 0.001\n",
      "ave_val_Loss: 1.34574,test_loss:1.28509\n",
      "input_size,hidden_size,num_layers,l_rate: 6 6 4 0.1\n",
      "ave_val_Loss: 1.25026,test_loss:1.16816\n",
      "input_size,hidden_size,num_layers,l_rate: 6 6 4 0.01\n",
      "ave_val_Loss: 1.22420,test_loss:1.16852\n",
      "input_size,hidden_size,num_layers,l_rate: 6 6 4 0.005\n",
      "ave_val_Loss: 1.22881,test_loss:1.16917\n",
      "input_size,hidden_size,num_layers,l_rate: 6 6 4 0.001\n",
      "ave_val_Loss: 1.25757,test_loss:1.19503\n"
     ]
    }
   ],
   "source": [
    "for input_size,hidden_size,num_layers,l_rate in param[96:]:\n",
    "    if input_size<=hidden_size:\n",
    "        print(\"input_size,hidden_size,num_layers,l_rate:\",input_size,hidden_size,num_layers,l_rate)\n",
    "        varl,testl=train_model(input_size,hidden_size,num_layers,l_rate)\n",
    "        total_para.append((varl,testl,input_size,hidden_size,num_layers,l_rate))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for input_size,hidden_size,num_layers,l_rate in param[128:160]:\n",
    "    if input_size<=hidden_size:\n",
    "        print(\"input_size,hidden_size,num_layers,l_rate:\",input_size,hidden_size,num_layers,l_rate)\n",
    "        varl,testl=train_model(input_size,hidden_size,num_layers,l_rate)\n",
    "        total_para.append((varl,testl,input_size,hidden_size,num_layers,l_rate))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for input_size,hidden_size,num_layers,l_rate in param[160:]:\n",
    "    if input_size<=hidden_size:\n",
    "        print(\"input_size,hidden_size,num_layers,l_rate:\",input_size,hidden_size,num_layers,l_rate)\n",
    "        varl,testl=train_model(input_size,hidden_size,num_layers,l_rate)\n",
    "        total_para.append((varl,testl,input_size,hidden_size,num_layers,l_rate))\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2383e+00, 1.1643e+00, 3.0000e+00, 3.0000e+00, 2.0000e+00, 1.0000e-01],\n",
      "        [1.3630e+00, 1.1918e+00, 3.0000e+00, 3.0000e+00, 2.0000e+00, 1.0000e-02],\n",
      "        [1.2333e+00, 1.1645e+00, 3.0000e+00, 3.0000e+00, 2.0000e+00, 5.0000e-03],\n",
      "        [1.3980e+00, 1.3443e+00, 3.0000e+00, 3.0000e+00, 2.0000e+00, 1.0000e-03],\n",
      "        [1.2644e+00, 1.1636e+00, 3.0000e+00, 3.0000e+00, 3.0000e+00, 1.0000e-01],\n",
      "        [1.2711e+00, 1.1669e+00, 3.0000e+00, 3.0000e+00, 3.0000e+00, 1.0000e-02],\n",
      "        [1.4762e+00, 1.3259e+00, 3.0000e+00, 3.0000e+00, 3.0000e+00, 5.0000e-03],\n",
      "        [1.5976e+00, 1.5415e+00, 3.0000e+00, 3.0000e+00, 3.0000e+00, 1.0000e-03],\n",
      "        [1.2859e+00, 1.1776e+00, 3.0000e+00, 3.0000e+00, 4.0000e+00, 1.0000e-01],\n",
      "        [1.2458e+00, 1.1654e+00, 3.0000e+00, 3.0000e+00, 4.0000e+00, 1.0000e-02],\n",
      "        [1.2555e+00, 1.1765e+00, 3.0000e+00, 3.0000e+00, 4.0000e+00, 5.0000e-03],\n",
      "        [1.3592e+00, 1.3020e+00, 3.0000e+00, 3.0000e+00, 4.0000e+00, 1.0000e-03],\n",
      "        [1.2421e+00, 1.1650e+00, 3.0000e+00, 4.0000e+00, 2.0000e+00, 1.0000e-01],\n",
      "        [1.3323e+00, 1.1745e+00, 3.0000e+00, 4.0000e+00, 2.0000e+00, 1.0000e-02],\n",
      "        [1.3017e+00, 1.2127e+00, 3.0000e+00, 4.0000e+00, 2.0000e+00, 5.0000e-03],\n",
      "        [1.2601e+00, 1.1746e+00, 3.0000e+00, 4.0000e+00, 2.0000e+00, 1.0000e-03],\n",
      "        [1.2398e+00, 1.1669e+00, 3.0000e+00, 4.0000e+00, 3.0000e+00, 1.0000e-01],\n",
      "        [1.2388e+00, 1.1641e+00, 3.0000e+00, 4.0000e+00, 3.0000e+00, 1.0000e-02],\n",
      "        [1.2823e+00, 1.1673e+00, 3.0000e+00, 4.0000e+00, 3.0000e+00, 5.0000e-03],\n",
      "        [1.4745e+00, 1.4151e+00, 3.0000e+00, 4.0000e+00, 3.0000e+00, 1.0000e-03],\n",
      "        [1.2630e+00, 1.1865e+00, 3.0000e+00, 4.0000e+00, 4.0000e+00, 1.0000e-01],\n",
      "        [1.4602e+00, 1.2300e+00, 3.0000e+00, 4.0000e+00, 4.0000e+00, 1.0000e-02],\n",
      "        [1.2665e+00, 1.1697e+00, 3.0000e+00, 4.0000e+00, 4.0000e+00, 5.0000e-03],\n",
      "        [1.5995e+00, 1.4725e+00, 3.0000e+00, 4.0000e+00, 4.0000e+00, 1.0000e-03],\n",
      "        [1.2512e+00, 1.1637e+00, 3.0000e+00, 6.0000e+00, 2.0000e+00, 1.0000e-01],\n",
      "        [1.2403e+00, 1.1668e+00, 3.0000e+00, 6.0000e+00, 2.0000e+00, 1.0000e-02],\n",
      "        [1.2431e+00, 1.1642e+00, 3.0000e+00, 6.0000e+00, 2.0000e+00, 5.0000e-03],\n",
      "        [1.2793e+00, 1.2177e+00, 3.0000e+00, 6.0000e+00, 2.0000e+00, 1.0000e-03],\n",
      "        [1.2748e+00, 1.1635e+00, 3.0000e+00, 6.0000e+00, 3.0000e+00, 1.0000e-01],\n",
      "        [1.2343e+00, 1.1632e+00, 3.0000e+00, 6.0000e+00, 3.0000e+00, 1.0000e-02],\n",
      "        [1.2351e+00, 1.1633e+00, 3.0000e+00, 6.0000e+00, 3.0000e+00, 5.0000e-03],\n",
      "        [1.2397e+00, 1.1643e+00, 3.0000e+00, 6.0000e+00, 3.0000e+00, 1.0000e-03],\n",
      "        [1.2609e+00, 1.1635e+00, 3.0000e+00, 6.0000e+00, 4.0000e+00, 1.0000e-01],\n",
      "        [1.2334e+00, 1.1632e+00, 3.0000e+00, 6.0000e+00, 4.0000e+00, 1.0000e-02],\n",
      "        [1.2335e+00, 1.1664e+00, 3.0000e+00, 6.0000e+00, 4.0000e+00, 5.0000e-03],\n",
      "        [1.2322e+00, 1.1633e+00, 3.0000e+00, 6.0000e+00, 4.0000e+00, 1.0000e-03],\n",
      "        [1.2318e+00, 1.1656e+00, 4.0000e+00, 4.0000e+00, 2.0000e+00, 1.0000e-01],\n",
      "        [1.2311e+00, 1.1692e+00, 4.0000e+00, 4.0000e+00, 2.0000e+00, 1.0000e-02],\n",
      "        [1.5288e+00, 1.3925e+00, 4.0000e+00, 4.0000e+00, 2.0000e+00, 5.0000e-03],\n",
      "        [1.3535e+00, 1.3036e+00, 4.0000e+00, 4.0000e+00, 2.0000e+00, 1.0000e-03],\n",
      "        [1.2377e+00, 1.1665e+00, 4.0000e+00, 4.0000e+00, 3.0000e+00, 1.0000e-01],\n",
      "        [1.3135e+00, 1.1701e+00, 4.0000e+00, 4.0000e+00, 3.0000e+00, 1.0000e-02],\n",
      "        [1.2543e+00, 1.1688e+00, 4.0000e+00, 4.0000e+00, 3.0000e+00, 5.0000e-03],\n",
      "        [1.2436e+00, 1.1842e+00, 4.0000e+00, 4.0000e+00, 3.0000e+00, 1.0000e-03],\n",
      "        [1.2743e+00, 1.1665e+00, 4.0000e+00, 4.0000e+00, 4.0000e+00, 1.0000e-01],\n",
      "        [1.2581e+00, 1.1697e+00, 4.0000e+00, 4.0000e+00, 4.0000e+00, 1.0000e-02],\n",
      "        [1.2277e+00, 1.1667e+00, 4.0000e+00, 4.0000e+00, 4.0000e+00, 5.0000e-03],\n",
      "        [1.2267e+00, 1.1665e+00, 4.0000e+00, 4.0000e+00, 4.0000e+00, 1.0000e-03],\n",
      "        [1.2584e+00, 1.1630e+00, 4.0000e+00, 6.0000e+00, 2.0000e+00, 1.0000e-01],\n",
      "        [1.2380e+00, 1.1652e+00, 4.0000e+00, 6.0000e+00, 2.0000e+00, 1.0000e-02],\n",
      "        [1.2268e+00, 1.1632e+00, 4.0000e+00, 6.0000e+00, 2.0000e+00, 5.0000e-03],\n",
      "        [1.2726e+00, 1.1880e+00, 4.0000e+00, 6.0000e+00, 2.0000e+00, 1.0000e-03],\n",
      "        [1.2460e+00, 1.1659e+00, 4.0000e+00, 6.0000e+00, 3.0000e+00, 1.0000e-01],\n",
      "        [1.2328e+00, 1.1669e+00, 4.0000e+00, 6.0000e+00, 3.0000e+00, 1.0000e-02],\n",
      "        [1.2281e+00, 1.1654e+00, 4.0000e+00, 6.0000e+00, 3.0000e+00, 5.0000e-03],\n",
      "        [1.2374e+00, 1.1685e+00, 4.0000e+00, 6.0000e+00, 3.0000e+00, 1.0000e-03],\n",
      "        [1.2342e+00, 1.1659e+00, 4.0000e+00, 6.0000e+00, 4.0000e+00, 1.0000e-01],\n",
      "        [1.2390e+00, 1.1745e+00, 4.0000e+00, 6.0000e+00, 4.0000e+00, 1.0000e-02],\n",
      "        [1.2284e+00, 1.1649e+00, 4.0000e+00, 6.0000e+00, 4.0000e+00, 5.0000e-03],\n",
      "        [1.2742e+00, 1.1898e+00, 4.0000e+00, 6.0000e+00, 4.0000e+00, 1.0000e-03],\n",
      "        [1.2305e+00, 1.1684e+00, 6.0000e+00, 6.0000e+00, 2.0000e+00, 1.0000e-01],\n",
      "        [1.2307e+00, 1.1704e+00, 6.0000e+00, 6.0000e+00, 2.0000e+00, 1.0000e-02],\n",
      "        [1.2236e+00, 1.1677e+00, 6.0000e+00, 6.0000e+00, 2.0000e+00, 5.0000e-03],\n",
      "        [1.2334e+00, 1.1786e+00, 6.0000e+00, 6.0000e+00, 2.0000e+00, 1.0000e-03],\n",
      "        [1.2316e+00, 1.1699e+00, 6.0000e+00, 6.0000e+00, 3.0000e+00, 1.0000e-01],\n",
      "        [1.2268e+00, 1.1684e+00, 6.0000e+00, 6.0000e+00, 3.0000e+00, 1.0000e-02],\n",
      "        [1.2256e+00, 1.1683e+00, 6.0000e+00, 6.0000e+00, 3.0000e+00, 5.0000e-03],\n",
      "        [1.3457e+00, 1.2851e+00, 6.0000e+00, 6.0000e+00, 3.0000e+00, 1.0000e-03],\n",
      "        [1.2503e+00, 1.1682e+00, 6.0000e+00, 6.0000e+00, 4.0000e+00, 1.0000e-01],\n",
      "        [1.2242e+00, 1.1685e+00, 6.0000e+00, 6.0000e+00, 4.0000e+00, 1.0000e-02],\n",
      "        [1.2288e+00, 1.1692e+00, 6.0000e+00, 6.0000e+00, 4.0000e+00, 5.0000e-03],\n",
      "        [1.2576e+00, 1.1950e+00, 6.0000e+00, 6.0000e+00, 4.0000e+00, 1.0000e-03]])\n",
      "best parameters: tensor([1.2236e+00, 1.1677e+00, 6.0000e+00, 6.0000e+00, 2.0000e+00, 5.0000e-03])\n"
     ]
    }
   ],
   "source": [
    "# print(total_para)\n",
    "ans = torch.as_tensor(total_para)\n",
    "print(ans)\n",
    "print('best parameters:',ans[torch.argmin(ans,0)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}